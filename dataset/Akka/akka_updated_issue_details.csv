issue_id,creator_login_id,created_date,closed_date,closed_by,commenters,title,description,files,resolvers
32681,0bon,2025-03-09T21:19:18Z,2025-03-12T08:01:13Z,johanandren,0bon; patriknw; johanandren,Cannot access 'akka.actor.typed.internal.BehaviorImpl.DeferredBehavior',"I am trying to implement `DurableStateBehaviour` in my kotlin code  but I keep getting the following error:   `Cannot access 'akka.actor.typed.internal.BehaviorImpl.DeferredBehavior' which is a supertype of 'uk.co.xyz.application.AppointActor'. Check your module classpath for missing or conflicting dependencies`   ``` class AppointActor : DurableStateBehavior<Command  State> {      override fun emptyState(): State {         TODO(""Not yet implemented"")     }      override fun commandHandler(): CommandHandler<Command  State> {         return CommandHandler<Command  State> { state  command ->             throw RuntimeException(""TODO: process the command & return an Effect"")         }     } } ```  The java variant works fine. Please advise.",,0bon; patriknw; johanandren
32667,zxuanhong,2025-02-21T12:53:40Z,2025-02-24T12:42:16Z,johanandren,johanandren,The akka-sample-sharding-killrweather-java in the latest repository cannot run,"## critical error info 1. java.lang.NoSuchMethodError: 'scala.concurrent.ExecutionContext akka.dispatch.ExecutionContexts$.parasitic()'  <img width=""1273"" alt=""Image"" src=""https://github.com/user-attachments/assets/d19e4b77-a86a-4896-84b6-00ac5d54a161"" />  ## env 1. system: macos 2. jdk: openjdk 21 3. akka: 2.13-->2.10.2   ## log infio ``` [2025-02-21 20:50:58 114] [WARN] [akka://KillrWeather@127.0.0.1:2553] [akka.stream.Materializer] [KillrWeather-akka.actor.default-dispatcher-28] [akka.stream.Log(akka://KillrWeather/system/Materializers/StreamSupervisor-7)] - [outbound connection to [akka://KillrWeather@127.0.0.1:2554]  control stream] Upstream failed  cause: StreamTcpException: Tcp command [Connect(127.0.0.1/<unresolved>:2554 None List() Some(5000 milliseconds) true)] failed because of java.net.ConnectException: Connection refused [2025-02-21 20:50:58 115] [INFO] [akka://KillrWeather@127.0.0.1:2553] [akka.cluster.sharding.ShardRegion] [KillrWeather-akka.actor.default-dispatcher-26] [akka://KillrWeather@127.0.0.1:2553/system/sharding/WeatherStation] - WeatherStation: Automatic entity passivation: idle entities after [2.000 min]  checked every [1.000 min] [2025-02-21 20:50:58 116] [WARN] [akka://KillrWeather@127.0.0.1:2553] [akka.stream.Materializer] [KillrWeather-akka.actor.default-dispatcher-26] [akka.stream.Log(akka://KillrWeather/system/Materializers/StreamSupervisor-7)] - [outbound connection to [akka://KillrWeather@127.0.0.1:2554]  message stream] Upstream failed  cause: StreamTcpException: Tcp command [Connect(127.0.0.1/<unresolved>:2554 None List() Some(5000 milliseconds) true)] failed because of java.net.ConnectException: Connection refused [2025-02-21 20:50:58 138] [INFO] [] [akka.event.slf4j.Slf4jLogger] [KillrWeather-akka.actor.default-dispatcher-4] [] - Slf4jLogger started [2025-02-21 20:50:58 168] [INFO] [akka://KillrWeather@127.0.0.1:2554] [akka.remote.artery.ArteryTransport] [KillrWeather-akka.actor.default-dispatcher-4] [ArteryTransport(akka://KillrWeather)] - Remoting started with transport [Artery tcp]; listening on address [akka://KillrWeather@127.0.0.1:2554] with UID [-6445106518558490889] [2025-02-21 20:50:58 169] [INFO] [akka://KillrWeather@127.0.0.1:2554] [akka.cluster.Cluster] [KillrWeather-akka.actor.default-dispatcher-4] [Cluster(akka://KillrWeather)] - Cluster Node [akka://KillrWeather@127.0.0.1:2554] - Starting up  Akka version [2.10.2] ... [2025-02-21 20:50:58 177] [WARN] [akka://KillrWeather@127.0.0.1:2554] [akka.cluster.Cluster] [KillrWeather-akka.actor.default-dispatcher-4] [Cluster(akka://KillrWeather)] - Could not register Cluster JMX MBean with name=akka:type=Cluster as it is already registered. If you are running multiple clusters in the same JVM  set 'akka.cluster.jmx.multi-mbeans-in-same-jvm = on' in config [2025-02-21 20:50:58 177] [INFO] [akka://KillrWeather@127.0.0.1:2554] [akka.cluster.Cluster] [KillrWeather-akka.actor.default-dispatcher-4] [Cluster(akka://KillrWeather)] - Cluster Node [akka://KillrWeather@127.0.0.1:2554] - Started up successfully [2025-02-21 20:50:58 179] [WARN] [akka://KillrWeather@127.0.0.1:2554] [akka.actor.ActorSystemImpl] [KillrWeather-akka.actor.default-dispatcher-14] [akka.actor.ActorSystemImpl(KillrWeather)] - Dev use only. Free keys at https://akka.io/key [2025-02-21 20:50:58 181] [INFO] [akka://KillrWeather@127.0.0.1:2554] [akka.cluster.sbr.SplitBrainResolver] [KillrWeather-akka.actor.default-dispatcher-14] [akka://KillrWeather/system/cluster/core/daemon/downingProvider] - SBR started. Config: strategy [KeepMajority]  stable-after [20 seconds]  down-all-when-unstable [15 seconds]  selfUniqueAddress [akka://KillrWeather@127.0.0.1:2554#-6445106518558490889]  selfDc [default]. [2025-02-21 20:50:58 197] [INFO] [akka://KillrWeather@127.0.0.1:2554] [akka.diagnostics.StarvationDetector$StarvationDetectorThread] [KillrWeather-akka.actor.default-dispatcher-4] [StarvationDetector$StarvationDetectorThread(akka://KillrWeather)] - Starvation detector will start after `akka.diagnostics.starvation-detector.initial-delay = 10000 milliseconds` [2025-02-21 20:50:58 197] [INFO] [akka://KillrWeather@127.0.0.1:2554] [akka.diagnostics.ConfigChecker] [KillrWeather-akka.actor.default-dispatcher-4] [akka.diagnostics.ConfigChecker] - Starting ConfigChecker. Looking for potential issues in your configuration. Issues found will be logged as warnings [2025-02-21 20:50:58 198] [INFO] [akka://KillrWeather@127.0.0.1:2554] [akka.diagnostics.StarvationDetector$StarvationDetectorThread] [KillrWeather-akka.actor.default-dispatcher-4] [StarvationDetector$StarvationDetectorThread(akka://KillrWeather)] - Starvation detector will start after `akka.diagnostics.starvation-detector.initial-delay = 10000 milliseconds` [2025-02-21 20:50:58 211] [INFO] [akka://KillrWeather@127.0.0.1:2554] [akka.cluster.sharding.typed.scaladsl.ClusterSharding] [KillrWeather-akka.actor.default-dispatcher-14] [ClusterSharding(akka://KillrWeather)] - Starting Shard Region [WeatherStation]... [2025-02-21 20:50:58 215] [INFO] [akka://KillrWeather@127.0.0.1:2554] [akka.cluster.sharding.ShardRegion] [KillrWeather-akka.actor.default-dispatcher-14] [akka://KillrWeather@127.0.0.1:2554/system/sharding/WeatherStation] - WeatherStation: Automatic entity passivation: idle entities after [2.000 min]  checked every [1.000 min] Uncaught error from thread [KillrWeather-akka.actor.default-dispatcher-4]: 'scala.concurrent.ExecutionContext akka.dispatch.ExecutionContexts$.parasitic()'  shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[KillrWeather] java.lang.NoSuchMethodError: 'scala.concurrent.ExecutionContext akka.dispatch.ExecutionContexts$.parasitic()' 	at akka.http.javadsl.server.directives.RouteDirectives.<init>(RouteDirectives.scala:31) 	at akka.http.javadsl.server.directives.SchemeDirectives.<init>(SchemeDirectives.scala:13) 	at akka.http.javadsl.server.directives.SecurityDirectives.<init>(SecurityDirectives.scala:47) 	at akka.http.javadsl.server.directives.WebSocketDirectives.<init>(WebSocketDirectives.scala:21) 	at akka.http.javadsl.server.directives.TimeoutDirectives.<init>(TimeoutDirectives.scala:17) 	at akka.http.javadsl.server.directives.FramedEntityStreamingDirectives.<init>(FramedEntityStreamingDirectives.scala:20) 	at akka.http.javadsl.server.AllDirectives.<init>(Directives.scala:14) 	at akka.http.javadsl.server.Directives$.<init>(Directives.scala:21) 	at akka.http.javadsl.server.Directives$.<clinit>(Directives.scala:21) 	at akka.http.javadsl.server.Directives.path(Directives.scala) 	at sample.killrweather.WeatherRoutes.weather(WeatherRoutes.java:78) 	at sample.killrweather.Guardian.lambda$create$77341534$1(Guardian.java:16) 	at akka.actor.typed.javadsl.Behaviors$.$anonfun$setup$1(Behaviors.scala:47) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.internal.InterceptorImpl$$anon$1.start(InterceptorImpl.scala:50) 	at akka.actor.typed.BehaviorInterceptor.aroundStart(BehaviorInterceptor.scala:55) 	at akka.actor.typed.internal.InterceptorImpl.preStart(InterceptorImpl.scala:73) 	at akka.actor.typed.internal.InterceptorImpl$.$anonfun$apply$1(InterceptorImpl.scala:30) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.Behavior$.interpret(Behavior.scala:283) 	at akka.actor.typed.Behavior$.interpretMessage(Behavior.scala:238) 	at akka.actor.typed.internal.adapter.ActorAdapter.handleMessage(ActorAdapter.scala:133) 	at akka.actor.typed.internal.adapter.ActorAdapter.aroundReceive(ActorAdapter.scala:109) 	at akka.actor.ActorCell.receiveMessage$$$capture(ActorCell.scala:575) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala) 	at --- Async.Stack.Trace --- (captured by IntelliJ IDEA debugger) 	at akka.actor.LocalActorRef.$bang(ActorRef.scala) 	at akka.actor.typed.ActorSystem$.createInternal(ActorSystem.scala:306) 	at akka.actor.typed.ActorSystem$.apply(ActorSystem.scala:218) 	at akka.actor.typed.ActorSystem$.create(ActorSystem.scala:255) 	at akka.actor.typed.ActorSystem.create(ActorSystem.scala) 	at sample.killrweather.KillrWeather.startup(KillrWeather.java:24) 	at sample.killrweather.KillrWeather.main(KillrWeather.java:18) Uncaught error from thread [KillrWeather-akka.actor.default-dispatcher-4]: Uncaught error from thread [KillrWeather-akka.actor.default-dispatcher-15]: Could not initialize class akka.http.javadsl.server.Directives$  shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[KillrWeather] java.lang.NoClassDefFoundError: Could not initialize class akka.http.javadsl.server.Directives$ 	at akka.http.javadsl.server.Directives.path(Directives.scala) 	at sample.killrweather.WeatherRoutes.weather(WeatherRoutes.java:78) 	at sample.killrweather.Guardian.lambda$create$77341534$1(Guardian.java:16) 	at akka.actor.typed.javadsl.Behaviors$.$anonfun$setup$1(Behaviors.scala:47) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.internal.InterceptorImpl$$anon$1.start(InterceptorImpl.scala:50) 	at akka.actor.typed.BehaviorInterceptor.aroundStart(BehaviorInterceptor.scala:55) 	at akka.actor.typed.internal.InterceptorImpl.preStart(InterceptorImpl.scala:73) 	at akka.actor.typed.internal.InterceptorImpl$.$anonfun$apply$1(InterceptorImpl.scala:30) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.Behavior$.interpret(Behavior.scala:283) 	at akka.actor.typed.Behavior$.interpretMessage(Behavior.scala:238) 	at akka.actor.typed.internal.adapter.ActorAdapter.handleMessage(ActorAdapter.scala:133) 	at akka.actor.typed.internal.adapter.ActorAdapter.aroundReceive(ActorAdapter.scala:109) 	at akka.actor.ActorCell.receiveMessage$$$capture(ActorCell.scala:575) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala) 	at --- Async.Stack.Trace --- (captured by IntelliJ IDEA debugger) 	at akka.actor.LocalActorRef.$bang(ActorRef.scala) 	at akka.actor.typed.ActorSystem$.createInternal(ActorSystem.scala:306) 	at akka.actor.typed.ActorSystem$.apply(ActorSystem.scala:218) 	at akka.actor.typed.ActorSystem$.create(ActorSystem.scala:255) 	at akka.actor.typed.ActorSystem.create(ActorSystem.scala) 	at sample.killrweather.KillrWeather.startup(KillrWeather.java:24) 	at sample.killrweather.KillrWeather.main(KillrWeather.java:16) Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.NoSuchMethodError: 'scala.concurrent.ExecutionContext akka.dispatch.ExecutionContexts$.parasitic()' [in thread ""KillrWeather-akka.actor.default-dispatcher-4""] 	at akka.http.javadsl.server.directives.RouteDirectives.<init>(RouteDirectives.scala:31) 	at akka.http.javadsl.server.directives.SchemeDirectives.<init>(SchemeDirectives.scala:13) 	at akka.http.javadsl.server.directives.SecurityDirectives.<init>(SecurityDirectives.scala:47) 	at akka.http.javadsl.server.directives.WebSocketDirectives.<init>(WebSocketDirectives.scala:21) 	at akka.http.javadsl.server.directives.TimeoutDirectives.<init>(TimeoutDirectives.scala:17) 	at akka.http.javadsl.server.directives.FramedEntityStreamingDirectives.<init>(FramedEntityStreamingDirectives.scala:20) 	at akka.http.javadsl.server.AllDirectives.<init>(Directives.scala:14) 	at akka.http.javadsl.server.Directives$.<init>(Directives.scala:21) 	at akka.http.javadsl.server.Directives$.<clinit>(Directives.scala:21) 	at akka.http.javadsl.server.Directives.path(Directives.scala) 	at sample.killrweather.WeatherRoutes.weather(WeatherRoutes.java:78) 	at sample.killrweather.Guardian.lambda$create$77341534$1(Guardian.java:16) 	at akka.actor.typed.javadsl.Behaviors$.$anonfun$setup$1(Behaviors.scala:47) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.internal.InterceptorImpl$$anon$1.start(InterceptorImpl.scala:50) 	at akka.actor.typed.BehaviorInterceptor.aroundStart(BehaviorInterceptor.scala:55) 	at akka.actor.typed.internal.InterceptorImpl.preStart(InterceptorImpl.scala:73) 	at akka.actor.typed.internal.InterceptorImpl$.$anonfun$apply$1(InterceptorImpl.scala:30) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.Behavior$.interpret(Behavior.scala:283) 	at akka.actor.typed.Behavior$.interpretMessage(Behavior.scala:238) 	at akka.actor.typed.internal.adapter.ActorAdapter.handleMessage(ActorAdapter.scala:133) 	at akka.actor.typed.internal.adapter.ActorAdapter.aroundReceive(ActorAdapter.scala:109) 	at akka.actor.ActorCell.receiveMessage$$$capture(ActorCell.scala:575) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala) 	at --- Async.Stack.Trace --- (captured by IntelliJ IDEA debugger) 	at akka.actor.LocalActorRef.$bang(ActorRef.scala) 	at akka.actor.typed.ActorSystem$.createInternal(ActorSystem.scala:306) 	at akka.actor.typed.ActorSystem$.apply(ActorSystem.scala:218) 	at akka.actor.typed.ActorSystem$.create(ActorSystem.scala:255) 	at akka.actor.typed.ActorSystem.create(ActorSystem.scala) 	at sample.killrweather.KillrWeather.startup(KillrWeather.java:24) 	at sample.killrweather.KillrWeather.main(KillrWeather.java:18) Uncaught error from thread [KillrWeather-akka.actor.default-dispatcher-17]: Could not initialize class akka.http.javadsl.server.Directives$  shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[KillrWeather] java.lang.NoClassDefFoundError: Could not initialize class akka.http.javadsl.server.Directives$ 	at akka.http.javadsl.server.Directives.path(Directives.scala) 	at sample.killrweather.WeatherRoutes.weather(WeatherRoutes.java:78) 	at sample.killrweather.Guardian.lambda$create$77341534$1(Guardian.java:16) 	at akka.actor.typed.javadsl.Behaviors$.$anonfun$setup$1(Behaviors.scala:47) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.internal.InterceptorImpl$$anon$1.start(InterceptorImpl.scala:50) 	at akka.actor.typed.BehaviorInterceptor.aroundStart(BehaviorInterceptor.scala:55) 	at akka.actor.typed.internal.InterceptorImpl.preStart(InterceptorImpl.scala:73) 	at akka.actor.typed.internal.InterceptorImpl$.$anonfun$apply$1(InterceptorImpl.scala:30) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.Behavior$.interpret(Behavior.scala:283) 	at akka.actor.typed.Behavior$.interpretMessage(Behavior.scala:238) 	at akka.actor.typed.internal.adapter.ActorAdapter.handleMessage(ActorAdapter.scala:133) 	at akka.actor.typed.internal.adapter.ActorAdapter.aroundReceive(ActorAdapter.scala:109) 	at akka.actor.ActorCell.receiveMessage$$$capture(ActorCell.scala:575) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala) 	at --- Async.Stack.Trace --- (captured by IntelliJ IDEA debugger) 	at akka.actor.LocalActorRef.$bang(ActorRef.scala) 	at akka.actor.typed.ActorSystem$.createInternal(ActorSystem.scala:306) 	at akka.actor.typed.ActorSystem$.apply(ActorSystem.scala:218) 	at akka.actor.typed.ActorSystem$.create(ActorSystem.scala:255) 	at akka.actor.typed.ActorSystem.create(ActorSystem.scala) 	at sample.killrweather.KillrWeather.startup(KillrWeather.java:24) 	at sample.killrweather.KillrWeather.main(KillrWeather.java:17) Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.NoSuchMethodError: 'scala.concurrent.ExecutionContext akka.dispatch.ExecutionContexts$.parasitic()' [in thread ""KillrWeather-akka.actor.default-dispatcher-4""] 	at akka.http.javadsl.server.directives.RouteDirectives.<init>(RouteDirectives.scala:31) 	at akka.http.javadsl.server.directives.SchemeDirectives.<init>(SchemeDirectives.scala:13) 	at akka.http.javadsl.server.directives.SecurityDirectives.<init>(SecurityDirectives.scala:47) 	at akka.http.javadsl.server.directives.WebSocketDirectives.<init>(WebSocketDirectives.scala:21) 	at akka.http.javadsl.server.directives.TimeoutDirectives.<init>(TimeoutDirectives.scala:17) 	at akka.http.javadsl.server.directives.FramedEntityStreamingDirectives.<init>(FramedEntityStreamingDirectives.scala:20) 	at akka.http.javadsl.server.AllDirectives.<init>(Directives.scala:14) 	at akka.http.javadsl.server.Directives$.<init>(Directives.scala:21) 	at akka.http.javadsl.server.Directives$.<clinit>(Directives.scala:21) 	at akka.http.javadsl.server.Directives.path(Directives.scala) 	at sample.killrweather.WeatherRoutes.weather(WeatherRoutes.java:78) 	at sample.killrweather.Guardian.lambda$create$77341534$1(Guardian.java:16) 	at akka.actor.typed.javadsl.Behaviors$.$anonfun$setup$1(Behaviors.scala:47) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.internal.InterceptorImpl$$anon$1.start(InterceptorImpl.scala:50) 	at akka.actor.typed.BehaviorInterceptor.aroundStart(BehaviorInterceptor.scala:55) 	at akka.actor.typed.internal.InterceptorImpl.preStart(InterceptorImpl.scala:73) 	at akka.actor.typed.internal.InterceptorImpl$.$anonfun$apply$1(InterceptorImpl.scala:30) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.Behavior$.interpret(Behavior.scala:283) 	at akka.actor.typed.Behavior$.interpretMessage(Behavior.scala:238) 	at akka.actor.typed.internal.adapter.ActorAdapter.handleMessage(ActorAdapter.scala:133) 	at akka.actor.typed.internal.adapter.ActorAdapter.aroundReceive(ActorAdapter.scala:109) 	at akka.actor.ActorCell.receiveMessage$$$capture(ActorCell.scala:575) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala) 	at --- Async.Stack.Trace --- (captured by IntelliJ IDEA debugger) 	at akka.actor.LocalActorRef.$bang(ActorRef.scala) 	at akka.actor.typed.ActorSystem$.createInternal(ActorSystem.scala:306) 	at akka.actor.typed.ActorSystem$.apply(ActorSystem.scala:218) 	at akka.actor.typed.ActorSystem$.create(ActorSystem.scala:255) 	at akka.actor.typed.ActorSystem.create(ActorSystem.scala) 	at sample.killrweather.KillrWeather.startup(KillrWeather.java:24) 	at sample.killrweather.KillrWeather.main(KillrWeather.java:18) Could not initialize class akka.http.javadsl.server.Directives$  shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[KillrWeather] java.lang.NoClassDefFoundError: Could not initialize class akka.http.javadsl.server.Directives$ 	at akka.http.javadsl.server.Directives.path(Directives.scala) 	at sample.killrweather.WeatherRoutes.weather(WeatherRoutes.java:78) 	at sample.killrweather.Guardian.lambda$create$77341534$1(Guardian.java:16) 	at akka.actor.typed.javadsl.Behaviors$.$anonfun$setup$1(Behaviors.scala:47) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.internal.InterceptorImpl$$anon$1.start(InterceptorImpl.scala:50) 	at akka.actor.typed.BehaviorInterceptor.aroundStart(BehaviorInterceptor.scala:55) 	at akka.actor.typed.internal.InterceptorImpl.preStart(InterceptorImpl.scala:73) 	at akka.actor.typed.internal.InterceptorImpl$.$anonfun$apply$1(InterceptorImpl.scala:30) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.Behavior$.interpret(Behavior.scala:283) 	at akka.actor.typed.Behavior$.interpretMessage(Behavior.scala:238) 	at akka.actor.typed.internal.adapter.ActorAdapter.handleMessage(ActorAdapter.scala:133) 	at akka.actor.typed.internal.adapter.ActorAdapter.aroundReceive(ActorAdapter.scala:109) 	at akka.actor.ActorCell.receiveMessage$$$capture(ActorCell.scala:575) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala) 	at --- Async.Stack.Trace --- (captured by IntelliJ IDEA debugger) 	at akka.actor.LocalActorRef.$bang(ActorRef.scala) 	at akka.actor.typed.ActorSystem$.createInternal(ActorSystem.scala:306) 	at akka.actor.typed.ActorSystem$.apply(ActorSystem.scala:218) 	at akka.actor.typed.ActorSystem$.create(ActorSystem.scala:255) 	at akka.actor.typed.ActorSystem.create(ActorSystem.scala) 	at sample.killrweather.KillrWeather.startup(KillrWeather.java:24) 	at sample.killrweather.KillrWeather.main(KillrWeather.java:19) Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.NoSuchMethodError: 'scala.concurrent.ExecutionContext akka.dispatch.ExecutionContexts$.parasitic()' [in thread ""KillrWeather-akka.actor.default-dispatcher-4""] 	at akka.http.javadsl.server.directives.RouteDirectives.<init>(RouteDirectives.scala:31) 	at akka.http.javadsl.server.directives.SchemeDirectives.<init>(SchemeDirectives.scala:13) 	at akka.http.javadsl.server.directives.SecurityDirectives.<init>(SecurityDirectives.scala:47) 	at akka.http.javadsl.server.directives.WebSocketDirectives.<init>(WebSocketDirectives.scala:21) 	at akka.http.javadsl.server.directives.TimeoutDirectives.<init>(TimeoutDirectives.scala:17) 	at akka.http.javadsl.server.directives.FramedEntityStreamingDirectives.<init>(FramedEntityStreamingDirectives.scala:20) 	at akka.http.javadsl.server.AllDirectives.<init>(Directives.scala:14) 	at akka.http.javadsl.server.Directives$.<init>(Directives.scala:21) 	at akka.http.javadsl.server.Directives$.<clinit>(Directives.scala:21) 	at akka.http.javadsl.server.Directives.path(Directives.scala) 	at sample.killrweather.WeatherRoutes.weather(WeatherRoutes.java:78) 	at sample.killrweather.Guardian.lambda$create$77341534$1(Guardian.java:16) 	at akka.actor.typed.javadsl.Behaviors$.$anonfun$setup$1(Behaviors.scala:47) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.internal.InterceptorImpl$$anon$1.start(InterceptorImpl.scala:50) 	at akka.actor.typed.BehaviorInterceptor.aroundStart(BehaviorInterceptor.scala:55) 	at akka.actor.typed.internal.InterceptorImpl.preStart(InterceptorImpl.scala:73) 	at akka.actor.typed.internal.InterceptorImpl$.$anonfun$apply$1(InterceptorImpl.scala:30) 	at akka.actor.typed.internal.BehaviorImpl$DeferredBehavior$$anon$1.apply(BehaviorImpl.scala:119) 	at akka.actor.typed.Behavior$.start(Behavior.scala:176) 	at akka.actor.typed.Behavior$.interpret(Behavior.scala:283) 	at akka.actor.typed.Behavior$.interpretMessage(Behavior.scala:238) 	at akka.actor.typed.internal.adapter.ActorAdapter.handleMessage(ActorAdapter.scala:133) 	at akka.actor.typed.internal.adapter.ActorAdapter.aroundReceive(ActorAdapter.scala:109) 	at akka.actor.ActorCell.receiveMessage$$$capture(ActorCell.scala:575) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala) 	at --- Async.Stack.Trace --- (captured by IntelliJ IDEA debugger) 	at akka.actor.LocalActorRef.$bang(ActorRef.scala) 	at akka.actor.typed.ActorSystem$.createInternal(ActorSystem.scala:306) 	at akka.actor.typed.ActorSystem$.apply(ActorSystem.scala:218) 	at akka.actor.typed.ActorSystem$.create(ActorSystem.scala:255) 	at akka.actor.typed.ActorSystem.create(ActorSystem.scala) 	at sample.killrweather.KillrWeather.startup(KillrWeather.java:24) 	at sample.killrweather.KillrWeather.main(KillrWeather.java:18) ``` ",samples/akka-sample-cluster-scala/build.sbt; samples/akka-sample-distributed-data-scala/build.sbt; samples/akka-sample-fsm-scala/build.sbt; samples/akka-sample-kafka-to-sharding-scala/build.sbt; samples/akka-sample-kafka-to-sharding-scala/client/src/main/resources/application.conf; samples/akka-sample-kafka-to-sharding-scala/client/src/main/scala/client/ClientApp.scala; samples/akka-sample-kafka-to-sharding-scala/processor/src/main/scala/sample/sharding/kafka/Main.scala; samples/akka-sample-kafka-to-sharding-scala/project/plugins.sbt; samples/akka-sample-sharding-java/build.sbt; samples/akka-sample-sharding-java/killrweather-fog/pom.xml; samples/akka-sample-sharding-java/killrweather/pom.xml; samples/akka-sample-sharding-scala/build.sbt,johanandren
32665,sheeladapts,2025-02-18T18:31:20Z,2025-02-26T09:14:12Z,johanandren,johanandren,Adapts AI Open Documentation for Akka – Tech Specs  High-Level Details & Data Flow Diagrams,Hi Akka Team   We at Adapts AI have documented a detailed technical specification  high-level details  and data sequence diagrams for Akka. Our goal is to provide a comprehensive reference that developers and contributors can leverage to understand and optimize their usage of Akka.  📌 Documentation Link: [Adapts AI Wiki for Akka](https://w.adapts.io/en/OpenSource/Akka)  We would love to hear your thoughts and any feedback on how we can improve or expand this resource for the community. Let us know if there are any additional insights or topics you’d like us to cover!  Looking forward to collaborating!  Thanks  Vivek Sheel,,johanandren
32659,patriknw,2025-02-17T09:22:14Z,2025-02-17T13:46:01Z,patriknw,,Release 2.10.2,"Release Akka 2.10.2  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.10.2=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [x] Update the version and change date in the LICENSE file. - [x] Update the Akka version in the samples to 2.10.2  otherwise the published zip files of the samples will have the old version. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.10.2 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [ ] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.10.2`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka-core/2.10.2/) documentation - [x] Check [reference](https://doc.akka.io/libraries/akka-core/2.10.2/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.10.2/akka-actor_2.13-2.10.2.pom  ### When everything is on https://repo.akka.io/maven   - [x] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.10.2`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add libraries/akka-core/current libraries/akka-core/2.10.2          git add api/akka-core/current api/akka-core/2.10.2          git add japi/akka-core/current japi/akka-core/2.10.2          git commit -m ""Akka 2.10.2""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/libraries/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update sbt new templates:   - [x] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,patriknw
32653,johanandren,2025-02-13T08:08:29Z,2025-02-13T14:49:16Z,johanandren,,Release 2.9.8,"Release Akka 2.9.8  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.8=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [x] Update the version and change date in the LICENSE file. - [x] Update the Akka version in the samples to 2.9.8  otherwise the published zip files of the samples will have the old version. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.9.8 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.8`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.9.8/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.9.8/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.9.8/akka-actor_2.13-2.9.8.pom  ### When everything is on https://repo.akka.io/maven   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.8`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.8          git add api/akka/current api/akka/2.9.8          git add japi/akka/current japi/akka/2.9.8          git commit -m ""Akka 2.9.8""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/docs/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update sbt new templates:   - [ ] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,johanandren
32630,patriknw,2025-01-28T06:36:18Z,2025-02-17T11:39:34Z,patriknw,,Release 2.10.1,"Release Akka 2.10.1  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.10.1=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [x] Update the version and change date in the LICENSE file. - [x] Update the Akka version in the samples to 2.10.1  otherwise the published zip files of the samples will have the old version. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.10.1 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.10.1`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka-core/2.10.1/) documentation - [x] Check [reference](https://doc.akka.io/libraries/akka-core/2.10.1/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.10.1/akka-actor_2.13-2.10.1.pom  ### When everything is on https://repo.akka.io/maven   - [x] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.10.1`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add libraries/akka-core/current libraries/akka-core/2.10.1          git add api/akka-core/current api/akka-core/2.10.1          git add japi/akka-core/current japi/akka-core/2.10.1          git commit -m ""Akka 2.10.1""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/libraries/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update sbt new templates:   - [ ] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,patriknw
32618,liuweiGit,2024-12-02T05:40:46Z,2024-12-09T14:18:18Z,patriknw,patriknw; yuanpli; liuweiGit,[Akka-actor] cannot create children while terminating or terminated] with root cause,"exception is java.lang.IllegalStateException: cannot create children while terminating or terminated] with root cause java.lang.IllegalStateException: cannot create children while terminating or terminated 	at akka.actor.dungeon.Children.makeChild(Children.scala:298) 	at akka.actor.dungeon.Children.attachChild(Children.scala:53) 	at akka.actor.dungeon.Children.attachChild$(Children.scala:23) 	at akka.actor.ActorCell.attachChild(ActorCell.scala:410) 	at akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:914)  Hello  how can I solve this problem? Run it for a while and it will look like this.",,patriknw; yuanpli; liuweiGit
32603,odidev,2024-11-14T06:26:46Z,2024-11-14T16:18:35Z,johanandren,johanandren,Build and test for Linux/ARM64,"## Description    For aarch64 platform  I have built "" Akka"" from source.    ## Steps     Following ""STEPS (https://doc.akka.io/docs/akka/current/typed/guide/index.html)"" were used for building and installing Akka.  ``` sudo apt install openjdk-21-jdk -y  export JAVA_HOME=/usr/lib/jvm/java-21-openjdk-arm64  export PATH=$PATH:$JAVA_HOME/bin  echo $PATH  echo ""deb https://repo.scala-sbt.org/scalasbt/debian /"" | sudo tee -a /etc/apt/sources.list.d/sbt.list  curl -sL ""https://keyserver.ubuntu.com/pks/lookup?op=get&search=0x2EE0EA64E40A89B84B2DF73499E82A75642AC823"" | sudo apt-key add  sudo apt-get update  sudo apt-get install sbt  Wget https://github.com/akka/akka/archive/refs/tags/v2.10.0.tar.gz  tar xvf v2.10.0.tar.gz  cd akka-2.10.0  sbt  ``` ## Outcome    The next steps after starting the sbt server using sbt command is to interact with the project.  ``` [info] started sbt server  akka > version  > [info] Akka version: 2.10.0  ```   All this information was also added to Software Ecosystem Dashboard for Arm (https://www.arm.com/developer-hub/ecosystem-dashboard/). ",,johanandren
32583,sebastian-alfers,2024-10-25T11:18:40Z,2024-10-28T13:47:03Z,sebastian-alfers,,Release 2.8.8,"Release Akka 2.8.8  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.8=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [x] Update the version and change date in the LICENSE file. - [x] Update the Akka version in the samples to 2.8.8  otherwise the published zip files of the samples will have the old version. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.8 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [x] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.8`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka-core/2.8.8/) documentation - [x] Check [reference](https://doc.akka.io/libraries/akka-core/2.8.8/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.8.8/akka-actor_2.13-2.8.8.pom  ### When everything is on https://repo.akka.io/maven   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.8`     - [ ] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add libraries/akka-core/current libraries/akka-core/2.8.8          git add api/akka-core/current api/akka-core/2.8.8          git add japi/akka-core/current japi/akka-core/2.8.8          git commit -m ""Akka 2.8.8""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/libraries/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update sbt new templates:   - [ ] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,sebastian-alfers
32576,sebastian-alfers,2024-10-16T21:05:45Z,2024-10-17T06:54:51Z,johanandren,sebastian-alfers,Version not parsed correct,"When I add the following assertion to `akka.util.VersionSpec`  only the first passes:  ```       Version(""2.10.0-M1"") should be < Version(""2.10.0"")       Version(""2.10.0"") should be > Version(""2.10.0-M1"") ```  Error: ``` [info] - should compare extra *** FAILED *** (4 milliseconds) [info]   2.10.0 was not greater than 2.10.0-M1 (VersionSpec.scala:55) ```",,sebastian-alfers
32572,johanandren,2024-10-16T11:53:47Z,2024-10-17T11:58:36Z,johanandren,,Release 2.9.7,"Release Akka 2.9.7  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.7=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [x] Update the version and change date in the LICENSE file. - [x] Update the Akka version in the samples to 2.9.7  otherwise the published zip files of the samples will have the old version. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.9.7 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.7`  title and release description. Use the `Publish release` button  which will create the tag. - [ ] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.9.7/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.9.7/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.9.7/akka-actor_2.13-2.9.7.pom  ### When everything is on https://repo.akka.io/maven   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.7`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.7          git add api/akka/current api/akka/2.9.7          git add japi/akka/current japi/akka/2.9.7          git commit -m ""Akka 2.9.7""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/docs/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update sbt new templates:   - [x] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,johanandren
32564,patriknw,2024-10-15T09:44:54Z,2024-10-24T13:17:49Z,johanandren,patriknw; johanandren,fail: ReplicatedEventSourcingSpec interceptor,"https://github.com/akka/akka/actions/runs/11342612762/job/31543407718?pr=32558#step:5:11617  ``` [10-15 09:10:55.166] [info] - should intercept and delay replicated events between two entities *** FAILED *** (206 milliseconds) [10-15 09:10:55.175] [info]   Set(Intercepted(R1  1  ""from r1"")  Intercepted(R2  2  ""from r2"")) did not equal Set(Intercepted(R1  2  ""from r1"")  Intercepted(R2  2  ""from r2"")) (ReplicatedEventSourcingSpec.scala:594) [10-15 09:10:55.175] [info]   Analysis: [10-15 09:10:55.175] [info]   Set(missingInLeft: [Intercepted(R1  2  ""from r1"")]  missingInRight: [Intercepted(R1  1  ""from r1"")]) [10-15 09:10:55.175] [info]   org.scalatest.exceptions.TestFailedException: [10-15 09:10:55.176] [info]   at org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:397) [10-15 09:10:55.176] [info]   at org.scalatest.matchers.should.Matchers$AnyShouldWrapper.shouldEqual(Matchers.scala:7394) [10-15 09:10:55.177] [info]   at akka.persistence.typed.ReplicatedEventSourcingSpec.$anonfun$new$36(ReplicatedEventSourcingSpec.scala:594) ```",,patriknw; johanandren
32561,sebastian-alfers,2024-10-14T15:28:01Z,2024-11-19T09:56:29Z,sebastian-alfers,,Release 2.10.0,"Release Akka 2.10.0  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.10.0=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [x] Update the version and change date in the LICENSE file. - [x] Update the Akka version in the samples to 2.10.0  otherwise the published zip files of the samples will have the old version. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.10.0 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [x] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.10.0`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka-core/2.10.0/) documentation - [x] Check [reference](https://doc.akka.io/libraries/akka-core/2.10.0/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.10.0/akka-actor_2.13-2.10.0.pom  ### When everything is on https://repo.akka.io/maven   - [x] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.10.0`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add libraries/akka-core/current libraries/akka-core/2.10.0          git add api/akka-core/current api/akka-core/2.10.0          git add japi/akka-core/current japi/akka-core/2.10.0          git commit -m ""Akka 2.10.0""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [x] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/libraries/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [x] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [x] Update sbt new templates:   - [x] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,sebastian-alfers
32546,patriknw,2024-10-01T15:26:48Z,2024-10-02T11:40:21Z,patriknw,,Release 2.7.1,"Release Akka 2.7.1  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.7.1=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] Update the version and change date in the LICENSE file. - [ ] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.7.1 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [ ] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.7.1`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.7.1/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.7.1/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.7.1/)  ### When everything is on maven central   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.7.1`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.7.1          git add api/akka/current api/akka/2.7.1          git add japi/akka/current japi/akka/2.7.1          git commit -m ""Akka 2.7.1""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,patriknw
32545,patriknw,2024-10-01T15:24:42Z,2024-10-02T11:38:57Z,patriknw,,Release 2.8.7,"Release Akka 2.8.7  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.7=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.7 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [ ] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [ ] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.7`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.7/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.7/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.7/)  ### When everything is on maven central   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.7`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.7          git add api/akka/current api/akka/2.8.7          git add japi/akka/current japi/akka/2.8.7          git commit -m ""Akka 2.8.7""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,patriknw
32540,patriknw,2024-10-01T14:11:00Z,2024-10-03T14:50:37Z,patriknw,,Release 2.9.6,"Release Akka 2.9.6  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.6=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [x] Update the version and change date in the LICENSE file. - [x] Update the Akka version in the samples to 2.9.6  otherwise the published zip files of the samples will have the old version. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.9.6 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [ ] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.6`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.9.6/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.9.6/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.9.6/akka-actor_2.13-2.9.6.pom  ### When everything is on https://repo.akka.io/maven   - [x] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.6`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.6          git add api/akka/current api/akka/2.9.6          git add japi/akka/current japi/akka/2.9.6          git commit -m ""Akka 2.9.6""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/docs/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [x] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update sbt new templates:   - [x] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,patriknw
32517,goshacodes,2024-09-14T12:11:11Z,2024-09-15T17:43:13Z,goshacodes,,Publish akka-http 10.2 with scala 3 support,"Hello  we are bound to use opensource akka  and we can't migrate to scala 3 since opensource akka has no scala 3 support. Is there any possibility that you add such an artifact? ",,goshacodes
32511,sebastian-alfers,2024-09-09T08:43:20Z,2024-09-09T12:10:36Z,johanandren,,scala-2.13+ source directory,,,johanandren
32507,vantersy,2024-09-06T03:12:41Z,2024-09-06T10:42:51Z,vantersy,vantersy,ShardRgion actor triggers postStop for unknown reasons  how to investigate the cause？,"![微信图片_20240906111122](https://github.com/user-attachments/assets/b4368486-1d24-4d0a-b8e2-8cbd4cb70d5a) ",,vantersy
32505,patriknw,2024-09-05T14:31:17Z,2024-09-17T13:34:38Z,patriknw,patriknw,Update Jackson dependency to 2.17.x,https://github.com/FasterXML/jackson/wiki/Jackson-Releases,,patriknw
32503,johanandren,2024-09-04T13:06:25Z,2024-09-06T07:22:27Z,johanandren,johanandren,Slf4j 2 bump broke native image,https://github.com/akka/akka/actions/runs/10692661610/job/29641494226,,johanandren
32501,sebastian-alfers,2024-09-03T13:51:46Z,2024-09-05T14:25:37Z,patriknw,sebastian-alfers; johanandren,try to remove akka.util.JavaDurationConverters,,,sebastian-alfers; johanandren
32500,sebastian-alfers,2024-09-02T14:23:10Z,2024-09-09T14:33:03Z,johanandren,sebastian-alfers; patriknw,deprecate logger ops  only needed for Scala 2.12,,,sebastian-alfers; patriknw
32498,sulo-genius,2024-09-02T11:26:50Z,2024-09-03T15:12:00Z,johanandren,sulo-genius; johanandren,Asktimeouts happening everytime there is scaling based on cpu usage,"Hi  Currently clusters are configured in a way that is scales up/down based on cpu usage  However  everytime this happens we are observing asktimeouts for short duration. Can this be avoided? ",,sulo-genius; johanandren
32488,johanandren,2024-08-28T12:41:35Z,2024-08-28T14:39:45Z,johanandren,,Failed: AeronErrorLog.java:26:18: cannot access org.agrona.DirectBuffer,"I think we merged some bump where agrona is built for newer JDKs than 11 without noticing:  ``` [08-25 00:11:29.514] [error] /home/runner/work/akka/akka/akka-remote/src/main/java/akka/remote/artery/aeron/AeronErrorLog.java:26:18: cannot access org.agrona.DirectBuffer [08-25 00:11:29.514] [error]   bad class file: /home/runner/.cache/coursier/v1/https/repo1.maven.org/maven2/org/agrona/agrona/1.23.0/agrona-1.23.0.jar(/org/agrona/DirectBuffer.class) [08-25 00:11:29.514] [error]     class file has wrong version 61.0  should be 55.0 [08-25 00:11:29.514] [error]     Please remove or make sure it appears in the correct subdirectory of the classpath. [08-25 00:11:29.514] [error] org.agrona.DirectBuffer [08-25 00:11:29.515] [error]                  ^ [08-25 00:11:29.516] [error] /home/runner/work/akka/akka/akka-remote/src/main/java/akka/remote/artery/aeron/AeronErrorLog.java:27:18: cannot access org.agrona.IoUtil [08-25 00:11:29.516] [error]   bad class file: /home/runner/.cache/coursier/v1/https/repo1.maven.org/maven2/org/agrona/agrona/1.23.0/agrona-1.23.0.jar(/org/agrona/IoUtil.class) [08-25 00:11:29.516] [error]     class file has wrong version 61.0  should be 55.0 [08-25 00:11:29.516] [error]     Please remove or make sure it appears in the correct subdirectory of the classpath. [08-25 00:11:29.516] [error] org.agrona.IoUtil [08-25 00:11:29.516] [error]                  ^ [08-25 00:11:29.517] [error] /home/runner/work/akka/akka/akka-remote/src/main/java/akka/remote/artery/aeron/AeronErrorLog.java:28:29: cannot access org.agrona.concurrent.AtomicBuffer [08-25 00:11:29.517] [error]   bad class file: /home/runner/.cache/coursier/v1/https/repo1.maven.org/maven2/org/agrona/agrona/1.23.0/agrona-1.23.0.jar(/org/agrona/concurrent/AtomicBuffer.class) [08-25 00:11:29.517] [error]     class file has wrong version 61.0  should be 55.0 [08-25 00:11:29.517] [error]     Please remove or make sure it appears in the correct subdirectory of the classpath. [08-25 00:11:29.517] [error] org.agrona.concurrent.AtomicBuffer [08-25 00:11:29.517] [error]                             ^ [08-25 00:11:29.518] [error] /home/runner/work/akka/akka/akka-remote/src/main/java/akka/remote/artery/aeron/AeronErrorLog.java:29:36: cannot access org.agrona.concurrent.errors.ErrorLogReader [08-25 00:11:29.518] [error]   bad class file: /home/runner/.cache/coursier/v1/https/repo1.maven.org/maven2/org/agrona/agrona/1.23.0/agrona-1.23.0.jar(/org/agrona/concurrent/errors/ErrorLogReader.class) [08-25 00:11:29.518] [error]     class file has wrong version 61.0  should be 55.0 [08-25 00:11:29.518] [error]     Please remove or make sure it appears in the correct subdirectory of the classpath. [08-25 00:11:29.518] [error] org.agrona.concurrent.errors.ErrorLogReader [08-25 00:11:29.518] [error]                                    ^ [08-25 00:11:30.103] [error] /home/runner/work/akka/akka/akka-remote/src/main/java/akka/remote/artery/aeron/AeronErrorLog.java:40:9: cannot find symbol [08-25 00:11:30.103] [error]   symbol:   class AtomicBuffer [08-25 00:11:30.103] [error]   location: class akka.remote.artery.aeron.AeronErrorLog [08-25 00:11:30.103] [error] AtomicBuffer [08-25 00:11:30.103] [error]         ^ ```",,johanandren
32482,patriknw,2024-08-19T08:23:23Z,2024-08-19T12:30:19Z,patriknw,,Release 2.9.5,"Release Akka 2.9.5  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.5=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [x] Update the version and change date in the LICENSE file. - [x] Update the Akka version in the samples to 2.9.5  otherwise the published zip files of the samples will have the old version. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.9.5 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.5`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.9.5/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.9.5/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [ ] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.9.5/akka-actor_2.13-2.9.5.pom  ### When everything is on https://repo.akka.io/maven   - [x] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.5`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.5          git add api/akka/current api/akka/2.9.5          git add japi/akka/current japi/akka/2.9.5          git commit -m ""Akka 2.9.5""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [x] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/docs/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update sbt new templates:   - [x] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,patriknw
32475,nathanmbrown,2024-08-10T16:40:51Z,2024-08-13T08:12:34Z,johanandren,,`EventSourcedRememberEntitiesShardStore` not honouring `max-updates-per-write` setting,"Upon inspection of the [`RememberEntitiesShardStore.Update` handler in `EventSourcedRememberEntitiesShardStore`](https://github.com/akka/akka/blob/aaf7b8748dbd0622db0dbee9c91e1f646497c8e5/akka-cluster-sharding/src/main/scala/akka/cluster/sharding/internal/EventSourcedRememberEntitiesShardStore.scala#L94) it appears that the code is not doing what was originally intended in #29233. It appears the `events` list will only ever contain 1 `EntitiesStarted` and/or 1 `EntitiesRemoved` each with the ids of all the entities started or removed  irrespective of their count.  The later code that was intended to split the entities across multiple writes thus takes no notice of the number of entities in each of those events and thus `max-updates-per-write` will not have any effect. This means with a large number of simultaneous entity activations or deactivations the journal could receive huge events to persist.",akka-cluster-sharding/src/main/scala/akka/cluster/sharding/internal/EventSourcedRememberEntitiesShardStore.scala; akka-cluster-sharding/src/test/scala/akka/cluster/sharding/internal/RememberEntitiesShardStoreSpec.scala,nathanmbrown
32464,Roiocam,2024-07-05T01:48:25Z,2024-07-10T13:38:21Z,octonato,octonato,sbt task `sortImports` has been removed.,"<!-- Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka HTTP: https://github.com/akka/akka-http/issues  - Alpakka:   https://github.com/akka/alpakka/issues  - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your issue precisely  and if possible provide a reproducer snippet (this helps resolve issues much quicker).  Thanks  happy hakking! --> After #31996  the sortImport has been removed.  ``` [IJ]akka > sortImports [error] Not a valid command: sortImports [error] Not a valid project ID: sortImports [error] Expected ':' [error] Not a valid key: sortImports [error] sortImports [error]            ^ [IJ]akka >  ```   ",,octonato
32458,johanandren,2024-06-27T11:05:10Z,2024-08-13T08:14:23Z,johanandren,johanandren,Old version warning in docs is broken,We have akka-docs/src/main/paradox/assets/js/warnOldVersion.js copied from Alpakka back in https://github.com/akka/akka/pull/32215 but it does not create the right path for the paradox.json file with version info so does not exist  and is blocked by CORS.,,johanandren
32454,sebastian-alfers,2024-06-27T04:59:22Z,2024-09-06T07:41:17Z,sebastian-alfers,johanandren,Release 2.8.6,"Release Akka 2.8.6  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.6=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [x] Update the version and change date in the LICENSE file. - [ ] ~Update the Akka version in the samples to 2.8.6  otherwise the published zip files of the samples will have the old version.~ - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.6 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] ~Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"".~ - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.6`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.6/) documentation - [ ] Check [reference](https://doc.akka.io/docs/akka/2.8.6/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.8.6/akka-actor_2.13-2.8.6.pom  ### When everything is on https://repo.akka.io/maven   - [x] Log into `gustav.akka.io` as `akkarepo`      - [ ] ~If this updates the `current` version  run `./update-akka-current-version.sh 2.8.6`~     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.6          git add api/akka/current api/akka/2.8.6          git add japi/akka/current japi/akka/2.8.6          git commit -m ""Akka 2.8.6""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] ~If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)~   - [ ] ~Update version in _config.yml in https://github.com/akka/akka.io~     ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] ~Send a release notification to [Lightbend discuss](https://discuss.akka.io)~ - [ ] ~Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release~ - [ ] ~Announce internally (with links to Tweet  discuss)~  For minor or major releases:  - [ ] ~Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.~  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/docs/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update sbt new templates:   - [ ] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,johanandren
32440,patriknw,2024-06-19T13:06:37Z,2024-06-20T11:21:21Z,patriknw,,Release 2.9.4,"Release Akka 2.9.4  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.4=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [x] Update the version and change date in the LICENSE file. - [x] Update the Akka version in the samples to 2.9.4  otherwise the published zip files of the samples will have the old version. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.9.4 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.4`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.9.4/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.9.4/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.9.4/akka-actor_2.13-2.9.4.pom  ### When everything is on https://repo.akka.io/maven   - [x] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.4`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.4          git add api/akka/current api/akka/2.9.4          git add japi/akka/current japi/akka/2.9.4          git commit -m ""Akka 2.9.4""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [x] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/docs/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update sbt new templates:   - [x] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,patriknw
32436,johanandren,2024-06-11T06:44:30Z,2024-06-11T11:40:18Z,johanandren,,Supervising ActorInitializationException broken when error is from preStart,"Reproducer shared in https://discuss.lightbend.com/t/expected-behavior-when-child-actor-throws-an-exception-during-pre-start/10753/3 (needs some fixes before it compiles).  ",,johanandren
32415,johanandren,2024-05-08T14:08:50Z,2024-05-08T14:35:22Z,patriknw,patriknw; johanandren,Allow initial timer delay to be 0,"              This works  but why do we need single+concat? Wouldn't an initial delay of 0 be enough? Alright  initial delay isn't allowed to be 0? Wonder if we shouldn't allow initial 0 and also allow 0 for scheduleOnce?  _Originally posted by @patriknw in https://github.com/akka/akka-persistence-jdbc/pull/834#discussion_r1594094489_  In https://github.com/akka/akka/pull/32275 we changed so that both initial and subsequent delay must be > 0  but the problem of busy-looping is only for the subsequent  we could allow the initial delay to be 0 still.             ",,patriknw; johanandren
32409,johanandren,2024-05-07T08:01:43Z,2024-05-17T11:59:37Z,johanandren,johanandren,Release 2.9.3,"Release Akka 2.9.3  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.3=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [x] Update the version and change date in the LICENSE file. - [x] Update the Akka version in the samples to 2.9.3  otherwise the published zip files of the samples will have the old version. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.9.3 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [ ] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.3`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.9.3/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.9.3/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.9.3/akka-actor_2.13-2.9.3.pom  ### When everything is on https://repo.akka.io/maven   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.3`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.3          git add api/akka/current api/akka/2.9.3          git add japi/akka/current japi/akka/2.9.3          git commit -m ""Akka 2.9.3""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [x] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/docs/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [x] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update sbt new templates:   - [x] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka HTTP Java](https://github.com/akka/akka-http-quickstart-java.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka gRPC Java](https://github.com/akka/akka-grpc-quickstart-java.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,johanandren
32408,johanandren,2024-05-07T08:00:58Z,2024-05-07T08:01:28Z,johanandren,johanandren,Release 2.9.2,"Release Akka 2.9.2  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.2=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [ ] Check that open PRs and issues assigned to the milestone are reasonable - [ ] If PRs were merged after EU midnight  trigger the [native-image tests](https://github.com/akka/akka/actions/workflows/native-image-tests.yml) and see that they are green. - [ ] Update the version and change date in the LICENSE file. - [ ] Update the Akka version in the samples to 2.9.2  otherwise the published zip files of the samples will have the old version. - [ ] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [ ] Close the [2.9.2 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [ ] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [ ] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [ ] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.2`  title and release description. Use the `Publish release` button  which will create the tag. - [ ] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [ ] Check [API](https://doc.akka.io/api/akka/2.9.2/) documentation - [ ] Check [reference](https://doc.akka.io/docs/akka/2.9.2/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [ ] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.9.2/akka-actor_2.13-2.9.2.pom  ### When everything is on https://repo.akka.io/maven   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.2`     - [ ] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.2          git add api/akka/current api/akka/2.9.2          git add japi/akka/current japi/akka/2.9.2          git commit -m ""Akka 2.9.2""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/docs/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update sbt new templates:   - [ ] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka HTTP Java](https://github.com/akka/akka-http-quickstart-java.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka gRPC Java](https://github.com/akka/akka-grpc-quickstart-java.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,johanandren
32381,Lovecxgood,2024-04-16T09:40:41Z,2024-04-21T13:59:46Z,Lovecxgood,Lovecxgood; johanandren,find a bug when using scheduler(),"ctx.getSystem().scheduler().scheduleOnce(Duration.ofMillis(22460288495L)  () -> { 	System.err.println(""*************""); }  ctx.getSystem()));  I using akka scheduler meet a problem when the delay time is too big all the actor will auto stop as the same as scheduler().scheduleAtFixedRate(delayTime ()->{})  ",,Lovecxgood; johanandren
32380,He-Pin,2024-04-15T18:16:30Z,2024-04-17T09:33:03Z,octonato,He-Pin; octonato,Source.fromJavaStream can use SplitIterator directly,"Motivation: The current Source.fromJavaStream should be using `stream.iterator`  as the code in pekko  I think it can be updated to make use of the splitIterator directly  because the `stream.iterator` just a wrapper around the `splititerator`.  Result: Less allocation.  If this is acceptble in akka I would like to send a PR.",akka-stream-tests/src/test/scala/akka/stream/scaladsl/StreamConvertersSpec.scala; akka-stream/src/main/scala/akka/stream/impl/JavaStreamSource.scala,johanandren
32379,johanandren,2024-04-11T16:41:03Z,2024-04-18T08:35:35Z,johanandren,patriknw; johanandren,Specifying ClusterSingletonManagerSettings programatically in typed not possible,I could be missing something but I can't find anywhere it is possible to specify `akka.cluster.typed.ClusterSingletonManagerSettings` when setting up a typed singleton. We do have API in typed sharding accepting it to configure the coordinator singleton though.,,patriknw; johanandren
32378,cnrainbing,2024-04-09T06:05:23Z,2024-04-09T06:59:06Z,johanandren,,Is it great that akka can be used as a public chain?,Is it great that akka can be used as a public chain?,,johanandren
32376,LetAmericaGreatAgain,2024-04-08T03:44:24Z,2024-04-08T09:25:49Z,johanandren,johanandren,How can I resolve the CORS issue?,"I am using Java and my akka http dependency is as follows:  xml <!-- https://mvnrepository.com/artifact/com.typesafe.akka/akka-http -->   <dependency>       <groupId>com.typesafe.akka</groupId>       <artifactId>akka-http_3</artifactId>       <version>10.6.0-M1</version>   </dependency> On the official website  I read that ""The directive uses config defined under akka.http.cors  or an explicitly provided CorsSettings instance."" However  I cannot find the akka.http.cors package. How can I resolve the CORS issue?",,johanandren
32372,johanandren,2024-04-02T07:09:13Z,2024-04-24T15:49:59Z,johanandren,,NotInfluenceReceiveTimeout does not work consistently with typed responses,When using typed context ask or response adapter we internally wrap response messages in a `AdaptWithRegisteredMessageAdapter` which is what the actor actually receives via inbox  if the message is marked with a `NotInfluenceReceiveTimeout` that does not have any effect and the response still affects the receive timeout.,akka-actor-typed-tests/src/test/scala/akka/actor/typed/ReceiveTimeoutSpec.scala; akka-actor/src/main/scala/akka/actor/ActorRef.scala; akka-actor/src/main/scala/akka/actor/dungeon/ReceiveTimeout.scala,johanandren
32367,dodnert,2024-03-25T17:11:01Z,2024-04-05T11:03:21Z,johanandren,johanandren,Scaladoc description of Source.cycle is confusing and should be clarified,"The current Scaladoc description of `Source.cycle` is as follows:  > Creates [[Source]] that will continually produce given elements in specified order. Starts a new 'cycled' `Source` from the given elements. The producer stream of elements will continue infinitely by repeating the sequence of elements provided by function parameter.  This is confusing documentation because it is unclear whether the intended behavior is that the function `f` passed to `cycle` will be called just once to produce an `Iterator` and that particular order will be cycled repeatedly  or is `f` invoked repeatedly after the elements from the previous invocation have been exhausted. I see that the implementation does the latter.  Also  it would be helpful to explicitly add that if `f` returns an empty `Iterator`  then the `Source` is terminated with an error.  Here is my suggested replacement for the function description.  > Create a [[Source]] that will continually produce elements in the order they are provided. The elements in the stream are determined by invoking the given function `f` to obtain an iterator. The function `f` is invoked repeatedly  as elements from the previous invocation are exhausted. The [[Source]] fails if `f` returns an empty iterator. ",,johanandren
32364,patriknw,2024-03-25T08:19:47Z,2024-09-25T14:58:08Z,patriknw,ennru; patriknw; johanandren,Update to slf4j 2.0,"Sl4fj 2.0 is not fully backwards compatible. We made a workaround in https://github.com/akka/akka/pull/31825 to make it work with both. We have been holding back to update the dependency to 2.0 so that Akka wouldn't enforce all downstream projects to bump to later slf4j.  Sooner or later we will have to update  but no decision on when we will do that yet. Important that we make that change in all Akka projects at the same time to avoid confusion.  We have already seen that 2.0 is brought in by transitive dependencies of external libraries. akka-persistence-jdbc and the Slick dependency is one such  and we pinned slf4j to 1.7.36. Remember to remove that when we update.  ",,ennru; patriknw; johanandren
32359,aludwiko,2024-03-21T12:26:41Z,2025-02-14T09:45:42Z,sebastian-alfers,aludwiko; patriknw; sebastian-alfers; johanandren,EventSourcedBehavior.lastSequenceNumber incorrect values after recovery,"Calling `EventSourcedBehavior.lastSequenceNumber` in the event handler returns incorrect value after entity recovery: Example for a new entity: ``` cmd handler: 0 evt handler: 0  cmd handler: 1 evt handler: 2  cmd handler: 2 evt handler: 3 ``` After recovery: ``` evt handler: 1 evt handler: 2 evt handler: 3  cmd handler: 3 evt handler: 3  cmd handler: 4 evt handler: 5 ```  When debugging  I've noticed that instead of the first event handler (after recovery) will still use `akka.persistence.typed.internal.ReplayingEvents#currentSequenceNumber`  and the following one will switch to `akka.persistence.typed.internal.Running.HandlingCommands#currentSequenceNumber`.  ",,aludwiko; patriknw; sebastian-alfers; johanandren
32344,sebastian-alfers,2024-03-14T14:00:52Z,2024-03-22T16:03:45Z,octonato,,Issue with rending DurableState docs on how to write custom plugin,"Rendering issue for https://doc.akka.io/docs/akka/current/durable-state/state-store-plugin.html  <img width=""806"" alt=""Screenshot 2024-03-14 at 14 59 53"" src=""https://github.com/akka/akka/assets/546816/899beaf6-9f83-4e73-9745-f546f3231548""> ",,octonato
32339,johanandren,2024-03-08T09:55:40Z,2024-04-12T08:07:15Z,patriknw,johanandren,Support PKCS8 and ECDSA,">One thing that I would probably consider with a higher priority is supporting keys other than RSA. ECDSA is the main one that is replacing RSA. > > Support ECDSA means adding support for two different formats. Firstly  there's the OpenSSL ASN.1 encoding of ECDSA keys  which is identified with `BEGIN EC PRIVATE KEY`. We already do ASN.1 parsing of RSA keys  we should be able to do it for ECDSA keys too  I think they only have two things encoded in them  the curve  and the key. The bouncycastle parsing is here: https://github.com/bcgit/bc-java/blob/main/core/src/main/java/org/bouncycastle/asn1/sec/ECPrivateKey.java > > Secondly  there's the PKCS8 encoding  identified as `BEGIN PRIVATE KEY`  which is used for all PKCS8 encoded keys  including RSA  ECDSA and Ed25519. The JDK has built in support for parsing ECDSA (and other) keys from PKCS8  what the JDK doesn't provide though is a means to check the type of key encoded in a PKCS8 sequence of bytes  you have to know the type up front  which is  in true JDK crypto key API fashion  not very helpful. But  again  this can be done using an ASN.1 parsing. Here's the [RFC for PKCS8](https://datatracker.ietf.org/doc/html/rfc5208)  so you want to extract out that algrothim identifier (and maybe validate the version). I think [this is the RFC for the algorithm identifier](https://datatracker.ietf.org/doc/html/rfc3279).  _Originally posted by @jroper in https://github.com/akka/akka-http/issues/4359#issuecomment-1979764279_  I _think_ this would go in akka-pki and not anything akka-http specific.",,johanandren
32337,shaoshuaidu,2024-03-02T17:57:48Z,2024-03-04T11:14:19Z,johanandren,shaoshuaidu; johanandren, cannot find symbol   symbol:   class Greet,"Hi  everyone! I am new to java and akka  I try to run akka-quickstart-java demo but this  error keeps happen. Mybe this problem happens due to the java version. But I work on a supercomputer cluster so I am not able to update the java8 to 11 or 17. Anyone can help me with this problem? thank you in advance.  [ERROR] COMPILATION ERROR :  [INFO] ------------------------------------------------------------- [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[10 54] cannot find symbol   symbol:   class Greet   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/GreeterBot.java:[6 57] cannot find symbol   symbol:   class Greeted   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/GreeterBot.java:[8 35] cannot find symbol   symbol:   class Greeted   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/GreeterBot.java:[15 44] cannot find symbol   symbol:   class Greeted   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/GreeterBot.java:[21 27] cannot find symbol   symbol:   class Greeted   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/GreeterBot.java:[25 56] cannot find symbol   symbol:   class Greeted   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/GreeterBot.java:[25 29] cannot find symbol   symbol:   class Greeted   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[12 52] cannot find symbol   symbol:   class Greeted   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[12 17] cannot find symbol   symbol:   class record   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[13 54] cannot find symbol   symbol:   class Greet   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[13 17] cannot find symbol   symbol:   class record   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[15 26] cannot find symbol   symbol:   class Greet   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[19 32] cannot find symbol   symbol:   class Greet   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[24 18] cannot find symbol   symbol:   class Greet   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[28 35] cannot find symbol   symbol:   class Greet   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[28 20] cannot find symbol   symbol:   class Greet   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/GreeterMain.java:[17 35] cannot find symbol   symbol:   class Greet   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/GreeterBot.java:[22 53] cannot find symbol   symbol:   class Greeted   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/GreeterBot.java:[31 44] cannot find symbol   symbol:   class Greet   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[25 42] cannot find symbol   symbol:   class Greet   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/Greeter.java:[31 32] cannot find symbol   symbol:   class Greeted   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/GreeterMain.java:[37 25] cannot find symbol   symbol:   class Greeted   location: class $package$.Greeter [ERROR] /home/sdu/dss_git/akka-quickstart-java.g8/src/main/g8/src/main/java/$package$/GreeterMain.java:[39 33] cannot find symbol   symbol:   class Greet   location: class $package$.Greeter [INFO] 23 errors  [INFO] ------------------------------------------------------------- [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE",,shaoshuaidu; johanandren
32332,johanandren,2024-02-27T12:50:38Z,2024-04-22T12:46:26Z,johanandren,,Release 2.9.2,"Release Akka 2.9.2  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.2=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.9.2 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.2`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.9.2/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.9.2/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.9.2/akka-actor_2.13-2.9.2.pom  ### When everything is on https://repo.akka.io/maven   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.2`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.2          git add api/akka/current api/akka/2.9.2          git add japi/akka/current japi/akka/2.9.2          git commit -m ""Akka 2.9.2""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) and version for [Akka module versions](https://doc.akka.io/docs/akka-dependencies/current/) in [akka-dependencies repo](https://github.com/akka/akka-dependencies) - [x] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - [ ] Update quickstarts:   - [x] [Akka Java](https://github.com/akka/akka-quickstart-java.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka HTTP Java](https://github.com/akka/akka-http-quickstart-java.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka gRPC Java](https://github.com/akka/akka-grpc-quickstart-java.g8/blob/main/src/main/g8/default.properties)   - [x] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,johanandren
32330,Roiocam,2024-02-27T06:42:09Z,2024-02-27T12:59:07Z,johanandren,Roiocam,AskPattern won't use`refPrefix` sometime.,"We use ActorPath to detect the source of the Actor.  In my case  the actor is partly from SourceActor and partly from the temporary Actor produced by AskPattern. We want to ensure that this logic is correct through the unit test.  These unit test look like:  ```diff ActorRef<Object> sourceRef = spawn(echoBehavior  ""source""); CompletionStage<Message> ask = AskPattern.ask(         sourceRef          reply -> { +           System.out.println(reply.toString());             return new Message(reply);         }          Duration.ofSeconds(1)          getSystem().scheduler() );  Message reply = ask.toCompletableFuture().join(); Assert.assertTrue(reply.getActorRef().path().toString().contains(""source"")); ```  As the title shows  when`messageFactory` lacks STDOUT code(which the line of diff shows)  the unit test fails  and the path of ActorRef is: `akka://test/temp/$a#0`  But after adding STDOUT into `messageFactory`  things turn to a different way: the unit test passed  and the path of ActorRef is `akka://test/temp/source$a#0`  This is a reproduction: https://gist.github.com/Roiocam/3f74b2078bd6caf1bdb5f8a18df56788 ",,Roiocam
32329,patriknw,2024-02-23T17:47:27Z,2024-02-26T17:54:59Z,johanandren,johanandren,failed: Native image tests - NoSuchElementException,"https://github.com/akka/akka/actions/runs/7989482895/job/21816139834  ``` java.util.NoSuchElementException: key not found: groupId 	at scala.collection.MapOps.default(Map.scala:274) 	at scala.collection.MapOps.default$(Map.scala:273) 	at scala.collection.AbstractMap.default(Map.scala:405) 	at scala.collection.MapOps.apply(Map.scala:176) 	at scala.collection.MapOps.apply$(Map.scala:175) 	at scala.collection.AbstractMap.apply(Map.scala:405) 	at com.fasterxml.jackson.module.scala.JacksonModule$.version$lzycompute(JacksonModule.scala:27) ```  @johanandren maybe this is already fixed?",,johanandren
32328,johanandren,2024-02-23T14:26:55Z,2024-04-05T11:03:10Z,johanandren,patriknw; johanandren,Set Jackson USE_PROPERTIES_BASED to no longer need @JsonCreator,"While digging into native image Jackson stuff I stumbled over `ObjectMapper#setConstructorDetector(ConstructorDetector.USE_PROPERTIES_BASED)` which seems to behave as you'd expect/want for single field classes out of the box  so no annotation needed for `case class Example(singleField: String)`.  We'd need to investigate but seems convenient if it doesn't have any negatives for normal usage.  Source article: https://cowtowncoder.medium.com/jackson-2-12-most-wanted-3-5-246624e2d3d0",,patriknw; johanandren
32309,johanandren,2024-02-16T13:27:20Z,2024-09-09T15:44:36Z,sebastian-alfers,patriknw,Simplify flight recorder interactions,When we still supported JDK 8 we had to dynamically avoid interacting with JFR APIs since not always available  now that we don't anymore we can simplify and just use JFR APIs directly (or with less in-between glue). In akka-actor-typed  akka-remote  and akka-cluster-sharding.,,patriknw
32307,johanandren,2024-02-13T10:19:23Z,2024-05-07T09:11:46Z,patriknw,,Circuit breaker registry usage requires ExtendedActorSystem,`CircuitBreaker.lookup(id  system)` and `CircuitBreaker(id)(implicit system)` expects `ExtendedActorSystem` so requires an explicit cast for normal usage. Should just request a `ClassicActorSystemProvider` for easy usage across classic and typed.,,patriknw
32304,Roiocam,2024-02-01T07:19:38Z,2024-02-01T14:58:17Z,Roiocam,Roiocam,[doc] Stream Fan In/Out operator missing applied component,"Not familiar Akka stream  Just treat it as a component.(for Source/Flow/Sink)  <img width=""425"" alt=""截屏2024-02-01 15 13 43"" src=""https://github.com/akka/akka/assets/26020358/b99087ce-ac19-4d2f-9497-e445fb945bb1""> <img width=""355"" alt=""截屏2024-02-01 15 13 46"" src=""https://github.com/akka/akka/assets/26020358/c4af686e-ecd2-447a-861a-31d5193c8306"">  ",,Roiocam
32300,mkurz,2024-01-28T16:29:43Z,2024-01-29T15:05:20Z,mkurz,mkurz,sbt-publish-rsync not on maven central yet (the last one! ;),"When  - #32298 and - #32299  are merged  there is just https://github.com/akka/akka/blob/62159d963fcacc47e0daa65fb2e1965488bfa110/project/plugins.sbt#L20 which is not available on maven central yet.  I started to block [repo.scala-sbt.org](http://repo.scala-sbt.org/) and [repo.typesafe.com](http://repo.typesafe.com/) in my `/etc/hosts` and also removed all artifacts from those libraries from my local cache  and when removing `sbt-publish-rsync` above  I am able to build and test akka and also akka-http (see https://github.com/akka/akka-http/pull/4347) locally.  I guess it is in your interest to get this last library moved to maven central in case one of the above mentioned repos goes down again.  There is an open issue already:  - https://github.com/lightbend/sbt-publish-rsync/issues/6  I am not going to work on this  I just wanted to let you know  since I did some work around the community to move away from those deprecated repos.",,mkurz
32272,luzhongjian,2023-12-28T08:27:57Z,2024-01-02T10:58:18Z,johanandren,johanandren,Stackoverflow in ByteString,"<!-- Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka HTTP: https://github.com/akka/akka-http/issues  - Alpakka:   https://github.com/akka/alpakka/issues  - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your issue precisely  and if possible provide a reproducer snippet (this helps resolve issues much quicker).  Thanks  happy hakking! -->  I have developed and run a project with akka 2.6  scala 2.12  java 1.8 for several years. Recently the load of the system has been getting heavier  I would want to improve the performance by upgrading to more modern akka: akka 2.9.1  scala 2.13  java 17. After I changed some codes to pass compilation to adapt the new version configuration and run the project in production environment. It  crashes every few minutes. The log shows a stackoverflow exception raised. The log has a huge amount of lines repeating as below.  ``` at akka.util.ByteStringBuilder.addAll(ByteString.scala:1076) at scala.collection.mutable.Growable.$plus$plus$eq(Growable.scala:69) at scala.collection.mutable.Growable.$plus$plus$eq$(Growable.scala:69) at akka.util.ByteStringBuilder.addAll(ByteString.scala:1187) at akka.util.ByteStringBuilder.addAll(ByteString.scala:1076)  ``` Unfornately  the log file does not show the exact place in my code where the exception is raised. [build.sbt.txt](https://github.com/akka/akka/files/13784609/build.sbt.txt)  I attached a build.sbt for you to bettern understand what versions of componets I am using.  Thanks for your talented work. ",akka-actor-tests/src/test/scala/akka/util/ByteStringSpec.scala; akka-actor/src/main/scala-2.13/akka/util/ByteString.scala; akka-actor/src/main/scala-3/akka/util/ByteString.scala,johanandren
32271,Roiocam,2023-12-28T06:46:54Z,2024-01-22T12:02:08Z,johanandren,johanandren,Actor system cannot be terminated when scheduling 0 delay task,"<!-- Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka HTTP: https://github.com/akka/akka-http/issues  - Alpakka:   https://github.com/akka/alpakka/issues  - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your issue precisely  and if possible provide a reproducer snippet (this helps resolve issues much quicker).  Thanks  happy hakking! -->  akka version:  2.6.20  I am currently know why it will be a deadlock  but i am wonder why `terminate` won't destory a spin timer  and scheduler willing accept a spin task.  case gist link: https://gist.github.com/Roiocam/d317683d54bdbf3afe75b1b945c7f115  and simplified code below(plz ignore those adapter...).  ```java public class DeadlockCase {      ActorSystem classicSystem;      @Before     public void setUp() {         classicSystem = ActorSystem.create(""test"");     }      @After     public void tearDown() throws InterruptedException  TimeoutException {         Await.ready(             classicSystem.terminate()              scala.concurrent.duration.Duration.create(""Inf""));     }       @Test     public void dead_lock_case(){         // unexpected assign with 0         long heartbeatInterval = 0L;          // create an actor and a probe         akka.actor.ActorRef actorRef = classicSystem.actorOf(             Adapter.props(() -> EchoActor.create(heartbeatInterval)));         TestProbe probe = TestProbe.apply(classicSystem);          // mock echo         String msg = ""msg"";         EchoCmd echoCmd = new EchoCmd(msg  Adapter.toTyped(probe.ref()));         actorRef.tell(echoCmd  akka.actor.ActorRef.noSender());          // assert         String reply = probe.expectMsgClass(FiniteDuration.apply(100  TimeUnit.MILLISECONDS) String.class);         // this line never reach         Assert.assertEquals(msg  reply);     }  } ```  AFAIK  java `ScheduledThreadPoolExecutor` will refuse the zero period task.   ",akka-actor/src/main/scala/akka/actor/LightArrayRevolverScheduler.scala; akka-actor/src/main/scala/akka/actor/Scheduler.scala,johanandren
32267,johanandren,2023-12-20T07:59:25Z,2024-01-08T09:14:31Z,johanandren,,Wait for initial subscriber listing in typed pubsub,In GroupRouter we stash messages until we get the listing from the receptionist. It'd make sense to do the same for topics to not always drop immediately published messages.,,johanandren
32264,patriknw,2023-12-18T14:24:56Z,2023-12-19T12:20:17Z,patriknw,,Release 2.9.1,"Release Akka 2.9.1  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.1=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.9.1 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [x] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.1`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.9.1/) documentation - [ ] Check [reference](https://doc.akka.io/docs/akka/2.9.1/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.9.1/akka-actor_2.13-2.9.1.pom  ### When everything is on https://repo.akka.io/maven   - [x] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.1`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.1          git add api/akka/current api/akka/2.9.1          git add japi/akka/current japi/akka/2.9.1          git commit -m ""Akka 2.9.1""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - [ ] Update quickstarts:   - [ ] [Akka Java](https://github.com/akka/akka-quickstart-java.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka Scala](https://github.com/akka/akka-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka HTTP Java](https://github.com/akka/akka-http-quickstart-java.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka HTTP Scala](https://github.com/akka/akka-http-quickstart-scala.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka gRPC Java](https://github.com/akka/akka-grpc-quickstart-java.g8/blob/main/src/main/g8/default.properties)   - [ ] [Akka gRPC Scala](https://github.com/akka/akka-grpc-quickstart-scala.g8/blob/main/src/main/g8/default.properties) - Close this issue ",,patriknw
32203,patriknw,2023-10-23T11:12:47Z,2023-12-19T12:16:41Z,patriknw,,Release 2.9.0,"Release Akka 2.9.0  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.0=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.9.0 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [x] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.0`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to https://repo.akka.io/maven)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.9.0/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.9.0/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on https://repo.akka.io/maven/com/typesafe/akka/akka-actor_2.13/2.9.0/akka-actor_2.13-2.9.0.pom  ### When everything is on https://repo.akka.io/maven   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.0`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.0          git add api/akka/current api/akka/2.9.0          git add japi/akka/current japi/akka/2.9.0          git commit -m ""Akka 2.9.0""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [x] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [x] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,patriknw
32197,Captain1653,2023-10-21T08:44:37Z,2023-10-23T07:30:28Z,Captain1653,Captain1653; johanandren,Cleanup in labels,"I have found many unused and unnecessary labels in the project: * [Merge After 2.6.0 Release](https://github.com/akka/akka/labels/Merge%20After%202.6.0%20Release) * [reviewed](https://github.com/akka/akka/labels/reviewed) * [tested](https://github.com/akka/akka/labels/tested) * [validating](https://github.com/akka/akka/labels/validating) * [wip](https://github.com/akka/akka/labels/wip) (can be used Draft PR) * [stashed PR](https://github.com/akka/akka/labels/stashed%20PR)  Is it worth removing them and maybe some others?",,Captain1653; johanandren
32182,johanandren,2023-10-18T11:15:07Z,2023-10-23T15:58:11Z,johanandren,patriknw; johanandren,Failed: RemoteConnectionSpec,"https://github.com/akka/akka/actions/runs/6554326968/job/17801126975#step:5:905  Related to the latest changes @patriknw ?  ``` [info] - should handle uid collision when connection FROM two systems with same uid *** FAILED *** (7 seconds  181 milliseconds) [info]   UidUnknown was not equal to UidKnown (RemoteConnectionSpec.scala:177) [info]   org.scalatest.exceptions.TestFailedException: [info]   at org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:392) [info]   at org.scalatest.matchers.should.Matchers$AnyShouldWrapper.shouldBe(Matchers.scala:7539) [info]   at akka.remote.artery.RemoteConnectionSpec.$anonfun$new$5(RemoteConnectionSpec.scala:177) ```",akka-remote/src/test/scala/akka/remote/artery/RemoteConnectionSpec.scala; akka-remote/src/test/scala/akka/remote/artery/RemoteConnectionSpec.scala,patriknw
32172,lychko,2023-10-12T19:15:42Z,2023-10-18T08:49:17Z,johanandren,johanandren,Misleading shard handoff timeout message,"Shard handoff timeout message says (see ShardRegion.scala) `s""Waiting additional [${handoffTimeout.toCoarsest}] before stopping the remaining entities."")` while at that moment `StopTimeoutWarningAfter `seconds has already passed. It took me some time to figure out why actual stop happens 5 seconds before the time that message predicts.  Suggestion is to change message accordingly (to `entityHandOffTimeout - StopTimeoutWarningAfter`)",akka-cluster-sharding/src/main/scala/akka/cluster/sharding/Shard.scala; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/ShardRegion.scala; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/Shard.scala; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/ShardRegion.scala,lychko; johanandren
32169,johanandren,2023-10-11T11:04:11Z,2023-10-18T08:51:30Z,johanandren,patriknw,Failed: RemoteConnectionSpec (aeron udp),"https://github.com/akka/akka/actions/runs/6476201087/job/17584535393#step:5:922   ``` [info] - should handle uid collision when connection TO two systems with same uid *** FAILED *** (3 seconds  651 milliseconds) [info]   java.lang.AssertionError: assertion failed: timeout (1 second) during expectMsg while waiting for ping1a [info]   at scala.Predef$.assert(Predef.scala:279) [info]   at akka.testkit.TestKitBase.expectMsg_internal(TestKit.scala:460) [info]   at akka.testkit.TestKitBase.expectMsg(TestKit.scala:446) [info]   at akka.testkit.TestKitBase.expectMsg$(TestKit.scala:446) [info]   at akka.testkit.TestKit.expectMsg(TestKit.scala:955) [info]   at akka.remote.artery.RemoteConnectionSpec.$anonfun$new$2(RemoteConnectionSpec.scala:68) ```",akka-remote/src/test/scala/akka/remote/artery/RemoteConnectionSpec.scala,patriknw
32157,patriknw,2023-10-05T08:40:57Z,2023-12-15T08:00:08Z,johanandren,,Release 2.9.0-M3,"Release Akka 2.9.0-M3  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.0-M3=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [ ] Close the [2.9.0-M3 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.0-M3`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [ ] Check [API](https://doc.akka.io/api/akka/2.9.0-M3/) documentation - [ ] Check [reference](https://doc.akka.io/docs/akka/2.9.0-M3/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [ ] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.9.0-M3/)  ### When everything is on maven central   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.0-M3`     - [ ] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.0-M3          git add api/akka/current api/akka/2.9.0-M3          git add japi/akka/current japi/akka/2.9.0-M3          git commit -m ""Akka 2.9.0-M3""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,johanandren
32136,patriknw,2023-09-27T13:00:47Z,2023-09-27T14:13:16Z,patriknw,,Release 2.9.0-M2,"Release Akka 2.9.0-M2  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.0-M2=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] Update the version and change date in the LICENSE file. - [ ] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.9.0-M2 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.0-M2`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.9.0-M2/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.9.0-M2/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.9.0-M2/)  ### When everything is on maven central   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.0-M2`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.0-M2          git add api/akka/current api/akka/2.9.0-M2          git add japi/akka/current japi/akka/2.9.0-M2          git commit -m ""Akka 2.9.0-M2""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,patriknw
32128,patriknw,2023-09-22T12:36:11Z,2023-09-27T12:58:22Z,patriknw,patriknw; pvlugter,failed: SupervisorSpec,"Strange  this is not looking good  https://github.com/akka/akka/actions/runs/6273505512/job/17037092542?pr=32127#step:5:1771  ``` Uncaught error from thread [SupervisorSpec-akka.actor.default-dispatcher-6]: Update to non-static final field akka.actor.SupervisorSpec$$anon$1.context attempted from a different method (akka$actor$Actor$_setter_$context_$eq) than the initializer method <init>   shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[SupervisorSpec] java.lang.IllegalAccessError: Update to non-static final field akka.actor.SupervisorSpec$$anon$1.context attempted from a different method (akka$actor$Actor$_setter_$context_$eq) than the initializer method <init>  	at akka.actor.SupervisorSpec$$anon$1.akka$actor$Actor$_setter_$context_$eq(SupervisorSpec.scala:222) 	at akka.actor.Actor.$init$(Actor.scala:495) 	at akka.actor.SupervisorSpec$$anon$1.<init>(SupervisorSpec.scala:222) 	at akka.actor.SupervisorSpec.childInstance$lzycompute$1(SupervisorSpec.scala:222) 	at akka.actor.SupervisorSpec.akka$actor$SupervisorSpec$$childInstance$1(SupervisorSpec.scala:222) 	at akka.actor.SupervisorSpec$$anon$2.$anonfun$child$1(SupervisorSpec.scala:242) 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:90) 	at akka.actor.Props.newActor(Props.scala:226) 	at akka.actor.ActorCell.newActor(ActorCell.scala:615) 	at akka.actor.ActorCell.create(ActorCell.scala:642) 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:513) 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:535) 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:295) 	at akka.dispatch.Mailbox.run(Mailbox.scala:230) 	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) 	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290) 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020) Error:  [SECURITY][09/22/2023 11:18:20.658] [SupervisorSpec-akka.actor.default-dispatcher-6] [akka.actor.ActorSystemImpl(SupervisorSpec)] Uncaught error from thread [SupervisorSpec-akka.actor.default-dispatcher-6]: Update to non-static final field akka.actor.SupervisorSpec$$anon$1.context attempted from a different method (akka$actor$Actor$_setter_$context_$eq) than the initializer method <init>   shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[SupervisorSpec] 	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656) 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594) 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) java.lang.IllegalAccessError: Update to non-static final field akka.actor.SupervisorSpec$$anon$1.context attempted from a different method (akka$actor$Actor$_setter_$context_$eq) than the initializer method <init>  	at akka.actor.SupervisorSpec$$anon$1.akka$actor$Actor$_setter_$context_$eq(SupervisorSpec.scala:222) 	at akka.actor.Actor.$init$(Actor.scala:495) 	at akka.actor.SupervisorSpec$$anon$1.<init>(SupervisorSpec.scala:222) 	at akka.actor.SupervisorSpec.childInstance$lzycompute$1(SupervisorSpec.scala:222) 	at akka.actor.SupervisorSpec.akka$actor$SupervisorSpec$$childInstance$1(SupervisorSpec.scala:222) 	at akka.actor.SupervisorSpec$$anon$2.$anonfun$child$1(SupervisorSpec.scala:242) 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:90) 	at akka.actor.Props.newActor(Props.scala:226) 	at akka.actor.ActorCell.newActor(ActorCell.scala:615) 	at akka.actor.ActorCell.create(ActorCell.scala:642) 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:513) 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:535) 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:295) 	at akka.dispatch.Mailbox.run(Mailbox.scala:230) 	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) 	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290) 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020) 	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656) 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594) 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) ```",,patriknw; pvlugter
32126,patriknw,2023-09-21T10:11:00Z,2024-10-31T16:29:55Z,patriknw,sebastian-alfers; ennru; patriknw,Additional cleanup after dropping Scala 2.12,"We should make this cleanup later  probably in Akka 2.10.  - [x] ccompat and akka.compat - [x] #32511 - [x] `unused` shouldn't be needed - [x] #32500 - [ ] and there could be some more  search for 2.12 - [x] drop scala-java8-compat (https://github.com/lightbend/akka-meta/issues/440) - [x] #32501 - [x] drop scala.collection.JavaConverters",,sebastian-alfers; ennru; patriknw
32115,patriknw,2023-09-20T11:01:30Z,2023-09-20T14:57:09Z,patriknw,,Release 2.8.5,"Release Akka 2.8.5  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.5=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.5 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [ ] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.5`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.5/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.5/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.5/)  ### When everything is on maven central   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.5`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.5          git add api/akka/current api/akka/2.8.5          git add japi/akka/current japi/akka/2.8.5          git commit -m ""Akka 2.8.5""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [x] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [x] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [x] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,patriknw
32109,nodefactory-bk,2023-09-19T07:59:30Z,2023-09-20T10:58:55Z,patriknw,leviramsey; nodefactory-bk,AsyncDns hang/deadlock causing permanent timeouts resolving affected names.,"We have run into an issue in our production env where async dns seems to deadlock on some domain names.  When this happens those names will never resolve again and all requests to do so will time out.  Only way to fix is to restart.  We do not use akka-dns directly  we use akka-http and when this happens all requests to such a name will time out every time until the application is restarted.  Logs show attempt to resolve: ``` Resolution request for bad1.example.com Ip(true true) from Actor[akka://sys-prod/system/IO-TCP/selectors/$a/70814#-1379895057] ``` But then nothing else is logged regarding that name from the dns actors.  Which names are affected is completely random.  This problem appeared after switching from akka 2.6.20 to 2.8.4. Although I cannot definitely say it never happened before I've looked through some old logs and can't find an earlier instance.Attached are two log files  one showing a domain failing. The issue starts 2023-09-12 16:06:45.828. (bad.log) The other is from a working name during the same timeframe. (good.log)  [bad1.log](https://github.com/akka/akka/files/12657209/bad1.log) [good1.log](https://github.com/akka/akka/files/12657210/good1.log)   I note that there were two changes to async dns in akka 2.8.1: #31906 and #31926 . I do see in #31926 that there changes made to the caching code and since caches really attract these kinds of issues I'd say that's a good place to start.  I would like to stress that we are unable to reproduce this in a test env. It happens only in a very busy production env and rarely at that  however it does cause us operational problems since it can't be solved without restarting so I would suggest this is a pretty critical issue.  ",,leviramsey; nodefactory-bk
32105,octonato,2023-09-18T09:06:03Z,2023-10-18T09:34:40Z,johanandren,octonato,failed: LineNumberSpec (jdk 17),"https://github.com/akka/akka/actions/runs/6203959191/job/16845381696#step:5:3573  ```scala  [09-16 00:19:36.028] [info]   - must work for larger functions *** FAILED *** (3 milliseconds) [09-16 00:19:36.034] [info]     LineNumberSpecCodeForScala.scala:16-17 did not equal LineNumberSpecCodeForScala.scala:15-17 (LineNumberSpec.scala:23) [09-16 00:19:36.034] [info]     org.scalatest.exceptions.TestFailedException: [09-16 00:19:36.034] [info]     at org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:392) [09-16 00:19:36.034] [info]     at org.scalatest.matchers.should.Matchers.should(Matchers.scala:6956) [09-16 00:19:36.034] [info]     at org.scalatest.matchers.should.Matchers.should$(Matchers.scala:1808) [09-16 00:19:36.034] [info]     at akka.testkit.AkkaSpec.should(AkkaSpec.scala:54) [09-16 00:19:36.034] [info]     at akka.util.LineNumberSpec.f$proxy2$1(LineNumberSpec.scala:23) [09-16 00:19:36.034] [info]     at akka.util.LineNumberSpec.f$proxy8$1$$anonfun$1$$anonfun$2(LineNumberSpec.scala:21) [09-16 00:19:36.034] [info]     at org.scalatest.Transformer.apply$$anonfun$1(Transformer.scala:22) [09-16 00:19:36.034] [info]     at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85) [09-16 00:19:36.034] [info]     at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:31) [09-16 00:19:36.034] [info]     at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104) [09-16 00:19:36.034] [info]     at org.scalatest.Transformer.apply(Transformer.scala:22) [09-16 00:19:36.034] [info]     at org.scalatest.Transformer.apply(Transformer.scala:21) ```  and also  https://github.com/akka/akka/actions/runs/6203959191/job/16845381696#step:5:3641  ```scala [3640](https://github.com/akka/akka/actions/runs/6203959191/job/16845381696#step:5:3641) [09-16 00:19:36.045] [info]   - must work for `def` *** FAILED *** (1 millisecond) [09-16 00:19:36.045] [info]     LineNumberSpecCodeForScala.scala:26-27 did not equal LineNumberSpecCodeForScala.scala:25-27 (LineNumberSpec.scala:32) [09-16 00:19:36.045] [info]     org.scalatest.exceptions.TestFailedException: [09-16 00:19:36.045] [info]     at org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:392) [09-16 00:19:36.045] [info]     at org.scalatest.matchers.should.Matchers.should(Matchers.scala:6956) [09-16 00:19:36.045] [info]     at org.scalatest.matchers.should.Matchers.should$(Matchers.scala:1808) [09-16 00:19:36.045] [info]     at akka.testkit.AkkaSpec.should(AkkaSpec.scala:54) [09-16 00:19:36.045] [info]     at akka.util.LineNumberSpec.f$proxy4$1(LineNumberSpec.scala:32) [09-16 00:19:36.045] [info]     at akka.util.LineNumberSpec.f$proxy8$1$$anonfun$1$$anonfun$4(LineNumberSpec.scala:30) [09-16 00:19:36.045] [info]     at org.scalatest.Transformer.apply$$anonfun$1(Transformer.scala:22) [09-16 00:19:36.045] [info]     at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85) ``` ",,octonato
32093,patriknw,2023-09-07T07:29:23Z,2023-09-20T08:41:18Z,patriknw,patriknw; johanandren,Update to Scala 3.3 in all projects,The Scala 3 version is one of those that we should align across all Akka modules  at least the minor version 3.3.x.,,patriknw; johanandren
32090,He-Pin,2023-09-06T12:18:42Z,2023-09-07T08:24:23Z,johanandren,,Need swtich the case order in Player.scala,"As the all `ServerOp` extends `NetworkOp`  otherwise it will fail when compiles with Scala 3.3.1. ",,johanandren
32088,johanandren,2023-09-06T07:20:43Z,2023-09-11T16:07:41Z,johanandren,He-Pin; jphelp32; johanandren,Reintroduce a way to specify default config for custom materialisers,With the deprecation of the ActorMaterializer API we expected that they canonical way of configuring for example dispatchers would be per stream  but it can definitely be convenient to be able to define default attributes for a separate materializer. I imagine we could do something like allowing a set of default attributes to the additional create/apply factories in `Materializer`,akka-docs/src/main/paradox/stream/stream-flows-and-basics.md; akka-stream-tests/src/test/scala/akka/stream/MaterializerWithAttributesSpec.scala; akka-stream/src/main/mima-filters/2.9.0-M1.backwards.excludes/impl-start-materializer.excludes; akka-stream/src/main/scala/akka/stream/ActorMaterializer.scala; akka-stream/src/main/scala/akka/stream/Materializer.scala; akka-stream/src/main/scala/akka/stream/SystemMaterializer.scala; akka-stream/src/main/scala/akka/stream/impl/MaterializerGuardian.scala,leviramsey
32085,patriknw,2023-09-05T08:26:11Z,2023-09-05T11:35:00Z,patriknw,,Release 2.9.0-M1,"Release Akka 2.9.0-M1  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.9.0-M1=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.9.0-M1 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.9.0-M1`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.9.0-M1/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.9.0-M1/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.9.0-M1/)  ### When everything is on maven central   - [x] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.9.0-M1`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.9.0-M1          git add api/akka/current api/akka/2.9.0-M1          git add japi/akka/current japi/akka/2.9.0-M1          git commit -m ""Akka 2.9.0-M1""          ```     - [ ] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,patriknw
32080,johanandren,2023-08-31T07:59:18Z,2023-12-05T13:28:42Z,patriknw,,Update replicated event sourcing projections docs,"They explicitly refer to events by tag but you'd probably want to do the sliced queries rather  now that we recommend gRPC projections.  I think the bit about using tagging to determine local vs replicated event or have a single (potentially sliced) stream of all events replicated and local still makes sense though.",akka-docs/src/main/paradox/typed/replicated-eventsourcing-db-transport.md; akka-docs/src/main/paradox/typed/replicated-eventsourcing.md,patriknw
32079,johanandren,2023-08-30T13:14:27Z,2023-11-28T10:39:11Z,patriknw,patriknw; johanandren,Failed: Google Compute Engine does not have enough resources,"Failing multi node tests  https://github.com/akka/akka/actions/runs/6019700168/job/16329880460  ``` ERROR: (gcloud.container.clusters.create) Operation [<Operation  clusterConditions: [<StatusCondition  canonicalCode: CanonicalCodeValueValuesEnum(UNAVAILABLE  15)  code: CodeValueValuesEnum(GCE_STOCKOUT  1)  message: 'Try a different location  or try again later: Google Compute Engine does not have enough resources available to fulfill request: us-central1-c.'>]  detail: 'Try a different location  or try again later: Google Compute Engine does not have enough resources available to fulfill request: us-central1-c.'  endTime: '2023-08-30T02:09:16.872106408Z'  error: <Status  code: 14  details: []  message: 'Try a different location  or try again later: Google Compute Engine does not have enough resources available to fulfill request: us-central1-c.'>  name: 'operation-1693361320699-b778c4c6-fef8-4182-892b-b4b06bbdf99a'  nodepoolConditions: []  operationType: OperationTypeValueValuesEnum(CREATE_CLUSTER  1)  progress: <OperationProgress  metrics: [<Metric  intValue: 10  name: 'CLUSTER_CONFIGURING'>  <Metric  intValue: 10  name: 'CLUSTER_CONFIGURING_TOTAL'>]  stages: []>  selfLink: 'https://container.googleapis.com/v1/projects/786223243746/zones/us-central1-c/operations/operation-1693361320699-b778c4c6-fef8-4182-892b-b4b06bbdf99a'  startTime: '2023-08-30T02:08:40.699233607Z'  status: StatusValueValuesEnum(DONE  3)  statusMessage: 'Try a different location  or try again later: Google Compute Engine does not have enough resources available to fulfill request: us-central1-c.'  targetLink: 'https://container.googleapis.com/v1/projects/786223243746/zones/us-central1-c/clusters/akka-multi-node-6019700168'  zone: 'us-central1-c'>] finished with error: Try a different location  or try again later: Google Compute Engine does not have enough resources available to fulfill request: us-central1-c. ```",,patriknw; johanandren
32069,krnkhanna,2023-08-28T13:17:18Z,2023-08-28T16:07:52Z,krnkhanna,leviramsey; krnkhanna,Logger documentation probable issue.,"Should it be context.log.info(""Greeting {} for {}""  n  message.whom)  in place of context.log.info2(""Greeting {} for {}""  n  message.whom)  in the documentation at: https://doc.akka.io/docs/akka/current/typed/actors.html (https://github.com/akka/akka/blob/9745f8857e38ef4b860d7785272103bfc6a868f0/akka-actor-typed-tests/src/test/scala/docs/akka/typed/IntroSpec.scala#L59)?",,leviramsey; krnkhanna
32064,He-Pin,2023-08-27T16:37:26Z,2023-08-28T08:34:55Z,He-Pin,He-Pin; johanandren,Update the gitter channel?,Seems no one is chatting on gitter  should it be replaced to discord room/channel?,,He-Pin; johanandren
32051,wangp-nhlab,2023-08-18T03:00:57Z,2023-08-22T03:37:11Z,wangp-nhlab,wangp-nhlab; johanandren,There are some issues with the ”Streaming TCP“  simple case in the document,"[https://doc.akka.io/docs/akka/current/stream/stream-io.html#accepting-connections-echo-server](url) I followed the tutorial in the documentation  but I am not getting the correct results  ``` import akka.stream.javadsl.*; import akka.NotUsed; import akka.actor.ActorSystem; import akka.util.ByteString; import java.util.concurrent.CompletionStage; import akka.stream.javadsl.Framing; import akka.stream.javadsl.Tcp.*;    public class SimpleStreams {     public static void main(String[] args) {         final ActorSystem system = ActorSystem.create(""QuickStart"");         final Source<IncomingConnection  CompletionStage<ServerBinding>> connections =                 Tcp.get(system).bind(""127.0.0.1""  8881);          connections.runForeach(                 connection -> {                     System.out.println(""New connection from: "" + connection.remoteAddress());                     final Flow<ByteString  ByteString  NotUsed> echo =                             Flow.of(ByteString.class)                                     .via(                                             Framing.delimiter(                                                     ByteString.fromString(""\n"")  256  FramingTruncation.DISALLOW))                                     .map(ByteString::utf8String)                                     .map(s -> s + ""!!!\n"")                                     .map(ByteString::fromString);                      connection.handleWith(echo  system);                 }                  system);     }  } ``` echo -n ""Hello World"" | netcat 127.0.0.1 8881 The correct outcome should be 'Hello World!!!'，but not returning any data.  If I runnetcat 127.0.0.1 8881 first and then echo -n ""Hello World""，Then you will successfully get ”Hello World!!!“.  Is it my mistake  or is there an issue with the document? If it's a document problem  I'm willing to help submit a modification  thanks ",,wangp-nhlab; johanandren
32040,johanandren,2023-08-15T08:32:59Z,2023-08-15T15:43:18Z,johanandren,,Release 2.8.4,"Release Akka 2.8.4  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.4=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.4 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.4`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.4/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.4/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.4/)  ### When everything is on maven central   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.4`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.4          git add api/akka/current api/akka/2.8.4          git add japi/akka/current japi/akka/2.8.4          git commit -m ""Akka 2.8.4""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [x] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [x] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [x] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,johanandren
32036,pvlugter,2023-08-14T05:00:04Z,2023-11-28T10:42:45Z,patriknw,patriknw,Failed: DownAllIndirectlyConnected5NodeSpec,"https://github.com/akka/akka/actions/runs/5851050126/job/15861266105#step:10:22693  ``` [info] [JVM-1] - should down all when indirectly connected combined with clean partition (on node 'node1'  class akka.cluster.sbr.DownAllIndirectlyConnected5NodeSpecMultiJvmNode1) *** FAILED *** (49 seconds  945 milliseconds) [info] [JVM-1]   TreeSet() did not equal Set(akka://DownAllIndirectlyConnected5NodeSpec@test-node1:6000) (DownAllIndirectlyConnected5NodeSpec.scala:107) [info] [JVM-1]   org.scalatest.exceptions.TestFailedException: [info] [JVM-1]   at org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:392) [info] [JVM-1]   at org.scalatest.matchers.should.Matchers$AnyShouldWrapper.should(Matchers.scala:7469) [info] [JVM-1]   at akka.cluster.sbr.DownAllIndirectlyConnected5NodeSpec.$anonfun$new$28(DownAllIndirectlyConnected5NodeSpec.scala:107) [info] [JVM-1]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) [info] [JVM-1]   at akka.testkit.TestKitBase.poll$2(TestKit.scala:331) [info] [JVM-1]   at akka.testkit.TestKitBase.awaitAssert(TestKit.scala:348) [info] [JVM-1]   at akka.testkit.TestKitBase.awaitAssert$(TestKit.scala:320) [info] [JVM-1]   at akka.testkit.TestKit.awaitAssert(TestKit.scala:955) [info] [JVM-1]   at akka.cluster.sbr.DownAllIndirectlyConnected5NodeSpec.$anonfun$new$27(DownAllIndirectlyConnected5NodeSpec.scala:106) [info] [JVM-1]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) [info] [JVM-1]   at akka.testkit.TestKitBase.within(TestKit.scala:417) [info] [JVM-1]   at akka.testkit.TestKitBase.within$(TestKit.scala:405) [info] [JVM-1]   at akka.testkit.TestKit.within(TestKit.scala:955) [info] [JVM-1]   at akka.testkit.TestKitBase.within(TestKit.scala:432) [info] [JVM-1]   at akka.testkit.TestKitBase.within$(TestKit.scala:432) [info] [JVM-1]   at akka.testkit.TestKit.within(TestKit.scala:955) [info] [JVM-1]   at akka.cluster.sbr.DownAllIndirectlyConnected5NodeSpec.$anonfun$new$26(DownAllIndirectlyConnected5NodeSpec.scala:106) [info] [JVM-1]   at akka.remote.testkit.MultiNodeSpec.runOn(MultiNodeSpec.scala:414) [info] [JVM-1]   at akka.cluster.sbr.DownAllIndirectlyConnected5NodeSpec.$anonfun$new$2(DownAllIndirectlyConnected5NodeSpec.scala:105) ```",,patriknw
32026,leviramsey,2023-08-01T16:52:50Z,2023-08-07T06:44:13Z,patriknw,,javadsl for typed Durable State Behavior `Effect.delete()`,#31529 did not implement `javadsl` for the delete effect in durable state.  Since Java doesn't respect the `private[akka]` modifier on `akka.persistence.typed.state.internal.Delete`  a possible workaround until a release with `javadsl.Effect.delete()` would be to directly construct an instance of `akka.persistence.typed.state.internal.Delete` to serve as a deletion effect.,,patriknw
32018,naval2608,2023-07-28T07:40:50Z,2023-08-22T06:15:29Z,patriknw,patriknw,Akka remote TCP configuration are overwritten when SSL is enabled,"Seeing this bug in version 2.6.20   - using https://doc.akka.io/docs/akka/2.6/project/migration-guide-2.5.x-2.6.x.html#remaining-with-classic-remoting-not-recommended- to move to version 2.6.20 from 2.5 - https://doc.akka.io/docs/akka/2.6/project/migration-guide-2.5.x-2.6.x.html#config-library-resolution-change is not working as expected where tcp configs should be copied over to ssl : _**akka.remote.classic.netty.ssl = ${akka.remote.classic.netty.tcp}**_  Repro: - setup ssl using https://docs.oracle.com/cd/E19509-01/820-3503/6nf1il6er/index.html and get akka ssl working. - set the following remote configs:   -  akka.remote.classic.netty.tcp.maximum-frame-size=""512m"" - add breakpoint https://github.com/akka/akka/blob/v2.6.20/akka-remote/src/main/scala/akka/remote/RemoteSettings.scala#L183 ",,patriknw
32015,lolboxen,2023-07-20T16:42:25Z,2023-07-26T09:16:06Z,octonato,He-Pin; octonato,Receive Timeout causes NullPointerException within internals,"Under specific timing conditions  calling `context.cancelReceiveTimeout()` will induce a `NullPointerException` thrown with this stack trace ``` java.lang.NullPointerException: null 	at akka.actor.typed.internal.InterceptorImpl.receive(InterceptorImpl.scala:84) 	at akka.actor.typed.Behavior$.interpret(Behavior.scala:282) 	at akka.actor.typed.Behavior$.interpretMessage(Behavior.scala:238) 	at akka.actor.typed.internal.adapter.ActorAdapter.handleMessage(ActorAdapter.scala:128) 	at akka.actor.typed.internal.adapter.ActorAdapter.aroundReceive(ActorAdapter.scala:93) 	at akka.actor.ActorCell.receiveMessage$$$capture(ActorCell.scala:579) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala) 	at akka.actor.ActorCell.invoke(ActorCell.scala:547) 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) 	at akka.dispatch.Mailbox.run(Mailbox.scala:231) 	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) 	at java.base/java.util.concurrent.ForkJoinTask.doExec$$$capture(ForkJoinTask.java:290) 	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java) 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020) 	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656) 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594) 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) ```  It is my believe the source of this issue is [here](https://github.com/akka/akka/blob/main/akka-actor-typed/src/main/scala/akka/actor/typed/internal/adapter/ActorContextAdapter.scala#L126). The message to be received is nulled out but the `akka.actor.ReceiveTimeout` is still sitting in the mailbox. When the message is then processed by `InterceptorImpl.scala:84` it attempts to call `getClass` on a null object.  This issue was observed with 2.8.3 and 2.6.21.  We have switched to using `Behaviors.withTimers` to get around this issue per the guarantees it makes on cancellations.  [reproducible evidence](https://github.com/lolboxen/akka-receive-timeout-bug)",,He-Pin; octonato
32014,0bon,2023-07-16T22:54:31Z,2023-07-17T09:26:50Z,octonato,octonato,Event Sourcing Issues with EventSourcedBehavior,"When using `EventSourcedBehavior` to persist events (`Effect.persist`)  from what I understand  this persistence mechanism is to internally maintain state and is not for consumption by other microservices.  This introduces a number of issues  since event sourcing is usually applicable to a group of services - those services can access and handle events by subscribing to topics on a message queue.  My current approach is to `Effect.persist(...).thenRun(pushToMessageQueue())` but this is very problematic. What if the MQ is down ? or some other issue emerges that prevents the event from being pushed onto the MQ. This will create data in inconsistencies which can cause serious accumulative effects overtime.  As it currently stands  I am having to build out an elaborate system of retries + using durable states in case the actorsystem crashes  and even then  there are still loopholes which could lead to data inconsistencies.  I think there needs to be a discussion about how this issue can be rectified in a more proper fashion. Below are some thoughts running through my mind:  1. Introduce transactions. If `thenRun` fails then rollback the `persist()` action. Ensuring atomicity is pretty standard with database transactions. Maybe something similar can be implemented here. Either all actions succeed or they all fail. 2. Create persistence plugins for backends that actually support event sourcing i.e. Eventstore. You might say there already is one  but it is outdated and no one from EvenstoreDB is giving it the much needed TLC. Kafka is bad news for ES and EventStore fixes many of the underlying issues and should be supported officially for  `EventSourcedBehavior`.  But in order for this to work the user should be able to define different streams and assign events to them respectively.  Option 1 is elegent  quick and shouldn't be too difficult to implementation. Option 2 would require a lot of ground work but would be more powerful since it reduces overhead and infrastructural needs.",,octonato
32012,octonato,2023-07-11T08:43:21Z,2023-11-28T10:34:14Z,patriknw,patriknw,failed: LeaseMajority5NodeSpecMultiJvm ,"https://github.com/akka/akka/actions/runs/5503370953/jobs/10028502944#step:10:6007  This is an Artery Aeron UDP test.  Quite a few failures following the first one. Nodes probably got into a state that triggered the other failures.",,patriknw
32009,johanandren,2023-07-05T11:24:52Z,2023-11-28T10:34:30Z,patriknw,patriknw; pvlugter; johanandren; octonato,Failed: LeaseMajority5NodeSpec,"https://github.com/akka/akka/actions/runs/5459886326/jobs/9936318139#step:10:6066  ``` [info] [JVM-4] - should keep the side that can acquire the lease (on node 'node4'  class akka.cluster.sbr.LeaseMajority5NodeSpecMultiJvmNode4) *** FAILED *** (13 seconds  119 milliseconds) [info] [JVM-4]   java.lang.AssertionError: assertion failed: timeout (6 seconds) during expectMsgClass waiting for class akka.coordination.lease.TestLease$AcquireReq [info] [JVM-4]   at scala.Predef$.assert(Predef.scala:279) [info] [JVM-4]   at akka.testkit.TestKitBase.expectMsgClass_internal(TestKit.scala:570) [info] [JVM-4]   at akka.testkit.TestKitBase.expectMsgType(TestKit.scala:542) [info] [JVM-4]   at akka.testkit.TestKitBase.expectMsgType$(TestKit.scala:541) [info] [JVM-4]   at akka.testkit.TestKit.expectMsgType(TestKit.scala:955) [info] [JVM-4]   at akka.cluster.sbr.LeaseMajority5NodeSpec.$anonfun$new$21(LeaseMajority5NodeSpec.scala:148) [info] [JVM-4]   at akka.remote.testkit.MultiNodeSpec.runOn(MultiNodeSpec.scala:414) [info] [JVM-4]   at akka.cluster.sbr.LeaseMajority5NodeSpec.$anonfun$new$19(LeaseMajority5NodeSpec.scala:148) ```",,patriknw; pvlugter; johanandren; octonato
32008,johanandren,2023-07-05T11:24:08Z,2023-11-28T10:34:52Z,patriknw,patriknw; pvlugter; johanandren; octonato,Failed: AeronStreamLatencySpec,"https://github.com/akka/akka/actions/runs/5459886326/jobs/9936318017#step:10:1666  ``` [info] [JVM-1] - must be low for rate-10000-size-100  at 10000 msg/s  payloadSize = 100 (on node 'first'  class akka.remote.artery.aeron.AeronStreamLatencySpecMultiJvmNode1) *** FAILED *** (3 seconds  793 milliseconds) [info] [JVM-1]   sendQueue full (AeronStreamLatencySpec.scala:283) [info] [JVM-1]   org.scalatest.exceptions.TestFailedException: [info] [JVM-1]   at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:472) [info] [JVM-1]   at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:471) [info] [JVM-1]   at akka.remote.artery.aeron.AeronStreamLatencySpec.newAssertionFailedException(AeronStreamLatencySpec.scala:73) ```",,patriknw; pvlugter; johanandren; octonato
32001,patriknw,2023-06-30T08:40:13Z,2023-06-30T14:28:45Z,patriknw,,Release 2.8.3,"Release Akka 2.8.3  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.3=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.3 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.3`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.3/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.3/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.3/)  ### When everything is on maven central   - [x] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.3`     - [ ] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.3          git add api/akka/current api/akka/2.8.3          git add japi/akka/current japi/akka/2.8.3          git commit -m ""Akka 2.8.3""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [x] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,patriknw
31979,johanandren,2023-06-21T11:53:48Z,2023-06-22T14:07:24Z,johanandren,patriknw; johanandren,Failed: EventsBySliceFirehoseSpec,"https://github.com/akka/akka/actions/runs/5295215290/jobs/9585318024#step:5:7510   ``` --> [EventsBySliceFirehose must track consumer progress] Start of log messages of test that [Failed(java.lang.AssertionError: assertion failed: timeout (6 seconds) during expectMsgClass waiting for class akka.stream.testkit.TestSubscriber$OnNext)] | [DEBUG] [06/17/2023 00:25:19.640] [pool-1-thread-1-ScalaTest-running-EventsBySliceFirehoseSpec] [WithLogCapturing(akka://EventsBySliceFirehoseSpec)] Logging started for test [EventsBySliceFirehose must track consumer progress] | [DEBUG] [06/17/2023 00:25:19.642] [pool-1-thread-1-ScalaTest-running-EventsBySliceFirehoseSpec] [EventsBySliceFirehose(akka://EventsBySliceFirehoseSpec)] Create firehose entityType [EntityA]  sliceRange [0-1023] | [DEBUG] [06/17/2023 00:25:19.657] [pool-1-thread-1-ScalaTest-running-EventsBySliceFirehoseSpec] [EventsBySliceFirehose(akka://EventsBySliceFirehoseSpec)] Firehose entityType [EntityA] sliceRange [0-1023] consumer [cda730f8-8de4-4e86-855d-0204dea81e64] started | [DEBUG] [06/17/2023 00:25:19.680] [pool-1-thread-1-ScalaTest-running-EventsBySliceFirehoseSpec] [EventsBySliceFirehose(akka://EventsBySliceFirehoseSpec)] Firehose entityType [EntityA] sliceRange [0-1023] consumer [b8a83e16-2515-4ea5-8281-1f1a0e7f0365] started | [DEBUG] [06/17/2023 00:25:20.692] [EventsBySliceFirehoseSpec-akka.actor.default-dispatcher-7] [CatchupOrFirehose(akka://EventsBySliceFirehoseSpec)] Firehose entityType [EntityA] sliceRange [0-1023] consumer [b8a83e16-2515-4ea5-8281-1f1a0e7f0365] push from catchup [EntityA|a] seqNr [1]  source [] | [DEBUG] [06/17/2023 00:25:20.692] [EventsBySliceFirehoseSpec-akka.actor.default-dispatcher-9] [CatchupOrFirehose(akka://EventsBySliceFirehoseSpec)] Firehose entityType [EntityA] sliceRange [0-1023] consumer [cda730f8-8de4-4e86-855d-0204dea81e64] push from catchup [EntityA|a] seqNr [1]  source [] | [DEBUG] [06/17/2023 00:25:20.693] [EventsBySliceFirehoseSpec-akka.actor.default-dispatcher-9] [CatchupOrFirehose(akka://EventsBySliceFirehoseSpec)] Firehose entityType [EntityA] sliceRange [0-1023] consumer [cda730f8-8de4-4e86-855d-0204dea81e64] push from catchup [EntityA|b] seqNr [1]  source [] | [DEBUG] [06/17/2023 00:25:20.693] [EventsBySliceFirehoseSpec-akka.actor.default-dispatcher-7] [CatchupOrFirehose(akka://EventsBySliceFirehoseSpec)] Firehose entityType [EntityA] sliceRange [0-1023] consumer [b8a83e16-2515-4ea5-8281-1f1a0e7f0365] push from catchup [EntityA|b] seqNr [1]  source [] | [DEBUG] [06/17/2023 00:25:26.699] [pool-1-thread-1-ScalaTest-running-EventsBySliceFirehoseSpec] [WithLogCapturing(akka://EventsBySliceFirehoseSpec)] Logging finished for test [EventsBySliceFirehose must track consumer progress] <-- [EventsBySliceFirehose must track consumer progress] End of log messages of test that [Failed(java.lang.AssertionError: assertion failed: timeout (6 seconds) during expectMsgClass waiting for class akka.stream.testkit.TestSubscriber$OnNext)] [06-17 00:25:26.719] [info] - must track consumer progress *** FAILED *** (7 seconds  65 milliseconds) [06-17 00:25:26.719] [info]   java.lang.AssertionError: assertion failed: timeout (6 seconds) during expectMsgClass waiting for class akka.stream.testkit.TestSubscriber$OnNext [06-17 00:25:26.719] [info]   at scala.Predef$.assert(Predef.scala:223) [06-17 00:25:26.720] [info]   at akka.testkit.TestKitBase.expectMsgClass_internal(TestKit.scala:571) [06-17 00:25:26.720] [info]   at akka.testkit.TestKitBase.expectMsgType(TestKit.scala:543) [06-17 00:25:26.721] [info]   at akka.testkit.TestKitBase.expectMsgType$(TestKit.scala:542) [06-17 00:25:26.721] [info]   at akka.testkit.TestKit.expectMsgType(TestKit.scala:956) [06-17 00:25:26.722] [info]   at akka.stream.testkit.TestSubscriber$ManualProbe.expectNextN(StreamTestKit.scala:418) [06-17 00:25:26.722] [info]   at akka.persistence.query.typed.internal.EventsBySliceFirehoseSpec$$anon$4.<init>(EventsBySliceFirehoseSpec.scala:250) [06-17 00:25:26.722] [info]   at akka.persistence.query.typed.internal.EventsBySliceFirehoseSpec.$anonfun$new$5(EventsBySliceFirehoseSpec.scala:218) ```",,patriknw; johanandren
31977,johanandren,2023-06-21T08:26:31Z,2023-06-21T11:32:49Z,johanandren,,Release Akka 2.6.21,"Release Akka 2.6.21  ### Before the release  - [x] Make sure all important / big PRs have been merged by now - [ ] Create a news item draft PR on [akka.io](https://github.com/akka/akka.io)  using the milestone and `scripts/authors.scala v2.6.14 v2.6.15` - [ ] Make sure to update `_config.yml` in it - In case of a new minor release:   - [ ] update the branch descriptions at CONTRIBUTING.md#branches-summary  ### Cutting the release  - [x] Make sure any running [actions](https://github.com/akka/akka/actions) for the commit you would like to release have completed. - [x] Tag the release `git tag -a -s -m 'Release v2.6.21' v2.6.21` and push the tag `git push --tags` - [x] Create a [new milestone](https://github.com/akka/akka/milestones) for the next version and close the current one. - [x] Check that the GitHub Actions release build has executed successfully (it should publish artifacts to Sonatype and documentation to Gustav) - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`)  ### Check availability  - [x] Check [reference](https://doc.akka.io/docs/akka/2.6.21/) documentation - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.6.21/)  ### When everything is on maven central  - [x] `ssh akkarepo@gustav.akka.io`   - [ ] update the `current` links on `repo.akka.io` to point to the latest version with        ```        ln -nsf 2.6.21 www/docs/akka/current        ln -nsf 2.6.21 www/api/akka/current        ln -nsf 2.6.21 www/japi/akka/current        ```   - [x] check changes and commit the new version to the local git repository        ```        cd ~/www        git add docs/akka/current docs/akka/2.6.21        git add api/akka/current api/akka/2.6.21        git add japi/akka/current japi/akka/2.6.21        git commit -m ""Akka 2.6.21""        ```   - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)        ```        cd ~/www        git push origin main        ```  ### Announcements  - [ ] Merge draft news item for [akka.io](https://github.com/akka/akka.github.com) - [x] Create a [GitHub release](https://github.com/akka/akka/releases) with the next tag version `v2.6.21`  title and a link to the announcement - [ ] Post about it on the [forum](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally  ## Update references  Update the versions used in:  * [ ] https://github.com/akka/akka-samples * [ ] https://github.com/lightbend/lightbend-platform-docs/blob/master/docs/modules/getting-help/examples/build.sbt (this populates https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html#_akka)  These are autoupdated by latest stable on maven central: * https://github.com/akka/akka-quickstart-java.g8 * https://github.com/akka/akka-quickstart-scala.g8 * https://github.com/akka/akka-http-quickstart-java.g8 * https://github.com/akka/akka-http-quickstart-scala.g8 * https://github.com/akka/akka-grpc-quickstart-java.g8 * https://github.com/akka/akka-grpc-quickstart-scala.g8 ",,johanandren
31976,gael-ft,2023-06-20T16:07:33Z,2023-06-21T08:22:45Z,gael-ft,leviramsey; gael-ft; patriknw,Akka Persistence with multi-tenant (ReadJournal),"Building a persistence plugin where each customer have its own database but the backend is shared.  For `AsyncWriteJournal` and `SnapshotStore` plugin APIs  current Akka Persistence API fits well as we can use the `PersistenceId` to map to the correct database. For example  the strategy could be `[customerName]/[entityTypeKey]|[entityId]`.  But for `ReadJournal` it is more complicated. For example `CurrentPersistenceIdsQuery` trait defines `def currentPersistenceIds(): Source[String  NotUsed]`. As no arguments is given  we have no way to perform the logic.  I know that child traits of `ReadJournal` are optional so I could add my own methods but I submit this request as doing so  I won't be able to some of the tools in [Event Sourced Akka Projection](https://doc.akka.io/docs/akka-projection/current/eventsourced.html). Once again  we could define our own ways to create `akka.projection.scaladsl.SourceProvider`. But that would be nice if we could reuse existing classes in Akka Projection.  I was thinking about providing overloaded methods in child traits of `ReadJournal` (which support should be documented by plugin authors as it's the case already with others methods):  ```scala // Plugin authors could extends it as they want trait QueryOptions  // In my case final case class TenantQueryOptions(customer: String) extends QueryOptions  // Adding a overloaded method to child traits of ReadJournal (here CurrentPersistenceIdsQuery) trait CurrentPersistenceIdsQuery extends ReadJournal {   def currentPersistenceIds(): Source[String  NotUsed]      def currentPersistenceIds(options: QueryOptions): Source[String  NotUsed] } ```  Do you think it would be acceptable ?",,leviramsey; gael-ft; patriknw
31974,johanandren,2023-06-16T06:37:44Z,2023-08-15T08:34:08Z,johanandren,He-Pin; patriknw,Bump or replace Netty in akka-multi-node-testkit,"akka-multi-node-testkit depends on an old Netty version (3.10.6) which has one or more CVEs attached  possibly firing off warnings in vulnerability scanners. I don't think there are any valid issues since the Netty usage is pretty minimal but who knows.  Bumping to Netty 4 is not a drop in replacement  might be just as much work to simply drop it completely.  Mostly noting this down for history keeping  this is a testkit and not something that should be on the production classpath of an app built with Akka. I don't expect we will make this a priority.",,He-Pin; patriknw
31954,He-Pin,2023-05-30T02:51:19Z,2023-06-06T09:52:59Z,octonato,johanandren,Add contramap to Flow,Hi I see there is a Sink#contramap  and it would be nice to have a `Flow#contramap` too which contramap the input.,,johanandren
31946,taepyongyang,2023-05-21T04:19:05Z,2023-05-22T06:48:14Z,patriknw,He-Pin; patriknw,Backport akka-cluster SBR to earlier revisions particularly for those that rely on Scala 2.11 (Akka 2.5.x),I'm seeking guidance for appetite to allow backport of the open sources SBR (Split Brain Resolver) released in akka/akka 2.8.x to earlier Akka versions. In my case  particular to the version of Scala I'm using 2.11 and am relying on Akka 2.5.x.   I'm happy to test and submit if maintainer would be willing accept PR to be built for distribution through existing distribution channels.,,He-Pin; patriknw
31938,johanandren,2023-05-09T06:57:56Z,2023-05-09T15:03:41Z,johanandren,,Release 2.8.2,"Release Akka 2.8.2  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.2=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.2 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.2`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.2/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.2/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.2/)  ### When everything is on maven central   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.2`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.2          git add api/akka/current api/akka/2.8.2          git add japi/akka/current japi/akka/2.8.2          git commit -m ""Akka 2.8.2""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [x] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [x] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,johanandren
31937,Canislupax,2023-05-08T22:30:27Z,2023-05-22T08:47:18Z,johanandren,johanandren,projection r2dbc documentation broken,"Since 2.8.1 the documentation for the projection-r2dbc after movement from the akka-persitence module broken.  -> https://doc.akka.io/docs/akka-projection/current/r2dbc.html ",,johanandren
31931,Valocop,2023-04-28T13:21:06Z,2023-04-28T13:49:55Z,johanandren,johanandren,How to config serialization for messages pub/sub topic,https://github.com/akka/akka/blob/40f9463d78fe84e418967905d874e127a7b3373b/akka-actor-typed-tests/src/test/java/jdocs/akka/typed/pubsub/PubSubExample.java#L16,,johanandren
31928,johanandren,2023-04-27T13:17:31Z,2023-04-27T15:46:11Z,johanandren,,Release 2.8.1,"Release Akka 2.8.1  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.1=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.1 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.1`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.1/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.1/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.1/)  ### When everything is on maven central   - [x] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.1`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.1          git add api/akka/current api/akka/2.8.1          git add japi/akka/current japi/akka/2.8.1          git commit -m ""Akka 2.8.1""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [x] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [x] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,johanandren
31925,mbrito-yieldstreet,2023-04-26T14:56:20Z,2023-04-26T15:01:36Z,johanandren,mbrito-yieldstreet; johanandren,Naming conflicts in cluster singleton leases,"The naming schemes for leases acquired by `ClusterSingletonManager` can easily hit the 63-character limit imposed by Kubernetes  causing multiple leases to end up with the name sanitized name.  For example  this is from one of our applications:  > Original lease name [deal-ledger-singleton-akka://deal-ledger/user/readSideGlobalPrepare-DistributionToJsonEventProcessor-singleton] sanitized for kubernetes: [deal-ledger-singleton-akkadeal-ledgeruserreadsideglobalprepare] > > Original lease name [deal-ledger-singleton-akka://deal-ledger/user/readSideGlobalPrepare-DealEventProcessor-singleton] sanitized for kubernetes: [deal-ledger-singleton-akkadeal-ledgeruserreadsideglobalprepare]  Granted  my actor names are somewhat long (thanks  Lagom)  but it would help if the name scheme didn't repeat the actor system name twice and included the probably useless `akka://` prefix. A pattern like `${context.system.name}-singleton-${self.name}` is probably appropriate for most applications; alternatively  using `self.path.toStringWithoutAddress` will at least remote the system name duplication.",,mbrito-yieldstreet; johanandren
31916,johanandren,2023-04-19T15:24:35Z,2023-06-02T11:42:15Z,johanandren,johanandren,Search index incomplete,"When setting up the new algolia search indexes I copy-pasted what I thought was the original config  but now when searching in the docs I often do not get any results at all when I expect to (examples ""split brain""  ""sharded daemon process"") or different matches as highest from what I'd expect (""sharding""  ""singleton"").  Was the indexes always suboptimal or did something change?",,johanandren
31905,andreezy777,2023-04-11T16:02:44Z,2023-04-21T11:33:43Z,patriknw,leviramsey; andreezy777; octonato; johanandren; He-Pin,Race condition in AsyncDnsResolver,"Hello guys   It looks like we have a race condition caused by this `var requestId`  https://github.com/akka/akka/blob/5e9e11b5f6df03ed89c5ca37bdbb295ff5c19ec4/akka-actor/src/main/scala/akka/io/dns/internal/AsyncDnsResolver.scala#L78  We have 3 grpc clients that are trying to initialize  so they are sending address lookup requests to the dns service. Here are the logs that we got from AsyncDnsResolver :  ``` {""timestamp"":""2023-04-03T11:49:50.410Z"" ""level"":""DEBUG"" ""logger"":""akka.io.dns.internal.AsyncDnsResolver"" ""message"":""Attempting to resolve X.namespace1.svc.cluster.local.svc.cluster.local with Actor[akka://testSystem/system/IO-DNS/async-dns/$a/$a#658321458]""} {""timestamp"":""2023-04-03T11:49:50.411Z"" ""level"":""DEBUG"" ""logger"":""akka.io.dns.internal.AsyncDnsResolver"" ""message"":""Attempting to resolve Y.namespace2.svc.cluster.local with Actor[akka://testSystem/system/IO-DNS/async-dns/$a/$a#658321458]""} {""timestamp"":""2023-04-03T11:49:50.420Z"" ""level"":""DEBUG"" ""logger"":""akka.io.dns.internal.AsyncDnsResolver"" ""message"":""Ip(true true) resolved Resolved(X.namespace1.svc.cluster.local.svc.cluster.local Vector(ARecord(Y.namespace2.svc.cluster.local Ttl(26 seconds) /100.68.87.33)) Vector())""}  ....  {""timestamp"":""2023-04-03T11:49:55.428Z"" ""level"":""INFO"" ""logger"":""akka.io.dns.internal.AsyncDnsResolver"" ""message"":""Resolve of Y.namespace2.svc.cluster.local timed out after 5.000 s. Trying next name server""} ```  As a possible solution  I can suggest using AtomicInteger to avoid race condition. ",,leviramsey; andreezy777; octonato; johanandren; He-Pin
31904,lfygh,2023-04-10T09:55:37Z,2023-04-12T08:26:12Z,lfygh,He-Pin; lfygh,watchTermination not report exception,"the [demo code](https://doc.akka.io/docs/akka/current/stream/operators/Source-or-Flow/watchTermination.html) does not work as expected  ``` Source.range(1  5)     .watchTermination(         (prevMatValue  completionStage) -> {           // this function will be run when the stream terminates           // the CompletionStage provided as a second parameter indicates whether           // the stream completed successfully or failed           completionStage.whenComplete(               (done  exc) -> {                 if (done != null)                   System.out.println(""The stream materialized "" + prevMatValue.toString());                 else System.out.println(exc.getMessage());               });           return prevMatValue;         })     .runForeach(         element -> {           if (element == 3) throw new Exception(""Boom"");           else System.out.println(element);         }          system); /* Prints: 1 2 Boom  */ ``` expect print error msg  but it print ""The stream materialized "" + prevMatValue.toString()  version: akka-stream_2.13-2.5.32-sources.jar",,He-Pin; lfygh
31895,johanandren,2023-03-23T13:57:40Z,2023-03-23T14:51:26Z,johanandren,,Release 2.8.1-M1,"Release Akka 2.8.1-M1  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.1-M1=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] Update the version and change date in the LICENSE file. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.1-M1 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.1-M1`  title and release description. Use the `Publish release` button  which will create the tag. - [ ] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.1-M1/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.1-M1/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.1-M1/)  ### When everything is on maven central   - [x] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.1-M1`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.1-M1          git add api/akka/current api/akka/2.8.1-M1          git add japi/akka/current japi/akka/2.8.1-M1          git commit -m ""Akka 2.8.1-M1""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [ ] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,johanandren
31885,johanandren,2023-03-16T12:21:48Z,2023-03-16T16:30:29Z,johanandren,patriknw,Release 2.8.0,"Release Akka 2.8.0  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.0=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] For minor or major versions  update the Change date in the LICENSE file and update the `licenses` url in the build. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.0 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.0`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.0/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.0/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.0/)  ### When everything is on maven central   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.0`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.0          git add api/akka/current api/akka/2.8.0          git add japi/akka/current japi/akka/2.8.0          git commit -m ""Akka 2.8.0""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [x] If this updated 'current' docs - trigger a re-index of the docs for search through [Run workflow for the scraper](https://github.com/akka/akka/actions/workflows/algolia-doc-site-scrape.yml)   - [x] Update version in _config.yml in https://github.com/akka/akka.io         ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [x] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [x] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [x] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [x] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,patriknw
31881,liuzhuang2017,2023-03-15T08:48:31Z,2023-05-08T15:11:31Z,johanandren,johanandren,When I use apache flink1.12.2 version  the following akka error often occurs.," java.util.concurrent.TimeoutException: Remote system has been silent for too long. (more than 48.0 hours) at akka.remote.ReliableDeliverySupervisor$$anonfun$idle$1.applyOrElse(Endpoint.scala:375) at akka.actor.Actor$class.aroundReceive(Actor.scala:502) at akka.remote.ReliableDeliverySupervisor.aroundReceive(Endpoint.scala:203) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526) at akka.actor.ActorCell.invoke(ActorCell.scala:495) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257) at akka.dispatch.Mailbox.run(Mailbox.scala:224) at akka.dispatch.Mailbox.exec(Mailbox.scala:234) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)  --------------------------------------------------------------------------------------------------------------------------- I checked that 48 hours ago  there was indeed a process hang inside flink  and the flink job was restarted.How to deal with this? Is this a bug in akka?  Thank you !  ",,johanandren
31880,ricrsantos,2023-03-14T17:28:04Z,2023-03-15T07:51:45Z,johanandren,johanandren,Link for quick guide is broken.,"Hello everyone. Sorry  I don't if it's the correct place to put this information. I would like to inform you that the link to access the quick guide: https://developer.lightbend.com/guides/akka-quickstart-java/?_ga=2.61186410.792724676.1678725944-735189854.1678725944  is broken.   Thank you for your job guys!  <!-- Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka HTTP: https://github.com/akka/akka-http/issues  - Alpakka:   https://github.com/akka/alpakka/issues  - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your issue precisely  and if possible provide a reproducer snippet (this helps resolve issues much quicker).  Thanks  happy hakking! --> ",,johanandren
31869,johanandren,2023-03-08T12:21:41Z,2023-03-13T07:11:28Z,patriknw,pvlugter,Fossa scanning akka-bench-jmh and failing,"https://github.com/akka/akka/actions/runs/4328275999/jobs/7557789150  jmh uses gpl libraries  but we only use the tool  so we should be fine.  It barks even though we have an exclude for akka-bench-jmh in .fossa.yml ",,pvlugter
31862,Roiocam,2023-03-06T07:09:41Z,2023-09-12T14:01:31Z,johanandren,patriknw; Roiocam,Typed Actor won't using a custom mailbox.," # How one can reproduce the issue  1. using akka-typed (definitely). 2. define custom mailbox. 3. define custom dispatcher on config(code.1) 4. start cluster sharing entity using the custom dispatcher(code.2).   **code.1**  ```conf my-dispatcher {   type = Dispatcher   executor = ""thread-pool-executor""   mailbox-type = ""my.PriorityMailbox""   thread-pool-executor {   ...  } } ```  **code.2**  ```java Props customDispatcher = Props.empty().withDispatcherFromConfig(""my-dispatcher""); Entity<Object ShardingEnvelope<Object>> entity = Entity.of(typeKey  etx-> new MyActor(etx)); entity = entity.withEntityProps(customDispatcher); sharding.init(entity); ```   I can't find custom mailbox documents of cluster sharing typed  classic documents were more explicit.  https://doc.akka.io/docs/akka/current/typed/mailboxes.html   # What is the expected correct behavior  My entity should use a custom dispatcher and a custom mailbox but only the dispatcher is being used.   # What actually happens  When I get into the debug mode  I found that the entity actor is only using a mailbox named 'akka.dispatch.SingleConsumerOnlyUnboundedMailbox`  Instead of my custom mailbox.  # My investigate  ## the first critical path   when the typed actor has been born  It will use `PropsAdapter` to transform to classic `Props`.  `PropsAdapter` has a critical path on L32  it gives a default mailbox when the Props was not `MailboxSelector`  https://github.com/akka/akka/blob/8e0d53968b2ab17a3ce21130d4f4f3106e30cff2/akka-actor-typed/src/main/scala/akka/actor/typed/internal/adapter/PropsAdapter.scala#L32  ## the second critical path   when an actor has been born  it will look up a dispatcher and mailbox.  It uses `Mailboxes` and passes in parameters that a  `Props` named deploy and the dispatcher config  https://github.com/akka/akka/blob/8e0d53968b2ab17a3ce21130d4f4f3106e30cff2/akka-actor/src/main/scala/akka/actor/ActorRefProvider.scala#L699  But because the first critical path  deploy always has a default mailbox  So on `Mailboxes`  it never reaches the L187  it is the meaning dispatcher never uses a custom mailbox.  https://github.com/akka/akka/blob/8e0d53968b2ab17a3ce21130d4f4f3106e30cff2/akka-actor/src/main/scala/akka/dispatch/Mailboxes.scala#L187  when I create an actor in a classic way  it won't reproduce(it does not use PropsAdapter). ",akka-actor-typed-tests/src/test/scala/akka/actor/typed/scaladsl/DispatcherSelectorSpec.scala; akka-actor-typed/src/main/resources/reference.conf; akka-actor-typed/src/main/scala/akka/actor/typed/Props.scala; akka-actor/src/main/resources/reference.conf; akka-cluster-sharding-typed/src/main/resources/reference.conf; akka-cluster-sharding/src/main/resources/reference.conf,Roiocam
31861,johanandren,2023-03-03T09:18:03Z,2023-03-03T10:13:17Z,johanandren,,Release 2.8.0-M6,"Release Akka 2.8.0-M6  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.0-M6=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] For minor or major versions  update the Change date in the LICENSE file and update the `licenses` url in the build. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.0-M6 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.0-M6`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.0-M6/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.0-M6/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.0-M6/)  ### When everything is on maven central   - [x] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.0-M6`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.0-M6          git add api/akka/current api/akka/2.8.0-M6          git add japi/akka/current japi/akka/2.8.0-M6          git commit -m ""Akka 2.8.0-M6""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] Update version in _config.yml in https://github.com/akka/akka.io      ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,johanandren
31840,SEMBM,2023-02-20T09:25:30Z,2023-02-20T09:32:48Z,johanandren,johanandren,Association to [akka_ tcp://name_server:49766] with UId [1896650320] is irrecoverably failed. Quarantining address,"Good morning  we are facing this exception every few days  nodes become unreachable although they could be in the same VLAN. The version we are using is Akka 1.3.18. It was stable until we configured some Firewall rules over windows allowing only ports needed   for instance Start Port 49152 Number of Ports 16384 or in some servers Start Port 32767  number of ports 32768. This is the exception Akka.Pattern.IllegalStateException: Error encountered while processing system message acknowledgement buffer: [-1 []] ack: ACK[0  []] ---> System.ArgumentException: ack Parameter name: Highest SEQ o far was -1 but cumulative ACK is 0 at Akka.Remote.AckedSendBuffer'1.Acknowledge(Ack ack) at Akka.Remote.ReliableDeliverySupervisor.<Receiving>b__32_3(Ack ack) --- End of inner excption stack trace --- ![image](https://user-images.githubusercontent.com/125868195/220062540-9d48ad0e-fecf-4232-b2c3-ef72ab7ce745.png)  ",,johanandren
31839,patriknw,2023-02-17T12:59:49Z,2023-11-27T13:39:24Z,patriknw,patriknw; johanandren; octonato,failed: EventSourcedBehaviorRetentionSpec,"https://github.com/akka/akka/actions/runs/4189334877/jobs/7261527717#step:5:22261  ``` [02-16 00:51:32.067] [info] - must optionally delete old events *** FAILED *** (6 seconds  47 milliseconds) [22261](https://github.com/akka/akka/actions/runs/4189334877/jobs/7261527717#step:5:22262) [02-16 00:51:32.067] [info]   java.lang.AssertionError: Timeout (6 seconds) during expectMessageClass waiting for class akka.persistence.typed.scaladsl.EventSourcedBehaviorRetentionSpec$WrappedSignal ```",,patriknw; johanandren; octonato
31838,patriknw,2023-02-16T12:50:26Z,2023-02-17T13:59:14Z,patriknw,,Release 2.8.0-M5,"Release Akka 2.8.0-M5  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.0-M5=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] For minor or major versions  update the Change date in the LICENSE file and update the `licenses` url in the build. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.0-M5 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.0-M5`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.0-M5/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.0-M5/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [ ] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.0-M5/)  ### When everything is on maven central   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.0-M5`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.0-M5          git add api/akka/current api/akka/2.8.0-M5          git add japi/akka/current japi/akka/2.8.0-M5          git commit -m ""Akka 2.8.0-M5""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] Update version in _config.yml in https://github.com/akka/akka.io      ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,patriknw
31830,franciscolopezsancho,2023-02-02T17:57:16Z,2023-02-03T14:34:29Z,franciscolopezsancho,patriknw; franciscolopezsancho; johanandren,Invalid configuration?,"Aren't these lines incompatible with`akka-diagnostics`  https://github.com/akka/akka/blob/7f1e439032cd5ee3163ba6d1ab80829fbf30b1d5/akka-persistence-testkit/src/main/scala/akka/persistence/testkit/PersistenceTestKitPlugin.scala#L93  https://github.com/akka/akka/blob/7f1e439032cd5ee3163ba6d1ab80829fbf30b1d5/akka-persistence-testkit/src/main/scala/akka/persistence/testkit/PersistenceTestKitPlugin.scala#L134-L136  Meaning. They are creating invalid configuration such as https://github.com/akka/akka-guide/actions/runs/4074859245/jobs/7020504974#step:6:91",,patriknw; franciscolopezsancho; johanandren
31826,philipwhiuk,2023-02-01T12:27:03Z,2023-02-01T13:04:29Z,patriknw,patriknw,akka-protobuf-v3 isn't fully shaded,"If you depend on akka and also use protobuf in your application (thus pulling in protobuf-java)  then try to build an uber JAR de-duplication will fail  The reason for this is that  while the Protobuf code is shaded the proto-files themselves aren't shaded.  ``` [error] /root/.ivy2/cache/com.typesafe.akka/akka-protobuf-v3_2.12/jars/akka-protobuf-v3_2.12-2.6.20.jar:google/protobuf/any.proto [error] /root/.ivy2/cache/com.google.protobuf/protobuf-java/bundles/protobuf-java-3.20.0.jar:google/protobuf/any.proto [error] deduplicate: different file contents found in the following: [error] /root/.ivy2/cache/com.typesafe.akka/akka-protobuf-v3_2.12/jars/akka-protobuf-v3_2.12-2.6.20.jar:google/protobuf/descriptor.proto [error] /root/.ivy2/cache/com.google.protobuf/protobuf-java/bundles/protobuf-java-3.20.0.jar:google/protobuf/descriptor.proto [error] deduplicate: different file contents found in the following: [error] /root/.ivy2/cache/com.typesafe.akka/akka-protobuf-v3_2.12/jars/akka-protobuf-v3_2.12-2.6.20.jar:google/protobuf/empty.proto [error] /root/.ivy2/cache/com.google.protobuf/protobuf-java/bundles/protobuf-java-3.20.0.jar:google/protobuf/empty.proto [error] deduplicate: different file contents found in the following: [error] /root/.ivy2/cache/com.typesafe.akka/akka-protobuf-v3_2.12/jars/akka-protobuf-v3_2.12-2.6.20.jar:google/protobuf/struct.proto [error] /root/.ivy2/cache/com.google.protobuf/protobuf-java/bundles/protobuf-java-3.20.0.jar:google/protobuf/struct.proto ```  (This is reproducible on 2.8.0-M4)  As a work-around assuming you don't actually have a runtime dependency on the proto files themselves you can probably safely do something like: ``` assemblyMergeStrategy in assembly ~= (old => {   case x if x.endsWith("".proto"") =>  MergeStrategy.discard     case x => old(x) } ```",,patriknw
31822,johanandren,2023-01-20T16:02:45Z,2023-08-29T09:02:30Z,johanandren,sebastian-alfers; ennru; patriknw; johanandren,Drop AkkaSSLConfig and transitive ssl-config dependency,I _think_ it is deprecated since 2.6.0 everywhere  could we drop it completely by now? (parser combinators versions is a head ache),,sebastian-alfers; ennru; patriknw; johanandren
31821,johanandren,2023-01-20T08:06:12Z,2023-01-20T12:07:47Z,johanandren,,Release 2.8.0-M4,"Release Akka 2.8.0-M4  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.0-M4=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] For minor or major versions  update the Change date in the LICENSE file and update the `licenses` url in the build. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.0-M4 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.0-M4`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.0-M4/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.0-M4/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.0-M4/)  ### When everything is on maven central   - [ ] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.0-M4`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.0-M4          git add api/akka/current api/akka/2.8.0-M4          git add japi/akka/current japi/akka/2.8.0-M4          git commit -m ""Akka 2.8.0-M4""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] Update version in _config.yml in https://github.com/akka/akka.io      ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,johanandren
31814,johanandren,2023-01-11T12:49:01Z,2023-10-06T15:06:01Z,johanandren,havenwang-plenty,Misbehaving failure handling for messages in backoff stash buffer,"Reported in SO: https://stackoverflow.com/questions/75065817/akka-why-are-stashed-messages-with-backoff-supervision-lost  Short: messages stashed in the internal supervision stash during backoff may be lost if one of them triggers a new error when unstashing once backoff completes and restarts. ",akka-actor-typed-tests/src/test/scala/akka/actor/typed/SupervisionSpec.scala; akka-actor-typed/src/main/scala/akka/actor/typed/internal/Supervision.scala,Roiocam
31806,johanandren,2022-12-22T15:23:56Z,2022-12-23T07:52:51Z,johanandren,,Release 2.8.0-M3,"Release Akka 2.8.0-M3  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.0-M3=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] For minor or major versions  update the Change date in the LICENSE file and update the `licenses` url in the build. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.0-M3 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [ ] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.0-M3`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.0-M3/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.0-M3/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.0-M3/)  ### When everything is on maven central   - [x] Log into `gustav.akka.io` as `akkarepo`      - [ ] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.0-M3`     - [ ] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.0-M3          git add api/akka/current api/akka/2.8.0-M3          git add japi/akka/current japi/akka/2.8.0-M3          git commit -m ""Akka 2.8.0-M3""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] Update version in _config.yml in https://github.com/akka/akka.io      ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,johanandren
31803,johanandren,2022-12-21T12:53:35Z,2022-12-22T15:22:32Z,johanandren,johanandren,Failed: SnapshotSerializeSpec,"https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30225   ``` [12-20 01:02:20.033] [info] - should test snapshot events with RetentionCriteria after sending commands *** FAILED *** (2 seconds  30 milliseconds) [30225](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30226) [12-20 01:02:20.033] [info]   java.lang.AssertionError: assertion failed: Failed to persist NonEmptyState(abcdefgh)  got Some(NonEmptyState(abcdefghij)) instead [30226](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30227) [12-20 01:02:20.033] [info]   at scala.Predef$.assert(Predef.scala:279) [30227](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30228) [12-20 01:02:20.033] [info]   at akka.persistence.testkit.scaladsl.ExpectOps.$anonfun$expectNextPersisted$1(TestOps.scala:148) [30228](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30229) [12-20 01:02:20.033] [info]   at akka.testkit.TestKitBase.poll$2(TestKit.scala:332) [30229](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30230) [12-20 01:02:20.033] [info]   at akka.testkit.TestKitBase.awaitAssert(TestKit.scala:349) [30230](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30231) [12-20 01:02:20.033] [info]   at akka.testkit.TestKitBase.awaitAssert$(TestKit.scala:321) [30231](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30232) [12-20 01:02:20.034] [info]   at akka.testkit.TestKit.awaitAssert(TestKit.scala:973) [30232](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30233) [12-20 01:02:20.034] [info]   at akka.persistence.testkit.scaladsl.ExpectOps.expectNextPersisted(TestOps.scala:150) [30233](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30234) [12-20 01:02:20.034] [info]   at akka.persistence.testkit.scaladsl.ExpectOps.expectNextPersisted$(TestOps.scala:143) [30234](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30235) [12-20 01:02:20.034] [info]   at akka.persistence.testkit.scaladsl.SnapshotTestKit.expectNextPersisted(PersistenceTestKit.scala:318) [30235](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30236) [12-20 01:02:20.034] [info]   at akka.persistence.testkit.scaladsl.ExpectOps.expectNextPersisted(TestOps.scala:135) [30236](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30237) [12-20 01:02:20.034] [info]   at akka.persistence.testkit.scaladsl.ExpectOps.expectNextPersisted$(TestOps.scala:134) [30237](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30238) [12-20 01:02:20.034] [info]   at akka.persistence.testkit.scaladsl.SnapshotTestKit.expectNextPersisted(PersistenceTestKit.scala:336) [30238](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30239) [12-20 01:02:20.034] [info]   at akka.persistence.testkit.scaladsl.CommonSnapshotTests.$anonfun$$init$$36(CommonSnapshotTests.scala:555) [30239](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30240) [12-20 01:02:20.034] [info]   at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85) [30240](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30241) [12-20 01:02:20.034] [info]   at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83) [30241](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30242) [12-20 01:02:20.035] [info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104) [30242](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30243) [12-20 01:02:20.035] [info]   at org.scalatest.Transformer.apply(Transformer.scala:22) [30243](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30244) [12-20 01:02:20.035] [info]   at org.scalatest.Transformer.apply(Transformer.scala:20) [30244](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30245) [12-20 01:02:20.035] [info]   at org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076) [30245](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30246) [12-20 01:02:20.035] [info]   at org.scalatest.TestSuite.withFixture(TestSuite.scala:196) [30246](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30247) [12-20 01:02:20.035] [info]   at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195) [30247](https://github.com/akka/akka/actions/runs/3736246858/jobs/6340346829#step:5:30248) [12-20 01:02:20.035] [info]   at akka.persistence.testkit.scaladsl.SnapshotSerializeSpec.withFixture(SnapshotSerializeSpec.scala:13) ```",,johanandren
31801,patriknw,2022-12-20T13:21:39Z,2022-12-22T14:46:07Z,johanandren,patriknw; johanandren,Error logs from DDataRememberEntitiesShardStore,"Would be good if the DDataRememberEntitiesShardStore logged warnings for the initial failed attempts and then switched to error. Similar to the DDataShardCoordinator.  I don't know if there was a good reason for stopping  throwing  and backoff restarting in case of GetFailure? Probably better to retry a few times within that actor. It has retry mechanism for the updates.",akka-cluster-sharding/src/main/scala/akka/cluster/sharding/internal/DDataRememberEntitiesCoordinatorStore.scala; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/internal/DDataRememberEntitiesShardStore.scala,johanandren
31796,johanandren,2022-12-16T10:17:33Z,2023-01-06T14:31:32Z,octonato,johanandren; octonato,Failed: EventSourcedBehaviorRetentionSpec,"https://github.com/akka/akka/actions/runs/3709022163/jobs/6287193701  ``` [12-16 00:49:16.125] [info] - must delete snapshots automatically  based on criteria *** FAILED *** (6 seconds  70 milliseconds) [12-16 00:49:16.125] [info]   java.lang.AssertionError: Timeout (6 seconds) during expectMessageClass waiting for class akka.persistence.typed.scaladsl.EventSourcedBehaviorRetentionSpec$WrappedSignal [12-16 00:49:16.125] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.assertFail(TestProbeImpl.scala:399) [12-16 00:49:16.126] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.expectMessageClass_internal(TestProbeImpl.scala:239) [12-16 00:49:16.127] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.expectMessageType(TestProbeImpl.scala:218) [12-16 00:49:16.127] [info]   at akka.persistence.typed.scaladsl.EventSourcedBehaviorRetentionSpec$WrappedSignalProbeAssert.expectSnapshotCompleted(EventSourcedBehaviorRetentionSpec.scala:98) [12-16 00:49:16.127] [info]   at akka.persistence.typed.scaladsl.EventSourcedBehaviorRetentionSpec.$anonfun$new$17(EventSourcedBehaviorRetentionSpec.scala:287) ```",akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/scaladsl/EventSourcedBehaviorRetentionSpec.scala,johanandren
31790,patriknw,2022-12-14T11:29:56Z,2022-12-14T13:56:53Z,patriknw,,Release 2.8.0-M2,"Release Akka 2.8.0-M2  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.0-M2=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [ ] For minor or major versions  update the Change date in the LICENSE file and update the `licenses` url in the build. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.0-M2 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [x] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.0-M2`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [ ] Check [API](https://doc.akka.io/api/akka/2.8.0-M2/) documentation - [ ] Check [reference](https://doc.akka.io/docs/akka/2.8.0-M2/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [ ] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.0-M2/)  ### When everything is on maven central   - [x] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.0-M2`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.0-M2          git add api/akka/current api/akka/2.8.0-M2          git add japi/akka/current japi/akka/2.8.0-M2          git commit -m ""Akka 2.8.0-M2""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] Update version in _config.yml in https://github.com/akka/akka.io      ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,patriknw
31788,octonato,2022-12-12T10:55:49Z,2022-12-16T12:09:25Z,johanandren,johanandren; octonato,Failed: removed gcp auth plugin,"This has been reported before when we notice the deprecation warnings.   Not it's failing the build. https://github.com/akka/akka/actions/runs/3672078501/jobs/6207914656#step:6:10",,johanandren; octonato
31785,patriknw,2022-12-09T07:37:26Z,2022-12-14T11:22:41Z,patriknw,,Many retention cycles in progress at the same time,"Deleting events and deleting snapshots are running in the ""background"" so if those are slow it's possible that the same for the same event sourced entity starts many such operations  running in the background at the same time. That may cause undesired load and contention of the database. Eventually triggering circuit breakers.  We should limit the retention to one cycle at a time.",akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/scaladsl/EventSourcedBehaviorRetentionSpec.scala; akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/scaladsl/EventSourcedBehaviorRetentionSpec.scala; akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/scaladsl/EventSourcedBehaviorWatchSpec.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/BehaviorSetup.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/EventSourcedBehaviorImpl.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/ExternalInteractions.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/RetentionCriteriaImpl.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/Running.scala; akka-persistence-typed/src/test/scala/akka/persistence/typed/internal/RetentionCriteriaSpec.scala,johanandren; patriknw
31778,pvlugter,2022-12-05T03:04:34Z,2022-12-09T16:24:54Z,patriknw,patriknw; pvlugter; johanandren; octonato,Failed: AeronStreamLatencySpec,"https://github.com/akka/akka/actions/runs/3579775018/jobs/6021293486#step:9:1500  ``` - must be low for rate-100-size-100  at 100 msg/s  payloadSize = 100 (on node 'first'  class akka.remote.artery.aeron.AeronStreamLatencySpecMultiJvmNode1) *** FAILED *** (6 seconds  177 milliseconds) [info] [JVM-1]   java.lang.AssertionError: assertion failed: timeout (6 seconds) during expectMsg while waiting for Done [info] [JVM-1]   at scala.Predef$.assert(Predef.scala:279) [info] [JVM-1]   at akka.testkit.TestKitBase.expectMsg_internal(TestKit.scala:461) [info] [JVM-1]   at akka.testkit.TestKitBase.expectMsg(TestKit.scala:438) [info] [JVM-1]   at akka.testkit.TestKitBase.expectMsg$(TestKit.scala:438) [info] [JVM-1]   at akka.testkit.TestKit.expectMsg(TestKit.scala:973) [info] [JVM-1]   at akka.remote.artery.aeron.AeronStreamLatencySpec.$anonfun$test$3(AeronStreamLatencySpec.scala:225) [info] [JVM-1]   at akka.testkit.TestKitBase.within(TestKit.scala:418) [info] [JVM-1]   at akka.testkit.TestKitBase.within$(TestKit.scala:406) [info] [JVM-1]   at akka.testkit.TestKit.within(TestKit.scala:973) [info] [JVM-1]   at akka.testkit.TestKitBase.within(TestKit.scala:433) [info] [JVM-1]   at akka.testkit.TestKitBase.within$(TestKit.scala:433) [info] [JVM-1]   at akka.testkit.TestKit.within(TestKit.scala:973) [info] [JVM-1]   at akka.remote.artery.aeron.AeronStreamLatencySpec.$anonfun$test$1(AeronStreamLatencySpec.scala:207) [info] [JVM-1]   at akka.remote.testkit.MultiNodeSpec.runOn(MultiNodeSpec.scala:412) [info] [JVM-1]   at akka.remote.artery.aeron.AeronStreamLatencySpec.test(AeronStreamLatencySpec.scala:170) [info] [JVM-1]   at akka.remote.artery.aeron.AeronStreamLatencySpec.$anonfun$new$6(AeronStreamLatencySpec.scala:321) ``` ",,patriknw; pvlugter; johanandren; octonato
31776,giena,2022-12-02T12:34:46Z,2022-12-07T12:20:57Z,johanandren,giena; johanandren,Improve groupBy stream example,"Hi   I think the function is a bad idea in this example: https://doc.akka.io/docs/akka/current/stream/operators/Source-or-Flow/groupBy.html#example  https://github.com/akka/akka/blob/7abc41cf4e7e8827393b181cd06c5f8ea684e696/akka-docs/src/test/scala/docs/stream/operators/sourceorflow/GroupBy.scala#L16  Since   .groupBy(maxSubstreams = 8  _ % 8 == 0) // create two sub-streams with odd and even numbers will still create 2 substreams.  .groupBy(maxSubstreams = 2  _ % 2) // create two sub-streams with odd and even numbers is better IMHO. ",,giena; johanandren
31769,JustinPihony,2022-11-28T18:44:39Z,2023-03-08T14:48:23Z,johanandren,patriknw; johanandren,Update Algolia key to use the commercial one,We should also have this as an environment variable.,,patriknw; johanandren
31764,patriknw,2022-11-25T11:11:21Z,2022-11-29T10:50:16Z,patriknw,He-Pin,Remove deprecated classic remoting,"Classic Remoting transport has been deprecated since Akka 2.6.0 (2019-11-06) and is replaced by the Artery transport  which has been the default since 2.6.0 and declared ready for production in Akka 2.5.22 (2019-04-03).",.github/workflows/nightly-builds.yml; akka-actor-typed-tests/src/test/scala/akka/actor/typed/internal/ActorRefSerializationSpec.scala; akka-actor/src/main/scala/akka/actor/ActorSystem.scala; akka-bench-jmh/src/main/scala/akka/cluster/ddata/ORSetSerializationBenchmark.scala; akka-bench-jmh/src/main/scala/akka/remote/artery/CodecBenchmark.scala; akka-cluster-metrics/src/multi-jvm/scala/akka/cluster/metrics/sample/StatsSampleSpec.scala; akka-cluster-metrics/src/test/scala/akka/cluster/metrics/TestUtil.scala; akka-cluster-metrics/src/test/scala/akka/cluster/metrics/WeightedRouteesSpec.scala; akka-cluster-metrics/src/test/scala/akka/cluster/metrics/protobuf/MessageSerializerSpec.scala; akka-cluster-sharding-typed/src/multi-jvm/scala/akka/cluster/sharding/typed/ClusterShardingPreparingForShutdownSpec.scala; akka-cluster-sharding-typed/src/test/java/akka/cluster/sharding/typed/ReplicatedShardingTest.java; akka-cluster-sharding-typed/src/test/java/akka/cluster/sharding/typed/javadsl/ClusterShardingPersistenceTest.java; akka-cluster-sharding-typed/src/test/java/jdocs/akka/cluster/sharding/typed/AccountExampleTest.java; akka-cluster-sharding-typed/src/test/java/jdocs/akka/cluster/sharding/typed/HelloWorldEventSourcedEntityExampleTest.java; akka-cluster-sharding-typed/src/test/scala/akka/cluster/sharding/typed/JoinConfigCompatCheckerClusterShardingSpec.scala; akka-cluster-sharding-typed/src/test/scala/akka/cluster/sharding/typed/ReplicatedShardingSpec.scala; akka-cluster-sharding-typed/src/test/scala/akka/cluster/sharding/typed/delivery/DurableShardingSpec.scala; akka-cluster-sharding-typed/src/test/scala/akka/cluster/sharding/typed/delivery/ReliableDeliveryShardingSpec.scala; akka-cluster-sharding-typed/src/test/scala/akka/cluster/sharding/typed/scaladsl/ClusterShardingPersistenceSpec.scala; akka-cluster-sharding-typed/src/test/scala/akka/cluster/sharding/typed/scaladsl/ClusterShardingSpec.scala; akka-cluster-sharding-typed/src/test/scala/akka/cluster/sharding/typed/scaladsl/ShardedDaemonProcessSpec.scala; akka-cluster-sharding-typed/src/test/scala/docs/akka/cluster/sharding/typed/AccountExampleSpec.scala; akka-cluster-sharding-typed/src/test/scala/docs/akka/cluster/sharding/typed/HelloWorldEventSourcedEntityExampleSpec.scala; akka-cluster-sharding/src/multi-jvm/scala/akka/cluster/sbr/GremlinController.scala; akka-cluster-sharding/src/multi-jvm/scala/akka/cluster/sbr/SplitBrainResolverIntegrationSpec.scala; akka-cluster-sharding/src/multi-jvm/scala/akka/cluster/sharding/ClusterShardCoordinatorDowning2Spec.scala; akka-cluster-sharding/src/multi-jvm/scala/akka/cluster/sharding/ClusterShardCoordinatorDowningSpec.scala; akka-cluster-sharding/src/multi-jvm/scala/akka/cluster/sharding/ClusterShardingFailureSpec.scala; akka-cluster-sharding/src/multi-jvm/scala/akka/cluster/sharding/ClusterShardingSingleShardPerEntitySpec.scala; akka-cluster-sharding/src/multi-jvm/scala/akka/cluster/sharding/MultiDcClusterShardingSpec.scala,patriknw
31761,johanandren,2022-11-23T17:58:07Z,2022-11-25T09:24:25Z,patriknw,ennru,Failed: Multi node tests broken,"https://github.com/akka/akka/actions/runs/3528725586/jobs/5919118579#step:5:9 https://github.com/akka/akka/actions/runs/3528725586/jobs/5919118732#step:5:21",,ennru
31760,johanandren,2022-11-23T17:55:17Z,2022-11-29T08:07:49Z,johanandren,ennru; patriknw; johanandren,Compilation error on JDK 8,"https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878951#step:5:28024 https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:5:28463  At least I think that is it  not entirely clear from output",,ennru; patriknw; johanandren
31759,johanandren,2022-11-23T17:51:34Z,2022-11-25T09:23:45Z,patriknw,ennru,Test report publishing not working,"In the nightlies:  https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:1  ``` Run scacap/action-surefire-report@482f012643ed0560e23ef605a79e8e87ca081648 [2](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:2)   with: [3](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:3)     report_paths: **/target/test-reports/TEST-*.xml [4](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:4)     fail_if_no_tests: false [5](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:5)     github_token: *** [6](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:6)     check_name: Test Report [7](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:7)     fail_on_test_failures: false [8](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:8)     skip_publishing: false [9](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:9)   env: [10](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:10)     JAVA_HOME: /home/runner/.cache/coursier/arc/https/github.com/adoptium/temurin8-binaries/releases/download/jdk8u352-b08/OpenJDK8U-jdk_x64_linux_hotspot_8u352b08.tar.gz/jdk8u352-b08 [11](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:11)     COURSIER_BIN_DIR: /home/runner/cs/bin [12](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:13) Going to parse results form **/target/test-reports/TEST-*.xml [13](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:14) Result: 7622 tests run  475 skipped  0 failed. [14](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:15) Posting status 'completed' with conclusion 'success' to refs/heads/main (sha: 85aa7f965d191fce96d3f9aa9ee078f856bde7b3) [15](https://github.com/akka/akka/actions/runs/3528120611/jobs/5917878694#step:6:16) Error: Resource not accessible by integration ```  (ping @ennru )",,ennru
31756,patriknw,2022-11-22T10:13:53Z,2022-11-22T11:57:04Z,patriknw,,Release 2.8.0-M1,"Release Akka 2.8.0-M1  <!-- # Release Train Issue Template for Akka  (Liberally copied and adopted from Scala itself https://github.com/scala/scala-dev/blob/b11cd2e4a4431de7867db6b39362bea8fa6650e7/notes/releases/template.md)  For every release  use the `scripts/create-release-issue.sh` to make a copy of this file named after the release  and expand the variables.  Variables to be expanded in this template: - 2.8.0-M1=???  Key links:   - akka/akka milestone: https://github.com/akka/akka/milestone/? -->  ### Cutting the release  - [x] Check that open PRs and issues assigned to the milestone are reasonable - [x] For minor or major versions  update the Change date in the LICENSE file and update the `licenses` url in the build. - [x] Create a new milestone for the [next version](https://github.com/akka/akka/milestones) - [x] Close the [2.8.0-M1 milestone](https://github.com/akka/akka/milestones?direction=asc&sort=due_date) - [x] Make sure all important PRs have been merged - [x] Update the revision in Fossa in the Akka Group for the Akka umbrella version  e.g. `22.10`. Note that the revisions for the release is udpated by Akka Group > Projects > Edit. For recent dependency updates the Fossa validation can be triggered from the GitHub actions ""Dependency License Scanning"". - [x] Wait until [main build finished](https://github.com/akka/akka/actions) after merging the latest PR - [x] Update the [draft release](https://github.com/akka/akka/releases) with the next tag version `v2.8.0-M1`  title and release description. Use the `Publish release` button  which will create the tag. - [x] Check that GitHub Actions release build has executed successfully (GitHub Actions will start a [CI build](https://github.com/akka/akka/actions) for the new tag and publish artifacts to Maven central via Sonatype)  ### Check availability  - [x] Check [API](https://doc.akka.io/api/akka/2.8.0-M1/) documentation - [x] Check [reference](https://doc.akka.io/docs/akka/2.8.0-M1/) documentation. Check that the reference docs were deployed and show a version warning (see section below on how to fix the version warning). - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.8.0-M1/)  ### When everything is on maven central   - [x] Log into `gustav.akka.io` as `akkarepo`      - [x] If this updates the `current` version  run `./update-akka-current-version.sh 2.8.0-M1`     - [x] otherwise check changes and commit the new version to the local git repository          ```          cd ~/www          git status          git add docs/akka/current docs/akka/2.8.0-M1          git add api/akka/current api/akka/2.8.0-M1          git add japi/akka/current japi/akka/2.8.0-M1          git commit -m ""Akka 2.8.0-M1""          ```     - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)          ```          cd ~/www          git push origin master          ```   - [ ] Update version in _config.yml in https://github.com/akka/akka.io      ### Announcements  For important patch releases  and only if critical issues have been fixed:  - [ ] Send a release notification to [Lightbend discuss](https://discuss.akka.io) - [ ] Tweet using the [@akkateam](https://twitter.com/akkateam/) account (or ask someone to) about the new release - [ ] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [ ] Announce internally (with links to Tweet  discuss)  For minor or major releases:  - [ ] Include noteworthy features and improvements in Akka umbrella release announcement at akka.io. Coordinate with PM and marketing.  ### Afterwards  - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`) - [ ] Update version for [Lightbend Supported Modules](https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html) in [private project](https://github.com/lightbend/lightbend-technology-intro-doc/blob/master/docs/modules/getting-help/examples/build.sbt) - [ ] Update [akka-dependencies bom](https://github.com/lightbend/akka-dependencies) - [ ] Update [Akka Guide samples](https://github.com/akka/akka-platform-guide) - [ ] Update [akka-samples](https://github.com/akka/akka-samples) - These are autoupdated by latest stable on maven central:   - https://github.com/akka/akka-quickstart-java.g8   - https://github.com/akka/akka-quickstart-scala.g8   - https://github.com/akka/akka-http-quickstart-java.g8   - https://github.com/akka/akka-http-quickstart-scala.g8   - https://github.com/akka/akka-grpc-quickstart-java.g8   - https://github.com/akka/akka-grpc-quickstart-scala.g8 - Close this issue ",,patriknw
31752,patriknw,2022-11-21T11:29:30Z,2022-11-21T14:15:21Z,patriknw,,DurableStateBehavior delete effect running in background,"Deletes are running in the background and the side effects are applied immediately without waiting for the confirmation from the store. Next command is also processed immediately without waiting (stashing).  Background reason for this is that delete of events in EventSourcedBehavior are background tasks  which makes sense for event sourced but not for durable state.",akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/state/scaladsl/DurableStateBehaviorReplySpec.scala; akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/state/scaladsl/DurableStateBehaviorSpec.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/state/internal/DurableStateStoreInteractions.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/state/internal/Running.scala,patriknw
31729,He-Pin,2022-11-14T09:44:56Z,2022-11-17T08:19:52Z,johanandren,He-Pin,Avoid subMaterialization for lazyFuture,It currently implemented by `lazySource` which will require a sub materialization.,,He-Pin
31724,steffenhaak,2022-11-10T09:45:27Z,2022-12-13T09:11:52Z,johanandren,johanandren; steffenhaak,Akka Discovery fails on SRV Lookup,"**Expected** `akka.discovery.ServiceDiscovery.lookup(""_cql._tcp.cassandra.default.svc.cluster.local""  resolveTimeout)` will use SRV lookup and provide nodes with ports.  **Actual** A/AAAA lookup is used and fails. Instead `akka.discovery.ServiceDiscovery.lookup(Lookup(""cassandra.default.svc.cluster.local""  Some(""cql"")  Some(""tcp"") )  resolveTimeout)` would have to be used.  **Problem** Neither Alpakka Cassandra nor Alpakka Kafka recognize the SRV pattern in the service name. So Akka Persistence Cassandra and Akka Projection Kafka currently are not able to discover Kubernetes services through Akka DNS.  **Proposed Change** Changing lines 106 to 111 in akka.discovery.dns.DnsServiceDiscovery from  ```   override def lookup(lookup: Lookup  resolveTimeout: FiniteDuration): Future[Resolved] = {     if (lookup.portName.isDefined && lookup.protocol.isDefined)       lookupSrv(lookup  resolveTimeout)     else       lookupIp(lookup  resolveTimeout)   } ``` to  ```   override def lookup(lookup: Lookup  resolveTimeout: FiniteDuration): Future[Resolved] = {     if (lookup.portName.isDefined && lookup.protocol.isDefined)       lookupSrv(lookup  resolveTimeout)     else {       if (Lookup.isValidSrv(lookup.serviceName)) {         lookupSrv(Lookup.parseSrv(lookup.serviceName)  resolveTimeout)       } else {         lookupIp(lookup  resolveTimeout)       }     }   } ```  would fix the issue.  <!-- Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka HTTP: https://github.com/akka/akka-http/issues  - Alpakka:   https://github.com/akka/alpakka/issues  - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your issue precisely  and if possible provide a reproducer snippet (this helps resolve issues much quicker).  Thanks  happy hakking! --> ",akka-discovery/src/main/scala/akka/discovery/ServiceDiscovery.scala,johanandren
31720,He-Pin,2022-11-06T09:49:53Z,2022-11-16T07:56:52Z,He-Pin,,Feature request: Add a `Source.queue` variant which returns a `BlockingQueue` materialized value?,I think this will be helpful when interact with the some blocking part  which act like a `SynchronousQueue`.,,He-Pin
31717,Roiocam,2022-11-03T07:07:18Z,2022-11-15T13:27:25Z,patriknw,aludwiko; johanandren; Roiocam,persistence delete event version calculate make integer overflow.,"check    akka.persistence.typed.internal.RetentionCriteriaImpl.scala#deleteUpperSequenceNr  [ math.max(0  lastSequenceNr - (keepNSnapshots * snapshotEveryNEvents))](https://github.com/akka/akka/blob/43d94bd42afae22f22e4d62563b2b65d11f3747f/akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/RetentionCriteriaImpl.scala#L29)  when I am using configuration that `keepNSnapshots = Integer.MAX_VALUE`  it will complain log like this  the debug result it was Integer overflow  make the result `deleteEventsToSeqNr` is negative.  <img width=""1086"" alt=""截屏2022-11-03 15 05 16"" src=""https://user-images.githubusercontent.com/26020358/199663781-d19fdaf8-a862-40d3-b381-0c2373f2569a.png"">  ",,aludwiko; johanandren; Roiocam
31715,studyandstudy,2022-11-02T09:28:52Z,2022-11-16T11:03:50Z,patriknw,johanandren,lease is not working fine when used by cluster sharding,"cluster sharding only try acquire lease but not release it when shard rebanlanced ![image](https://user-images.githubusercontent.com/39394298/199453798-249dde4b-ac8d-4847-b103-faf37392307b.png) ",akka-cluster-sharding/src/main/scala/akka/cluster/sharding/Shard.scala,johanandren
31711,He-Pin,2022-10-31T08:12:09Z,2022-10-31T08:55:00Z,johanandren,johanandren,Flow#keepAlive cause error when onTimer triggered,"Hi team  I just encounter this problem.  usage: ```java         if (keepAliveEnabled) {             final int keepAliveInSeconds = bizConfig.getKeepAliveInSeconds();             groupedSource = groupedSource                 .keepAlive(                     Duration.ofSeconds(Math.max(keepAliveInSeconds  1))                      (Creator<List<MergeClass>>) () -> keepAliveMessageProvider.getKeepAliveMergeClass(namespace  topic));         } ```  Error when offering `akka.stream.BoundedSourceQueue#offer`: ![lQLPJxbUSNrGjWLNA3vNBz6wf0O9ctWCF9gDXN-VmgAFAA_1854_891](https://user-images.githubusercontent.com/501740/198961472-940e27a7-3dd5-458e-9327-51d4164aa3ea.png)  ![image](https://user-images.githubusercontent.com/501740/198964123-c7655b59-06dd-4e30-946e-a622809b4779.png)  ![lQLPJxbUSSVIAf3NAk3NB0ywhRB847yuSeEDXOAPOoA2AA_1868_589](https://user-images.githubusercontent.com/501740/198961506-be3ae334-c364-4ee4-9bbe-f0c7f648b669.png)  My keep alive time is `30s`.  I'm still try to find the root cause  thanks. ",,johanandren
31705,He-Pin,2022-10-28T04:41:33Z,2022-11-23T14:45:28Z,patriknw,patriknw,High resolution ticker support?,"In current Akka  the default timer is from `System.nano...` or `System.currentTimeInMillis`  how about change add a Clock interface for that? https://github.com/OpenHFT/Chronicle-Ticker seems providing lower latency. ![image](https://user-images.githubusercontent.com/501740/198505521-ed90ee41-69b4-4fce-ba0c-20be8b2eced0.png) ",,patriknw
31698,octonato,2022-10-24T14:09:31Z,2022-10-27T11:32:21Z,octonato,,Failed: multi-node tests failing to deploy due to docker container issue,"```java ERROR: (gcloud.container.clusters.create) ResponseError: code=400  message=Creation of node pools using node images based on Docker container runtimes is not supported in GKE v1.23. This is to prepare for the removal of Dockershim in Kubernetes v1.24. We recommend that you migrate to image types based on Containerd (examples). For more information  contact Cloud Suppor ```  Failing consistency. Simply put  multi-node tests are broken due to some unsupported usage we have. It seems that GKE was upgraded and now our build is broken?  ",kubernetes/create-cluster-gke.sh,patriknw
31692,patriknw,2022-10-19T07:48:47Z,2022-11-08T07:53:47Z,patriknw,,Release Akka 2.7.0,"### Before the release  - [x] Make sure all important / big PRs have been merged by now - [x] Create a news item draft PR on [akka.io](https://github.com/akka/akka.io)  using the milestone and `scripts/authors.scala v2.6.14 v2.6.15` - [x] Make sure to update `_config.yml` in it - In case of a new minor release:   - [ ] update the branch descriptions at CONTRIBUTING.md#branches-summary  ### Cutting the release  - [x] Make sure any running [actions](https://github.com/akka/akka/actions) for the commit you would like to release have completed. - [ ] Tag the release `git tag -a -s -m 'Release v2.7.0' v2.7.0` and push the tag `git push --tags` - [x] Create a [new milestone](https://github.com/akka/akka/milestones) for the next version and close the current one. - [x] Check that the GitHub Actions release build has executed successfully (it should publish artifacts to Sonatype and documentation to Gustav) - [x] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`)  ### Check availability  - [x] Check [reference](https://doc.akka.io/docs/akka/2.7.0/) documentation - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.7.0/)  ### When everything is on maven central  - [x] `ssh akkarepo@gustav.akka.io`   - [x] update the `current` links on `repo.akka.io` to point to the latest version with        ```        ln -nsf 2.7.0 www/docs/akka/current        ln -nsf 2.7.0 www/api/akka/current        ln -nsf 2.7.0 www/japi/akka/current        ```   - [x] check changes and commit the new version to the local git repository        ```        cd ~/www        git add docs/akka/current docs/akka/2.7.0        git add api/akka/current api/akka/2.7.0        git add japi/akka/current japi/akka/2.7.0        git commit -m ""Akka 2.7.0""        ```   - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)        ```        cd ~/www        git push origin main        ```  ### Announcements  - [x] Merge draft news item for [akka.io](https://github.com/akka/akka.github.com) - [x] Create a [GitHub release](https://github.com/akka/akka/releases) with the next tag version `v2.7.0`  title and a link to the announcement - [x] Post about it on the [forum](https://discuss.akka.io) - [x] Tweet using the [@akkateam](https://twitter.com/akkateam) account (or ask someone to) about the new release - [x] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [x] Announce internally  ## Update references  Update the versions used in:  * [x] https://github.com/akka/akka-samples * [x] https://github.com/lightbend/lightbend-platform-docs/blob/master/docs/modules/getting-help/examples/build.sbt (this populates https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html#_akka)  These are autoupdated by latest stable on maven central: * https://github.com/akka/akka-quickstart-java.g8 * https://github.com/akka/akka-quickstart-scala.g8 * https://github.com/akka/akka-http-quickstart-java.g8 * https://github.com/akka/akka-http-quickstart-scala.g8 * https://github.com/akka/akka-grpc-quickstart-java.g8 * https://github.com/akka/akka-grpc-quickstart-scala.g8",,patriknw
31689,skestle,2022-10-18T23:24:46Z,2022-11-15T13:10:41Z,patriknw,patriknw; jackyscript,"Add color to LogCapturing ""Logging started"" and ""Logging finished""","The default behavior is for LogCapturing to keep logs after each test (https://github.com/akka/akka/blob/main/akka-actor-testkit-typed/src/main/scala/akka/actor/testkit/typed/scaladsl/LogCapturing.scala#L55)  Since this is the case  it'd be really good to add a color to test start and end messages so we can at least easily see when the failed test started (and whether we might need to look back further) (https://github.com/akka/akka/blob/main/akka-actor-testkit-typed/src/main/scala/akka/actor/testkit/typed/scaladsl/LogCapturing.scala#L69) ",akka-actor-testkit-typed/src/main/scala/akka/actor/testkit/typed/javadsl/LogCapturing.scala; akka-actor-testkit-typed/src/main/scala/akka/actor/testkit/typed/scaladsl/LogCapturing.scala,jackyscript
31677,aludwiko,2022-10-17T10:12:19Z,2022-10-17T14:34:32Z,johanandren,aludwiko,PersistenceTestKitDurableStateStore should emit DeletedDurableState,"Currently `akka.persistence.testkit.state.scaladsl.PersistenceTestKitDurableStateStore#changesBySlices` doesn't emit `DeletedDurableState` for deleted durable state. ",,aludwiko
31674,pvlugter,2022-10-17T03:26:51Z,2022-10-27T11:31:53Z,octonato,,Failed: docs.stream.cookbook.RecipeAdhocSource,"https://github.com/akka/akka/actions/runs/3253711477/jobs/5341219952#step:5:10973 https://github.com/akka/akka/actions/runs/3257634599/jobs/5349020934#step:5:10894 https://github.com/akka/akka/actions/runs/3261455837/jobs/5356374302#step:5:10942  ``` [10-15 00:34:04.347] [info] - must restart up to specified maxRetries *** FAILED *** (2 seconds  532 milliseconds) [10-15 00:34:04.347] [info]   class akka.stream.BackpressureTimeoutException was not equal to class java.util.concurrent.TimeoutException (RecipeAdhocSource.scala:121) [10-15 00:34:04.353] [info]   org.scalatest.exceptions.TestFailedException: [10-15 00:34:04.353] [info]   at org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:344) [10-15 00:34:04.353] [info]   at org.scalatest.matchers.should.Matchers$ShouldMethodHelperClass.shouldMatcher(Matchers.scala:6778) [10-15 00:34:04.353] [info]   at org.scalatest.matchers.should.Matchers$AnyShouldWrapper.should(Matchers.scala:6822) [10-15 00:34:04.354] [info]   at docs.stream.cookbook.RecipeAdhocSource.$anonfun$new$12(RecipeAdhocSource.scala:121) ```",akka-docs/src/test/java/jdocs/stream/javadsl/cookbook/RecipeAdhocSourceTest.java; akka-docs/src/test/scala/docs/stream/cookbook/RecipeAdhocSource.scala,patriknw
31671,He-Pin,2022-10-15T06:32:23Z,2023-04-17T08:48:20Z,johanandren,,Flow onErrorComplete completing when failed,"        Adding `recoverWithComplete` is fine  _Originally posted by @patriknw in https://github.com/akka/akka/pull/24985#discussion_r184636660_    and           I like this  together with #31640 it nicely covers the various timeout scenarios.   I wonder if we should skip the no-param variation though  handing it `Throwable` in user code seems concise enough for the catch-all IMO.  Also not sure about the name  should it rather be something like `completeOn[IdleTimeoutException]`? Recover would be to turn the stream back into something working  but this operator always completes.  _Originally posted by @johanandren in https://github.com/akka/akka/pull/31639#pullrequestreview-1128374415_        scaladsl ```scala   def completeOn(pf: PartialFunction[Throwable  Boolean]): Repr[Out]    def completeOn[T <: Throwable](implicit tag: ClassTag[T]): Repr[Out] ```  javadsl ```scala def completeOn(clazz: Class[_ <: Throwable]): javadsl.Flow[In  Out  Mat] def completeOn(predicate: java.util.function.Predicate[_ >: Throwable]): javadsl.Flow[In  Out  Mat] ```     refs: https://github.com/akka/akka/pull/24985 refs: https://github.com/akka/akka/issues/31455 refs:https://github.com/akka/akka/issues/24951 refs: https://github.com/akka/akka/issues/31555 ",,johanandren
31670,He-Pin,2022-10-15T06:25:30Z,2023-03-02T16:18:34Z,johanandren,,Remove the deprecation of `Flow#recoverWith`,"As working on https://github.com/akka/akka/pull/31639 and https://github.com/akka/akka/pull/31669  I found that the `recoverWith` is deprecated. when digging further  I think it's a mistaken to deprecate it and we should remove the deprecation.  And in issue https://github.com/akka/akka/issues/24992  @patriknw pointed out that: > By the way  I suggest removing the deprecation of `recoverWith` since I think in most of the time the attempt count is not interesting  especially since there is no reset of the count or notion of failures per time unit.  As for the change  I think the only change  need to do is just updated the java/scala doc about if you prefer to limit the maximum retring times  use `RecoverWithRetries`.  ",akka-stream/src/main/scala/akka/stream/javadsl/Flow.scala; akka-stream/src/main/scala/akka/stream/javadsl/Source.scala; akka-stream/src/main/scala/akka/stream/javadsl/SubFlow.scala; akka-stream/src/main/scala/akka/stream/javadsl/SubSource.scala; akka-stream/src/main/scala/akka/stream/scaladsl/Flow.scala,RichardMarto
31664,He-Pin,2022-10-14T04:00:10Z,2023-03-10T11:44:29Z,patriknw,patriknw,Remove deprecations since 2.5.x,"Since 2.7.x is on the way  I think it should be better to remove methods those deprecated since 2.5.x ![image](https://user-images.githubusercontent.com/501740/195759598-60b6ea08-4c26-4aac-aebb-12177029ca4a.png) ",,patriknw
31660,JananiRavichandranDFI,2022-10-12T13:08:32Z,2022-10-12T14:52:31Z,johanandren,He-Pin; johanandren,Getting 'LocalActorRefProvider(akka://APIX) : guardian failed  shutting down system' Error,"We are currently using akka-actor_2.10-2.3.8  Getting the below error and we couldn't able to find the root cause with the provided log.   LocalActorRefProvider(akka://APIX)       : guardian failed  shutting down system java.lang.StackOverflowError: null 	at java.lang.Exception.<init>(Exception.java:102) 	at java.lang.ReflectiveOperationException.<init>(ReflectiveOperationException.java:89) 	at java.lang.reflect.InvocationTargetException.<init>(InvocationTargetException.java:72) 	at sun.reflect.GeneratedMethodAccessor998.invoke(Unknown Source) 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) 	at java.lang.reflect.Method.invoke(Method.java:498) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:66) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:60) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:72) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:60) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:72) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:60) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:72) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:60) . . .    akka.actor.OneForOneStrategy             : null java.lang.StackOverflowError: null 	at java.lang.Exception.<init>(Exception.java:102) 	at java.lang.ReflectiveOperationException.<init>(ReflectiveOperationException.java:89) 	at java.lang.reflect.InvocationTargetException.<init>(InvocationTargetException.java:72) 	at sun.reflect.GeneratedMethodAccessor998.invoke(Unknown Source) 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) 	at java.lang.reflect.Method.invoke(Method.java:498) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:66) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:60) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:72) 	at ch.qos.logback.classic.spi.ThrowableProxy.<init>(ThrowableProxy.java:60) . . .",,He-Pin; johanandren
31658,johanandren,2022-10-12T11:59:19Z,2022-10-13T07:57:01Z,johanandren,He-Pin; johanandren,Failed: genjavadoc,We are waiting for a Scala 2.13.10 release of genjavadoc,,He-Pin; johanandren
31653,He-Pin,2022-10-12T09:05:47Z,2022-10-14T11:47:34Z,He-Pin,He-Pin; johanandren,Add an overloaded method for `scheduler.scheduleOnce` etc which accepts an Executor for JavaApi?,"I have to wrap it as an ExecutionContext For now: ```java                     final Scheduler scheduler = actorSystem.getScheduler();                     final ExecutionContext executor = sendMessageExecutorProvider.getExecutionContext(namespace);                     return scheduler.scheduleOnce(                         Duration.ofMillis(timeBeforeFlushInMills)                          () -> {                            //do something ...                         }                          executor); ```",,He-Pin; johanandren
31650,ennru,2022-10-10T08:48:37Z,2022-10-10T12:52:39Z,ennru,ennru; patriknw,Broken links in 2.7,"The link validator is unhappy about some links. Some look like wrong `@scaladoc` notations.  https://github.com/akka/akka/actions/runs/3217255524/jobs/5260014882#step:8:56  ## HTTP failure response `https://doc.akka.io/api/akka/0.0.0+1-a6863e9e-SNAPSHOT/StageLogging.html` status 404 Not Found  - stream/stream-customize.html  `https://doc.akka.io/japi/akka/2.7/akka/actor/typed/javadsl/AbstractOnMessageBehavior.html` status 404 Not Found  - typed/actors.html  `https://doc.akka.io/japi/akka/2.7/akka/cluster/sharding/ShardRegion.ClusterShardingStats.html` status 404 Not Found  - typed/cluster-sharding.html  `https://doc.akka.io/japi/akka/2.7/akka/cluster/sharding/ShardRegion.CurrentShardRegionState.html` status 404 Not Found  - typed/cluster-sharding.html  `https://www.lightbend.com/contribute/cla/akka/current` status 404 Not Found  - project/licenses.html",,ennru; patriknw
31649,pvlugter,2022-10-09T22:50:39Z,2022-10-12T12:05:34Z,johanandren,johanandren,Failed: Fossa vulnerability - jackson-databind ,"Fossa check failed with vulnerability for `com.fasterxml.jackson.core:jackson-databind 2.13.4`  https://github.com/akka/akka/actions/runs/3208417079/jobs/5244248990  CVE-2022-42003: https://nvd.nist.gov/vuln/detail/CVE-2022-42003",,johanandren
31647,He-Pin,2022-10-08T10:38:20Z,2022-10-10T19:05:13Z,He-Pin,He-Pin; johanandren,Add Flow#`zipWithNext`  `zipWithPrevious` and `zipWithPreviousAndNext`?,These kind of operators present in fs2 and zio  and are useful in IOT scenario.,,He-Pin; johanandren
31646,lfygh,2022-10-08T06:26:22Z,2022-10-10T11:45:51Z,patriknw,patriknw; johanandren,akka-stream_2.13:2.5.32 stream.materializer.subscription-timeout not work?,"  akka-stream_2.13:2.5.32 stream.materializer.subscription-timeout not work? is ture?",,patriknw; johanandren
31641,ennru,2022-10-03T13:04:36Z,2022-11-08T13:34:06Z,johanandren,johanandren,Link errors,"The link validator discovered some 404s that look legit: https://github.com/akka/akka/actions/runs/3171947397/jobs/5165898120#step:8:59  ## HTTP failure response [`https://doc.akka.io/api/akka/0.0.0+1-77d757c4-SNAPSHOT/StageLogging.html`](https://doc.akka.io/api/akka/0.0.0+1-77d757c4-SNAPSHOT/StageLogging.html) status 404 Not Found  - stream/stream-customize.html    [`https://doc.akka.io/japi/akka/2.7/akka/actor/typed/javadsl/AbstractOnMessageBehavior.html`](https://doc.akka.io/japi/akka/2.7/akka/actor/typed/javadsl/AbstractOnMessageBehavior.html) status 404 Not Found  - typed/actors.html    [`https://doc.akka.io/japi/akka/2.7/akka/cluster/sharding/ShardRegion.ClusterShardingStats.html`](https://doc.akka.io/japi/akka/2.7/akka/cluster/sharding/ShardRegion.ClusterShardingStats.html) status 404 Not Found  - typed/cluster-sharding.html  [`https://doc.akka.io/japi/akka/2.7/akka/cluster/sharding/ShardRegion.CurrentShardRegionState.html`](https://doc.akka.io/japi/akka/2.7/akka/cluster/sharding/ShardRegion.CurrentShardRegionState.html) status 404 Not Found  - typed/cluster-sharding.html  [`https://www.lightbend.com/contribute/cla/akka/current`](https://www.lightbend.com/contribute/cla/akka/current) status 404 Not Found  - project/licenses.html",akka-docs/src/main/paradox/typed/actors.md; akka-docs/src/main/paradox/typed/cluster-sharding.md,johanandren
31637,patriknw,2022-09-29T11:31:01Z,2023-03-22T09:19:54Z,patriknw,,Requirement failed when starting Sharding with separate Coordinator role,"The new feature in https://github.com/akka/akka/pull/31487 doesn't work as expected.  ``` This cluster member [...] doesn't have the role [Some(coordinator)]] ```  Using `akka.cluster.roles` and config: ```   akka.cluster.sharding {     role = shard     coordinator-singleton-role-override = off     coordinator-singleton.role = coordinator   } ```",akka-cluster-sharding/src/main/resources/reference.conf; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/ClusterSharding.scala; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/ClusterShardingSettings.scala; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/ShardCoordinator.scala; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/ShardRegion.scala; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/internal/DDataRememberEntitiesShardStore.scala; akka-cluster-sharding/src/multi-jvm/scala/akka/cluster/sharding/ClusterShardingCoordinatorRoleSpec.scala; akka-distributed-data/src/main/scala/akka/cluster/ddata/Replicator.scala,patriknw
31628,He-Pin,2022-09-28T06:41:47Z,2022-09-29T06:16:27Z,patriknw,patriknw,backport to release-2.6: Fix statefulMap to not call onComplete twice.,"As I noticed when handle with `mapWithResource` https://github.com/akka/akka/pull/31361  this is a bug  so I try to backport it to release 2.6.otherwise user need to do a try catch even the exception we do not expected.  I think it's not a new feature but fix  so hope it can be accepted.  a new need to backport: https://github.com/akka/akka/pull/31630",,patriknw
31623,octonato,2022-09-26T12:31:11Z,2022-11-28T11:42:54Z,johanandren,leviramsey; pvlugter; octonato; patriknw; johanandren,Failed: EventSourcedBehaviorRetentionSpec,"Have been reported before  but then marked as fixed.  This is slightly different than previous reports  so opening a new one.  https://github.com/akka/akka/actions/runs/3120281053/jobs/5060740827#step:5:23326  ```scala [09-25 01:00:25.535] [info] - must be possible to snapshot every event *** FAILED *** (117 milliseconds) [09-25 01:00:25.536] [info]   SnapshotCompleted(SnapshotMetadata(c9) 6 1664067625407)) was not an instance of akka.persistence.typed.DeleteSnapshotsCompleted  but an instance of akka.persistence.typed.SnapshotCompleted (EventSourcedBehaviorRetentionSpec.scala:106) [09-25 01:00:25.542] [info]   org.scalatest.exceptions.TestFailedException: [09-25 01:00:25.543] [info]   at org.scalatest.matchers.MatchersHelper$.newTestFailedException(MatchersHelper.scala:137) [09-25 01:00:25.543] [info]   at org.scalatest.matchers.TypeMatcherHelper$.assertAType(TypeMatcherHelper.scala:162) [09-25 01:00:25.543] [info]   at akka.persistence.typed.scaladsl.EventSourcedBehaviorRetentionSpec$WrappedSignalProbeAssert.expectDeleteSnapshotCompleted(EventSourcedBehaviorRetentionSpec.scala:106) [09-25 01:00:25.543] [info]   at akka.persistence.typed.scaladsl.EventSourcedBehaviorRetentionSpec.$anonfun$new$40(EventSourcedBehaviorRetentionSpec.scala:480) [09-25 01:00:25.543] [info]   at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85) [09-25 01:00:25.543] [info]   at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83) [09-25 01:00:25.543] [info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104) [09-25 01:00:25.543] [info]   at org.scalatest.Transformer.apply(Transformer.scala:22) [09-25 01:00:25.543] [info]   at org.scalatest.Transformer.apply(Transformer.scala:20) [09-25 01:00:25.543] [info]   at org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076) [09-25 01:00:25.544] [info]   at akka.actor.testkit.typed.scaladsl.LogCapturing.withFixture(LogCapturing.scala:70) [09-25 01:00:25.544] [info]   at akka.actor.testkit.typed.scaladsl.LogCapturing.withFixture$(LogCapturing.scala:68) [09-25 01:00:25.544] [info]   at akka.persistence.typed.scaladsl.EventSourcedBehaviorRetentionSpec.withFixture(EventSourcedBehaviorRetentionSpec.scala:117) [09-25 01:00:25.544] [info]   at org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074) [09-25 01:00:25.544] [info]   at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086) ``` ",akka-persistence-testkit/src/main/scala/akka/persistence/testkit/PersistenceTestKitPlugin.scala; akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/scaladsl/EventSourcedBehaviorRetentionSpec.scala; akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/scaladsl/EventSourcedBehaviorRetentionSpec.scala,patriknw
31616,djx314,2022-09-22T07:38:21Z,2022-09-22T07:53:51Z,patriknw,patriknw,New package name for akka,"Since more repo will stay akka 2.6.   Request for new package name and new maven name that make one project can support akka 2.6 and 2.7 in the same time.",,patriknw
31610,He-Pin,2022-09-19T11:32:02Z,2022-09-26T09:09:22Z,patriknw,,Use java.util.function.* in mapWithResource javadsl,"We use our own where we want to allow throwing checked exceptions  like in actor message handling where it makes sense  but here the JDK ones makes more sense indeed.  _Originally posted by @johanandren in https://github.com/akka/akka/pull/31573#discussion_r974099010_",,patriknw
31606,pvlugter,2022-09-18T23:22:10Z,2022-09-19T07:46:57Z,patriknw,He-Pin,Failed: akka stream binary compatibility checks,"https://github.com/akka/akka/actions/runs/3069213127/jobs/4957596316 https://github.com/akka/akka/actions/runs/3069213127/jobs/4957596429  ``` [error] akka-stream: Failed binary compatibility check against com.typesafe.akka:akka-stream_2.12:2.6.20! Found 1 potential problems (filtered 37) [error]  * method onFeedbackDispatched()Unit in class akka.stream.stage.GraphStageLogic does not have a correspondent in current version [error]    filter with: ProblemFilters.exclude[DirectMissingMethodProblem](""akka.stream.stage.GraphStageLogic.onFeedbackDispatched"") ```",,He-Pin
31593,patriknw,2022-09-15T09:04:30Z,2023-01-26T15:30:35Z,octonato,ennru; patriknw,slf4j 2.0.1 and logback 1.4.1,"Logback 1.4.1 depends on slf4j 2.0.1 and that is not fully compatible with 1.7.36 that we are currently using.  In the StubbedActorContext that is used in the BehaviorTestKit it is capturing the markers from `SubstituteLoggingEvent`  but `getMarker` has been replaced with `getMarkers`.  I don't think we want to force an upgrade to slf4j 2.0 yet?",akka-actor-testkit-typed/src/main/scala/akka/actor/testkit/typed/internal/StubbedActorContext.scala; akka-actor-testkit-typed/src/test/scala/akka/actor/testkit/typed/scaladsl/BehaviorTestKitSpec.scala,patriknw
31589,He-Pin,2022-09-14T11:22:05Z,2022-10-09T14:22:28Z,He-Pin,johanandren,SupervisedGraphStageLogic allocates `Some` per element,"![image](https://user-images.githubusercontent.com/501740/190140697-ea5d6836-6dff-4d7c-be0c-09684c38669e.png) ",akka-stream/src/main/mima-filters/2.7.0.backwards.excludes/31589-supervised-grapshtagelogic.backwards.excludes; akka-stream/src/main/scala/akka/stream/impl/fusing/Ops.scala,johanandren
31587,He-Pin,2022-09-14T09:08:40Z,2022-10-11T14:19:57Z,johanandren,He-Pin; patriknw; johanandren,Collect can not filter out elements without demand.,"If you write a filter with collect  then it will failed with ： ```scala     ""complete without demand if remaining elements are filtered out with collect"" in {       Source(1 to 1000).collect({ case elem if elem > 1000 => elem}).runWith(TestSink.probe[Int])         .ensureSubscription()         .expectComplete()     } ``` I think that's because it's not call `pull(in)` at prestart  But the filter operator works that way.",,He-Pin; patriknw; johanandren
31586,He-Pin,2022-09-14T08:49:07Z,2022-09-16T06:19:38Z,patriknw,,Akka docs render error: Output port,"https://doc.akka.io/docs/akka/current/stream/stream-customize.html#custom-processing-with-graphstage ![image](https://user-images.githubusercontent.com/501740/190107632-5e38e70b-c22d-487a-8809-5baeb8d5820e.png) ",akka-docs/src/main/paradox/stream/stream-customize.md,johanandren
31585,He-Pin,2022-09-14T06:35:44Z,2022-09-15T10:12:21Z,patriknw,He-Pin; patriknw; johanandren,Failed: MapWithResourceSpec.MapWithResource must fail when close throws exception,"``` sbt.ForkMain$ForkError: java.lang.AssertionError: assertion failed: expected OnNext(a)  found OnError(akka.stream.testkit.Utils$TE:  ) 	at scala.Predef$.assert(Predef.scala:279) 	at akka.testkit.TestKitBase.expectMsg_internal(TestKit.scala:462) 	at akka.testkit.TestKitBase.expectMsg(TestKit.scala:438) 	at akka.testkit.TestKitBase.expectMsg$(TestKit.scala:438) 	at akka.testkit.TestKit.expectMsg(TestKit.scala:973) 	at akka.stream.testkit.TestSubscriber$ManualProbe.expectNext(StreamTestKit.scala:399) 	at akka.stream.scaladsl.MapWithResourceSpec.$anonfun$new$33(MapWithResourceSpec.scala:247) 	at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85) 	at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83) 	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104) 	at org.scalatest.Transformer.apply(Transformer.scala:22) 	at org.scalatest.Transformer.apply(Transformer.scala:20) 	at org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076) 	at org.scalatest.TestSuite.withFixture(TestSuite.scala:196) 	at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195) 	at akka.stream.testkit.StreamSpec.withFixture(StreamSpec.scala:36) 	at org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074) 	at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086) 	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306) 	at org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086) 	at org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068) 	at akka.testkit.AkkaSpec.runTest(AkkaSpec.scala:54) 	at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145) 	at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413) 	at scala.collection.immutable.List.foreach(List.scala:333) 	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401) 	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390) 	at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427) 	at scala.collection.immutable.List.foreach(List.scala:333) 	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401) 	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396) 	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475) 	at org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145) 	at org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144) 	at akka.testkit.AkkaSpec.runTests(AkkaSpec.scala:54) 	at org.scalatest.Suite.run(Suite.scala:1112) 	at org.scalatest.Suite.run$(Suite.scala:1094) 	at akka.testkit.AkkaSpec.org$scalatest$wordspec$AnyWordSpecLike$$super$run(AkkaSpec.scala:54) 	at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190) 	at org.scalatest.SuperEngine.runImpl(Engine.scala:535) 	at org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190) 	at org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188) 	at akka.testkit.AkkaSpec.org$scalatest$BeforeAndAfterAll$$super$run(AkkaSpec.scala:54) 	at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213) 	at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210) 	at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208) 	at akka.testkit.AkkaSpec.run(AkkaSpec.scala:54) 	at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318) 	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513) 	at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:413) 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) ```  https://github.com/akka/akka/runs/8341017910 ",,He-Pin; patriknw; johanandren
31583,t5kaji,2022-09-14T01:41:58Z,2022-09-15T09:37:47Z,t5kaji,t5kaji; patriknw,Avoid name collisions in MessageFormats.proto in non-Java  non-Scala languages,"<!-- Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka HTTP: https://github.com/akka/akka-http/issues  - Alpakka:   https://github.com/akka/alpakka/issues  - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your use case precisely  and if possible provide an example snippet.  Thanks  happy hakking! --> Hi  we've used akka-persistence to construct a system based on event sourcing  and we've adopted Rust to implement an application to consume event data from journal database. In order to consume persistent message data from journal database and decode it  we compile MessageFormats.proto and generate some Rust codes for serialization/deserialization because event data contains bytes serialized via MessageFormats.proto.  Currently  MessageFormats.proto's only defined java_package  which prevents non-Java  non-Scala users from compiling this file with namespace attached to it (https://github.com/akka/akka/blob/main/akka-persistence/src/main/protobuf/MessageFormats.proto#L7) Since it's recommended to ""still define a normal package as well to avoid name collisions in the Protocol Buffers name space as well as in non-Java languages"" according to official document on Protocol Buffer (https://developers.google.com/protocol-buffers/docs/javatutorial#defining-your-protocol-format)  I'd like to define ""package"" as well in MessageFormats.proto.  Could I add ""package"" to it? ",,t5kaji; patriknw
31580,nate100guess,2022-09-13T07:16:56Z,2022-09-14T10:07:45Z,patriknw,patriknw,>How would light bend enforce the pricing in a variable workload environment?,">How would light bend enforce the pricing in a variable workload environment?   I have an idea: there will be a daemon running in akka  which will phone home with actual number of available CPU cores every minute or so and Lightbend will send a bill for max reported number during the year :)   With rolling updates it will be even more fun - instead of regular X instances we will run X+\<maxSurge\> instances!  _Originally posted by @mr-git in https://github.com/akka/akka/issues/31561#issuecomment-1244994777_",,patriknw
31577,He-Pin,2022-09-12T11:20:27Z,2022-09-26T09:32:56Z,patriknw,johanandren,SubFlow and SubSource in javadsl should be final class.,I think these class should be marked as `final class`.,,johanandren
31576,Zhen-hao,2022-09-11T13:35:12Z,2022-09-13T07:09:53Z,patriknw,He-Pin; patriknw; Zhen-hao,Akka 2.6.20 might have broken the usage of Aeron UDP,"After upgrading to Akka 2.6.20  I saw extremely high CPU usage and unrecoverable Aeron runtime error on a cluster running Java17.  I hope the following logs can help diagnose the issue.   ``` Sep 10 17:42:16 app1 nt-ui[279640]: Fatal Aeron error DriverTimeoutException. Have to terminate ActorSystem because it lost contact with the embedded Aeron media driver. Possible configuration properties to mitigate the problem are 'client-liveness-timeout' or 'driver-timeout'. io.aeron.exceptions.DriverTimeoutException: FATAL - MediaDriver keepalive (ms): age=20992 > timeout=20000 Sep 10 17:42:16 app1 nt-ui[279640]: Cluster Node [akka://nt-ui@172.16.16.122:2552] - Scheduled sending of heartbeat was delayed. Previous heartbeat was sent [5486] ms ago  expected interval is [1000] ms. This may cause failure detection to mark members as unreachable. The reason can be thread starvation  CPU overload  or GC. Sep 10 17:42:16 app1 nt-ui[279640]: Cluster Node [akka://nt-ui@172.16.16.122:2552] - Scheduled sending of heartbeat was delayed. Previous heartbeat was sent [236324] ms ago  expected interval is [1000] ms. This may cause failure detection to mark members as unreachable. The reason can be thread starvation  CPU overload  or GC. Sep 10 17:42:16 app1 nt-ui[279640]: Aeron error  org.agrona.concurrent.AgentTerminationException ```  and   ``` Sep 11 03:33:12 app1 nt-ui[281262]: Fatal Aeron error DriverTimeoutException. Have to terminate ActorSystem because it lost contact with the embedded Aeron media driver. Possible configuration properties to mitigate the problem are 'client-liveness-timeout' or 'driver-timeout'. io.aeron.exceptions.DriverTimeoutException: FATAL - MediaDriver keepalive (ms): age=20341 > timeout=20000 Sep 11 03:33:13 app1 nt-ui[281262]: Running CoordinatedShutdown with reason [ActorSystemTerminateReason] Sep 11 03:33:14 app1 nt-ui[281262]: Aeron error  org.agrona.concurrent.AgentTerminationException ```   After reverting back to Akka 2.6.19  the Aeron error is gone.  I can confirm the Aeron version isn't a problem. With Akka 2.6.19  both Aeron 1.39.0 and 1.38.2 work without giving the same runtime error as with Akka 2.6.20.    ",,He-Pin; patriknw; Zhen-hao
31569,an-tex,2022-09-09T09:40:31Z,2022-09-23T15:21:37Z,johanandren,an-tex; patriknw; johanandren,Optimized JsonFraming breaks existing functionality in v2.6.20,"The JsonFraming optimization in https://github.com/akka/akka/pull/31380 breaks existing functionality by differently handling the `maximumObjectLength` parameter. E.g. if you set the parameter to fit in the longest element but not the whole stream  the flow fails with an error `JSON element exceeded maximumObjectLength`  I've changed the existing test case to showcase the issue. The test case   passes on the [v2.6.19 tag](https://github.com/an-tex/akka/blob/jsonframing_2.6.19/akka-stream-tests/src/test/scala/akka/stream/scaladsl/JsonFramingSpec.scala#L34)  but failes on the [v2.6.20 tag](https://github.com/an-tex/akka/blob/jsonframing_2.6.20/akka-stream-tests/src/test/scala/akka/stream/scaladsl/JsonFramingSpec.scala#L34)",akka-stream-tests/src/test/scala/akka/stream/scaladsl/JsonFramingSpec.scala; akka-stream/src/main/scala/akka/stream/impl/JsonObjectParser.scala,patriknw
31567,guiwoda-inviu,2022-09-08T16:58:33Z,2022-09-09T18:49:44Z,guiwoda-inviu,guiwoda-inviu; johanandren,Akka 2.6.19: Unable to update jackson to 2.13 to avoid vulnerabilities,"I've created [this demo repository](https://github.com/guiwoda-inviu/akka-2.19-jackson-2.13-bug) using:  - Actor typed - Serialization jackson - Persistence + testkit  To demonstrate that  in Akka 2.6.19  trying to override the dependency on a vulnerable jackson version (2.11) to a non-vulnerable version (2.13.4) is currently breaking our tests. You'll be able to see that the first commit is a naive dependency update on only the jackson core and databind dependencies  while the second commit also updates the scala module and introduces a failure that I cannot fix from the application side AFAIK:  ``` java.lang.NoClassDefFoundError: com/fasterxml/jackson/annotation/JsonKey  	at com.fasterxml.jackson.databind.introspect.JacksonAnnotationIntrospector.hasAsKey(JacksonAnnotationIntrospector.java:1094) 	at com.fasterxml.jackson.databind.introspect.AnnotationIntrospectorPair.hasAsKey(AnnotationIntrospectorPair.java:619) 	at com.fasterxml.jackson.databind.introspect.AnnotationIntrospectorPair.hasAsKey(AnnotationIntrospectorPair.java:617) 	at com.fasterxml.jackson.databind.introspect.AnnotationIntrospectorPair.hasAsKey(AnnotationIntrospectorPair.java:617) 	at com.fasterxml.jackson.databind.introspect.POJOPropertiesCollector._addFields(POJOPropertiesCollector.java:496) 	at com.fasterxml.jackson.databind.introspect.POJOPropertiesCollector.collectAll(POJOPropertiesCollector.java:421) 	at com.fasterxml.jackson.databind.introspect.POJOPropertiesCollector.getJsonValueAccessor(POJOPropertiesCollector.java:270) 	at com.fasterxml.jackson.databind.introspect.BasicBeanDescription.findJsonValueAccessor(BasicBeanDescription.java:258) 	at com.fasterxml.jackson.databind.ser.BasicSerializerFactory.findSerializerByAnnotations(BasicSerializerFactory.java:391) 	at com.fasterxml.jackson.databind.ser.BeanSerializerFactory._createSerializer2(BeanSerializerFactory.java:224) 	at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.createSerializer(BeanSerializerFactory.java:173) 	at com.fasterxml.jackson.databind.SerializerProvider._createUntypedSerializer(SerializerProvider.java:1495) 	at com.fasterxml.jackson.databind.SerializerProvider._createAndCacheUntypedSerializer(SerializerProvider.java:1443) 	at com.fasterxml.jackson.databind.SerializerProvider.findValueSerializer(SerializerProvider.java:544) 	at com.fasterxml.jackson.databind.SerializerProvider.findTypedValueSerializer(SerializerProvider.java:822) 	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:308) 	at com.fasterxml.jackson.databind.ObjectMapper._writeValueAndClose(ObjectMapper.java:4568) 	at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsBytes(ObjectMapper.java:3844) 	at akka.serialization.jackson.JacksonSerializer.toBinary(JacksonSerializer.scala:283) 	at akka.serialization.Serialization.$anonfun$serialize$2(Serialization.scala:167) 	at scala.util.Try$.apply(Try.scala:210) 	at akka.serialization.Serialization.$anonfun$serialize$1(Serialization.scala:167) 	at akka.serialization.Serialization.withTransportInformation(Serialization.scala:157) 	at akka.serialization.Serialization.serialize(Serialization.scala:166) 	at akka.actor.testkit.typed.scaladsl.SerializationTestKit.roundtrip(SerializationTestKit.scala:55) 	at akka.actor.testkit.typed.scaladsl.SerializationTestKit.verifySerialization(SerializationTestKit.scala:41) 	at akka.persistence.testkit.internal.EventSourcedBehaviorTestKitImpl.verifySerializationAndThrow(EventSourcedBehaviorTestKitImpl.scala:238) 	at akka.persistence.testkit.internal.EventSourcedBehaviorTestKitImpl.preCommandCheck(EventSourcedBehaviorTestKitImpl.scala:192) 	at akka.persistence.testkit.internal.EventSourcedBehaviorTestKitImpl.runCommand(EventSourcedBehaviorTestKitImpl.scala:143) 	at akka.persistence.testkit.javadsl.EventSourcedBehaviorTestKit.runCommand(EventSourcedBehaviorTestKit.scala:229) 	at demo.ActorSerializationTest.asd(ActorSerializationTest.java:25) 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) 	at java.base/java.lang.reflect.Method.invoke(Method.java:566) 	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725) 	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60) 	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131) 	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149) 	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140) 	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84) 	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115) 	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105) 	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106) 	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64) 	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45) 	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37) 	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104) 	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98) 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214) 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210) 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135) 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151) 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) 	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541) 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) 	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541) 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) 	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) 	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) 	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107) 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88) 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54) 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67) 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52) 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114) 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86) 	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86) 	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53) 	at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:71) 	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38) 	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11) 	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35) 	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235) 	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54) Caused by: java.lang.ClassNotFoundException: com.fasterxml.jackson.annotation.JsonKey 	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581) 	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178) 	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522) 	... 100 more  ```  ",,guiwoda-inviu; johanandren
31559,patriknw,2022-09-06T08:51:26Z,2022-09-08T12:26:55Z,patriknw,,Release Akka 2.6.20,"### Before the release  - [x] Make sure all important / big PRs have been merged by now - [ ] Create a news item draft PR on [akka.io](https://github.com/akka/akka.io)  using the milestone and `scripts/authors.scala v2.6.14 v2.6.15` - [ ] Make sure to update `_config.yml` in it - In case of a new minor release:   - [ ] update the branch descriptions at CONTRIBUTING.md#branches-summary  ### Cutting the release  - [x] Make sure any running [actions](https://github.com/akka/akka/actions) for the commit you would like to release have completed. - [x] Tag the release `git tag -a -s -m 'Release v2.6.20' v2.6.20` and push the tag `git push --tags` - [x] Create a [new milestone](https://github.com/akka/akka/milestones) for the next version and close the current one. - [x] Check that the GitHub Actions release build has executed successfully (it should publish artifacts to Sonatype and documentation to Gustav) - [ ] Update `MiMa.latestPatchOf` and PR that change (`project/MiMa.scala`)  ### Check availability  - [x] Check [reference](https://doc.akka.io/docs/akka/2.6.20/) documentation - [x] Check the release on [Maven central](https://repo1.maven.org/maven2/com/typesafe/akka/akka-actor_2.13/2.6.20/)  ### When everything is on maven central  - [x] `ssh akkarepo@gustav.akka.io`   - [x] update the `current` links on `repo.akka.io` to point to the latest version with        ```        ln -nsf 2.6.20 www/docs/akka/current        ln -nsf 2.6.20 www/api/akka/current        ln -nsf 2.6.20 www/japi/akka/current        ```   - [x] check changes and commit the new version to the local git repository        ```        cd ~/www        git add docs/akka/current docs/akka/2.6.20        git add api/akka/current api/akka/2.6.20        git add japi/akka/current japi/akka/2.6.20        git commit -m ""Akka 2.6.20""        ```   - [x] push changes to the [remote git repository](https://github.com/akka/doc.akka.io)        ```        cd ~/www        git push origin main        ```  ### Announcements  - [x] Merge draft news item for [akka.io](https://github.com/akka/akka.github.com) - [x] Create a [GitHub release](https://github.com/akka/akka/releases) with the next tag version `v2.6.20`  title and a link to the announcement - [x] Post about it on the [forum](https://discuss.akka.io) - [x] Tweet using the [@akkateam](https://twitter.com/akkateam) account (or ask someone to) about the new release - [x] Announce on [Gitter akka/akka](https://gitter.im/akka/akka) - [x] Announce internally  ## Update references  Update the versions used in:  * [x] https://github.com/akka/akka-samples * [x] https://github.com/lightbend/lightbend-platform-docs/blob/master/docs/modules/getting-help/examples/build.sbt (this populates https://developer.lightbend.com/docs/lightbend-platform/introduction/getting-help/build-dependencies.html#_akka)  These are autoupdated by latest stable on maven central: * https://github.com/akka/akka-quickstart-java.g8 * https://github.com/akka/akka-quickstart-scala.g8 * https://github.com/akka/akka-http-quickstart-java.g8 * https://github.com/akka/akka-http-quickstart-scala.g8 * https://github.com/akka/akka-grpc-quickstart-java.g8 * https://github.com/akka/akka-grpc-quickstart-scala.g8",,patriknw
31555,He-Pin,2022-09-05T18:41:53Z,2022-10-15T06:32:31Z,He-Pin,He-Pin,Feature request: Add `mask`/`onErrorComplete`/`recoverWithComplete`?,"Just a like `.recoverWithRetries(-1  { case _: Throwable => Source.empty })` which recover the error with a complete.  And in fs2 there is a `mask` method: ```scala def mask: Stream[F  O] = this.handleErrorWith(_ => Stream.empty) ```  And reactor just add the `onErrorComplete` in https://github.com/reactor/reactor-core/pull/3159 too.   refs: https://github.com/akka/akka/pull/24985 refs: https://github.com/akka/akka/issues/31455 refs:https://github.com/akka/akka/issues/24951  ",,He-Pin
31552,He-Pin,2022-09-05T06:20:55Z,2024-04-02T19:04:23Z,He-Pin,johanandren,Add common trait for AbruptTerminationException and AbruptStageTerminationException?,Sometime a graphStage can be failed with an `AbruptTerminationException` or `AbruptStageTerminationException`  add a common trait for them can be easy to write test for abrupt termination.,,johanandren
31546,He-Pin,2022-09-03T16:12:02Z,2022-09-10T11:42:12Z,patriknw,He-Pin; johanandren,Failed: FlowMergeAllSpec——must merge all elements of the first completed source to its downstream,"``` [09-03 14:35:32.382] [info] - must merge all elements of the first completed source to its downstream  *** FAILED *** (26 milliseconds) [09-03 14:35:32.382] [info]   HashSet(5  1  6  7  3  4) did not contain all elements of List(1  2) (FlowMergeAllSpec.scala:34) [09-03 14:35:32.382] [info]   org.scalatest.exceptions.TestFailedException: [09-03 14:35:32.382] [info]   at org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:339) [09-03 14:35:32.382] [info]   at org.scalatest.matchers.dsl.ResultOfContainWord.allElementsOf(ResultOfContainWord.scala:319) [09-03 14:35:32.382] [info]   at akka.stream.scaladsl.FlowMergeAllSpec.$anonfun$new$4(FlowMergeAllSpec.scala:34) [09-03 14:35:32.382] [info]   at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85) [09-03 14:35:32.382] [info]   at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83) [09-03 14:35:32.382] [info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104) [09-03 14:35:32.382] [info]   at org.scalatest.Transformer.apply(Transformer.scala:22) [09-03 14:35:32.382] [info]   at org.scalatest.Transformer.apply(Transformer.scala:20) [09-03 14:35:32.383] [info]   at org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076) [09-03 14:35:32.383] [info]   at akka.stream.testkit.StreamSpec.withFixture(StreamSpec.scala:64) [09-03 14:35:32.383] [info]   at org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074) [09-03 14:35:32.383] [info]   at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086) [09-03 14:35:32.383] [info]   at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306) [09-03 14:35:32.404] [info]   at org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086) [09-03 14:35:32.404] [info]   at org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068) [09-03 14:35:32.404] [info]   at akka.testkit.AkkaSpec.runTest(AkkaSpec.scala:54) [09-03 14:35:32.404] [info]   at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145) [09-03 14:35:32.404] [info]   at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413) [09-03 14:35:32.404] [info]   at scala.collection.immutable.List.foreach(List.scala:333) [09-03 14:35:32.404] [info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401) [09-03 14:35:32.404] [info]   at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390) [09-03 14:35:32.404] [info]   at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427) [09-03 14:35:32.404] [info]   at scala.collection.immutable.List.foreach(List.scala:333) [09-03 14:35:32.404] [info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401) [09-03 14:35:32.404] [info]   at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396) [09-03 14:35:32.404] [info]   at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475) [09-03 14:35:32.404] [info]   at org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145) [09-03 14:35:32.404] [info]   at org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144) [09-03 14:35:32.404] [info]   at akka.testkit.AkkaSpec.runTests(AkkaSpec.scala:54) [09-03 14:35:32.404] [info]   at org.scalatest.Suite.run(Suite.scala:1112) [09-03 14:35:32.405] [info]   at org.scalatest.Suite.run$(Suite.scala:1094) [09-03 14:35:32.405] [info]   at akka.testkit.AkkaSpec.org$scalatest$wordspec$AnyWordSpecLike$$super$run(AkkaSpec.scala:54) [09-03 14:35:32.405] [info]   at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190) [09-03 14:35:32.405] [info]   at org.scalatest.SuperEngine.runImpl(Engine.scala:535) [09-03 14:35:32.405] [info]   at org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190) [09-03 14:35:32.405] [info]   at org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188) [09-03 14:35:32.405] [info]   at akka.testkit.AkkaSpec.org$scalatest$BeforeAndAfterAll$$super$run(AkkaSpec.scala:54) [09-03 14:35:32.405] [info]   at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213) [09-03 14:35:32.405] [info]   at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210) [09-03 14:35:32.405] [info]   at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208) [09-03 14:35:32.405] [info]   at akka.testkit.AkkaSpec.run(AkkaSpec.scala:54) [09-03 14:35:32.405] [info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318) [09-03 14:35:32.405] [info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513) [09-03 14:35:32.405] [info]   at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:413) [09-03 14:35:32.405] [info]   at java.util.concurrent.FutureTask.run(FutureTask.java:266) [09-03 14:35:32.405] [info]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [09-03 14:35:32.405] [info]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [09-03 14:35:32.405] [info]   at java.lang.Thread.run(Thread.java:748) ``` `2` from the first completed source is lost.",,He-Pin; johanandren
31531,leviramsey,2022-09-02T15:49:56Z,2022-09-22T17:29:47Z,patriknw,leviramsey; patriknw,Java OO Typed Behavior not depending on Receive,"Prompted by [this SO question](https://stackoverflow.com/questions/69361006/remove-duplication-with-abstractbehavior-createreceive)  Conceptually  all a `Behavior<T>` is is a function from `T` to `Behavior<T>` (along with a (potentially partial) function from a `Signal` to a `Behavior<T>`).  In the Scala API  `AbstractBehavior` captures this with (in Java notation) `Behavior<T> onMessage(T msg)`.  In the Java API  though  an `AbstractBehavior` has to first define a different `Behavior` which is constrained to be a `Receive`.  Perhaps this is down to Java not having pattern matching (and partial functions for signal handling) and also to ape the classic API.  We can see this in the implementations of `scaladsl.AbstractBehavior.receive(TypedActorContext[T]  T)` and `javadsl.AbstractBehavior.receive(TypedActorContext[T]  T)` after inlining:  ```scala // scaladsl checkRightContext(ctx) onMessage(msg)  // javadsl checkRightContext(ctx) _receive match {   case OptionVal.Some(r) => r.receive(ctx  msg)   case _ =>     val r = createReceive     _receive = OptionVal.Some(r)     r.receive(ctx  msg) } ```  The scaladsl is pretty clearly a more direct encoding.  Goal:  ```java public class AccumulatorBehavior extends AbstractBehaviorWithoutReceive<AccumulatorBehavior.Command> {   public interface Command;    public static final class Add implements Command {     public final int n;      public Add(int n) {       this.n = n;     }   }    public AccumulatorBehavior(ActorContext<Command> context) {     context.setLoggerName(""Accumulator"")     super(context);     value = 0;   }    public Behavior<Command> onMessage(Command cmd) {     // pre-Java 16     if (cmd instanceof Add) {       value += ((Add)cmd).n;       getContext().getLog().info(""value is now {}""  Integer.valueOf(value));     }     return this;      // Java 16: instanceof and cast (JEP 394)     if (cmd instanceof Add add) {       value += add.n;       getContext().getLog().info(""value is now {}""  Integer.valueOf(value));     }     return this;   }    private int value; } ```  I'm not that familiar with Java 17 onwards pattern matching (e.g. can you have blocks)  so not confident enough to provide an example  but that would likely make any ergonomic advantage of a builder even less.",,leviramsey; patriknw
31530,andreaslochbihler-da,2022-09-02T12:58:52Z,2023-03-16T09:34:07Z,johanandren,,BroadcastHub: race condition between Initialize and Unregister for a consumer,"After a new consumer is registered on a `BroadcastHub` as part of the `RegistrationPending` event  the consumer [is sent an `Initialize` event with the starting offset for its events](https://github.com/akka/akka/blob/main/akka-stream/src/main/scala/akka/stream/scaladsl/Hub.scala#L527). If the consumer cancels its stream concurrently  [the `Unregister` event resulting from the cancellation](https://github.com/akka/akka/blob/main/akka-stream/src/main/scala/akka/stream/scaladsl/Hub.scala#L794) races with the `Initialize` event. If the `postStop` method creates the `Unregister` event before the `Initialize` event is processed  the zero offsets in `previousPublishedOffset` and `offset`  which should have been [set by the `Initialize` event](https://github.com/akka/akka/blob/main/akka-stream/src/main/scala/akka/stream/scaladsl/Hub.scala#L802-L805)  are passed back to the `BroadcastHub`. Accordingly  the `BroadcastHub` may [zero out its buffer at bogus offsets](https://github.com/akka/akka/blob/main/akka-stream/src/main/scala/akka/stream/scaladsl/Hub.scala#L543-L546). In practice  since the initial head offset is `Int.MaxValue`  this means that the loop executes about two billion times  which takes a couple of seconds on our machines.  When this race condition happens in our application  we see a latency spike in event processing and unexpectedly long times for terminating an actor system. (I have too little understanding of the `BroadcastHub` implementation to judge whether this race condition could zero out elements that still need to be served.)  I can trigger this behaviour reasonably often (>20% of the runs on my Linux laptop) with the following program provided that I add a `Thread.sleep(10)` before [the line that sends the `Initialize` event](https://github.com/akka/akka/blob/main/akka-stream/src/main/scala/akka/stream/scaladsl/Hub.scala#L527). Whether a particular run triggers the race condition can be read off from the timing data printed out at the end. Short runs (around 200ms  which are mainly due to the `Thread.sleep`s) are fine and long runs (more than 1 second) contain the race condition.  ``` import akka.actor.ActorSystem import akka.stream.{KillSwitches  Materializer  OverflowStrategy} import akka.stream.scaladsl.{BroadcastHub  Keep  Sink  Source}  import scala.concurrent.Await import scala.concurrent.duration.Duration  object BroadcastHubMwe extends App {    def run(): Unit = {     implicit val actorSystem = ActorSystem(""BroadcastHubMwe"")     implicit val materializer = implicitly[Materializer]      val (queue  hubSource) = Source       .queue[Int](1  OverflowStrategy.backpressure)       .toMat(BroadcastHub.sink(1))(Keep.both)       .run()      println(""Add element to the queue"")     Await.result(queue.offer(23)  Duration.Inf)      println(""Adding consumer 0"")     val (killSwitch0  c0) =       hubSource         .viaMat(KillSwitches.single)(Keep.right)         .toMat(Sink.ignore)(Keep.both)         .run()     // Give the consumer enough time to get registered  including the Initialize call     Thread.sleep(100)     println(""Pulling the kill switch on consumer 0"")     killSwitch0.shutdown()     Await.result(c0  Duration.Inf)      // The hub's head is now at Int.MinValue      Thread.sleep(10)      println(""Adding consumer 1"")     val (killSwitch1  c1) =       hubSource         .viaMat(KillSwitches.single)(Keep.right)         .toMat(Sink.ignore)(Keep.both)         .run()     // Give the consumer some time to get registered     // and pull the kill switch before the Initialize call actually executes     Thread.sleep(1)     println(""Pulling the kill switch on consumer 1"")     killSwitch1.shutdown()     // Since the Initialize event has not yet been sent  the kill switch cancels the consumer stream     // and executes the postStop logic with the uninitialized offsets 0. Since this was the last active consumer      // BroadcastHub will iterate from Int.MinValue to 0  writing null into the buffer's single cell each time.     // The actor system will not terminate before this loop is done.     Await.result(actorSystem.terminate()  Duration.Inf)   }    val start = System.nanoTime()   run()   val stop = System.nanoTime()   println(s""Time: ${(stop - start).toFloat / 1e9}"") } ```     <!-- Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka HTTP: https://github.com/akka/akka-http/issues  - Alpakka:   https://github.com/akka/alpakka/issues  - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your issue precisely  and if possible provide a reproducer snippet (this helps resolve issues much quicker).  Thanks  happy hakking! -->   ",akka-stream/src/main/scala/akka/stream/scaladsl/Hub.scala,patriknw
31522,mdedetrich,2022-08-30T11:22:26Z,2022-09-05T10:56:05Z,mdedetrich,raboof; johanandren; mdedetrich,unsafeDataVia doesn't work with Flows which cannot truncate (i.e. gzip compression),"In PR https://github.com/akka/akka/pull/31123 `unsafeDataVia` was added to `FlowWithContext`/`SourceWithContext` and the implementation was further simplified with https://github.com/akka/akka/pull/31440. Although `unsafeDataVia` works fine in normal cases it doesn't seem to work with `Flow`'s that are sensitive to truncation  such as gzip compression. To illustrate this  the following test  ```scala ""unsafeDataVia works with flows which isn't compatible with truncation (i.e. gzip-compression)"" in {   val data = List((""1""  1)  (""2""  2)  (""3""  3)  (""4""  4)).map {     case (string  int) =>       (ByteString(string  ""UTF-8"")  int)   }    val compressed = Await.result(SourceWithContext     .fromTuples(Source(data))     .unsafeDataVia(Compression.gzip)     .runWith(Sink.seq)  Duration.Inf)     .map{ case (byteString  _) => byteString}     .foldLeft(ByteString.empty)(_ ++ _)    Await.result(Source     .single(compressed)     .via(Compression.gunzip())     .runFold(ByteString.empty)(_ ++ _)  Duration.Inf) shouldBe ByteString(""1234"") } ```  fails with  ``` [info] - must unsafeDataVia works with flows which isn't compatible with truncation (i.e. gzip-compression) *** FAILED *** (2 seconds  64 milliseconds) [info]   java.lang.AssertionError: assertion failed: expected OnComplete  found OnError(java.util.zip.ZipException: Truncated GZIP stream [info] 	at akka.stream.impl.io.compression.GzipDecompressor$$anon$1$Step.onTruncation(GzipDecompressor.scala:28) [info] 	at akka.stream.impl.io.compression.GzipDecompressor$$anon$1$Step.onTruncation$(GzipDecompressor.scala:28) [info] 	at akka.stream.impl.io.compression.GzipDecompressor$$anon$1$inflating$.onTruncation(GzipDecompressor.scala:30) ```  The same version using a standard Source with `.via` works as expected  i.e.  ```scala ""unsafeDataVia works with flows which isn't compatible with truncation (i.e. gzip-compression)"" in {   val data = List((""1""  1)  (""2""  2)  (""3""  3)  (""4""  4)).map {     case (string  int) =>       (ByteString(string  ""UTF-8"")  int)   }    val compressed = Await     .result(       Source(data.map { case (string  _) => string })         .via(Compression.gzip)         .runWith(Sink.seq)        Duration.Inf)     .foldLeft(ByteString.empty)(_ ++ _)    Await.result(Source     .single(compressed)     .via(Compression.gunzip())     .runFold(ByteString.empty)(_ ++ _)  Duration.Inf) shouldBe ByteString(""1234"") } ```",,raboof; johanandren; mdedetrich
31512,He-Pin,2022-08-27T11:36:28Z,2022-09-05T07:18:32Z,patriknw,He-Pin; johanandren,Parameter `request` should be `segmentSize` for Flow.interleaveMat,"![image](https://user-images.githubusercontent.com/501740/187028461-2a844b40-fb3b-4414-ae03-cf23864e8b85.png) ",,He-Pin; johanandren
31510,He-Pin,2022-08-26T18:27:22Z,2023-09-13T07:11:05Z,johanandren,Captain1653; johanandren,Add `expectCancellationWithNoMoreElementsNeeded`?,Which will help distinguishing with the `expectCancellationWithCause` one.,,Captain1653; johanandren
31505,Donzz,2022-08-25T20:31:03Z,2022-08-29T12:22:53Z,octonato,johanandren; octonato,Not very clean examples in docs,"Hi!  In docs describing event sourcing and persistence you have examples where new command and event handlers are built every time in commandHandler() and eventHandler() methods. But these methods are invoked for every command and event has come. So it's better to clarify examples and build command and event handlers once in constructor or somewhere else and use them in pointed methods. Yes  building up these objects are very simple operations but anyway it needs little bit more resources and  that most important  such code style misleads developers as they can think that commandHandler() and eventHandler() methods are invoked once.",akka-persistence-typed/src/main/scala/akka/persistence/typed/javadsl/EventSourcedBehavior.scala,johanandren
31503,He-Pin,2022-08-25T12:54:12Z,2022-09-06T11:13:00Z,patriknw,,Add @FunctionalInterface annotation to japi functions,I think those japi can be annotated with `@FunctionalInterface` to get some benefit from compiler.,,patriknw
31499,He-Pin,2022-08-24T13:57:53Z,2022-08-25T08:46:16Z,patriknw,,akka.stream.impl.fusing.TimerKeys is not used.,"```scala /**  * INTERNAL API  */ @InternalApi private[stream] object TimerKeys {    case object TakeWithinTimerKey    case object DropWithinTimerKey    case object GroupedWithinTimerKey  } ```  Those objects are not used.",,patriknw
31497,He-Pin,2022-08-24T05:27:17Z,2022-08-24T06:56:47Z,raboof,He-Pin; GreyPlane,failed: ActorContextDelegateSpec,"https://github.com/akka/akka/runs/7987568376?check_suite_focus=true#step:5:4000  ``` [08-24 04:47:50.888] [info] - must publish unhandled message to eventStream as UnhandledMessage and switch to delegator behavior *** FAILED *** (12 seconds  11 milliseconds) [08-24 04:47:50.889] [info]   java.lang.AssertionError: timeout (12 seconds) during fishForMessage  seen messages List()  hint: [08-24 04:47:50.889] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.assertFail(TestProbeImpl.scala:399) [08-24 04:47:50.889] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.loop$1(TestProbeImpl.scala:316) [08-24 04:47:50.889] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.fishForMessage_internal(TestProbeImpl.scala:320) [08-24 04:47:50.889] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.fishForMessage(TestProbeImpl.scala:268) [08-24 04:47:50.889] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.fishForMessage(TestProbeImpl.scala:275) [08-24 04:47:50.889] [info]   at akka.actor.typed.scaladsl.ActorContextDelegateSpec.$anonfun$new$4(ActorContextDelegateSpec.scala:85) [08-24 04:47:50.889] [info]   at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85) [08-24 04:47:50.889] [info]   at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83) [08-24 04:47:50.889] [info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104) [08-24 04:47:50.889] [info]   at org.scalatest.Transformer.apply(Transformer.scala:22) [08-24 04:47:50.889] [info]   at org.scalatest.Transformer.apply(Transformer.scala:20) [08-24 04:47:50.889] [info]   at org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076) [08-24 04:47:50.889] [info]   at akka.actor.testkit.typed.scaladsl.LogCapturing.withFixture(LogCapturing.scala:70) [08-24 04:47:50.889] [info]   at akka.actor.testkit.typed.scaladsl.LogCapturing.withFixture$(LogCapturing.scala:68) [08-24 04:47:50.889] [info]   at akka.actor.typed.scaladsl.ActorContextDelegateSpec.withFixture(ActorContextDelegateSpec.scala:52) [08-24 04:47:50.889] [info]   at org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074) [08-24 04:47:50.889] [info]   at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086) [08-24 04:47:50.889] [info]   at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306) [08-24 04:47:50.889] [info]   at org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086) [08-24 04:47:50.889] [info]   at org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068) [08-24 04:47:50.889] [info]   at akka.actor.typed.scaladsl.ActorContextDelegateSpec.runTest(ActorContextDelegateSpec.scala:52) [08-24 04:47:50.889] [info]   at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145) [08-24 04:47:50.889] [info]   at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413) [08-24 04:47:50.889] [info]   at scala.collection.immutable.List.foreach(List.scala:333) [08-24 04:47:50.889] [info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401) [08-24 04:47:50.889] [info]   at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390) [08-24 04:47:50.889] [info]   at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427) [08-24 04:47:50.890] [info]   at scala.collection.immutable.List.foreach(List.scala:333) [08-24 04:47:50.890] [info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401) [08-24 04:47:50.890] [info]   at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396) [08-24 04:47:50.890] [info]   at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475) [08-24 04:47:50.890] [info]   at org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145) [08-24 04:47:50.890] [info]   at org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144) [08-24 04:47:50.890] [info]   at akka.actor.typed.scaladsl.ActorContextDelegateSpec.runTests(ActorContextDelegateSpec.scala:52) [08-24 04:47:50.890] [info]   at org.scalatest.Suite.run(Suite.scala:1112) [08-24 04:47:50.890] [info]   at org.scalatest.Suite.run$(Suite.scala:1094) [08-24 04:47:50.890] [info]   at akka.actor.testkit.typed.scaladsl.ScalaTestWithActorTestKit.org$scalatest$BeforeAndAfterAll$$super$run(ScalaTestWithActorTestKit.scala:31) [08-24 04:47:50.890] [info]   at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213) [08-24 04:47:50.890] [info]   at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210) [08-24 04:47:50.890] [info]   at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208) [08-24 04:47:50.890] [info]   at akka.actor.typed.scaladsl.ActorContextDelegateSpec.org$scalatest$wordspec$AnyWordSpecLike$$super$run(ActorContextDelegateSpec.scala:52) [08-24 04:47:50.890] [info]   at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190) [08-24 04:47:50.890] [info]   at org.scalatest.SuperEngine.runImpl(Engine.scala:535) [08-24 04:47:50.890] [info]   at org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190) [08-24 04:47:50.890] [info]   at org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188) [08-24 04:47:50.890] [info]   at akka.actor.typed.scaladsl.ActorContextDelegateSpec.run(ActorContextDelegateSpec.scala:52) [08-24 04:47:50.890] [info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318) [08-24 04:47:50.890] [info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513) [08-24 04:47:50.890] [info]   at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:413) [08-24 04:47:50.890] [info]   at java.util.concurrent.FutureTask.run(FutureTask.java:266) [08-24 04:47:50.890] [info]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [08-24 04:47:50.890] [info]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [08-24 04:47:50.932] [info]   at java.lang.Thread.run(Thread.java:748) [08-24 04:47:50.939] [info] ActorLoggingTest: [WARN] [08/24/2022 04:47:50.941] [ActorLoggingTest-akka.actor.default-dispatcher-10] [akka://ActorLoggingTest/user/$a] unhandled message from Actor[akka://ActorLoggingTest/deadLetters]: Hello [INFO] [akkaDeadLetter][08/24/2022 04:47:50.943] [ActorLoggingTest-akka.actor.default-dispatcher-11] [akka://ActorLoggingTest/user/$a] Message [java.lang.String] to Actor[akka://ActorLoggingTest/user/$a#711066292] was unhandled. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'. ```",,He-Pin; GreyPlane
31493,patriknw,2022-08-19T07:25:31Z,2023-01-09T08:20:33Z,johanandren,patriknw; pvlugter; johanandren; octonato,failed: EventSourcedBehaviorStashSpec,"https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23100  ``` [08-18 00:51:50.026] [info] - must handle many stashed *** FAILED *** (6 seconds  130 milliseconds) [23100](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23101) [08-18 00:51:50.030] [info]   java.lang.AssertionError: timeout (6 seconds) while expecting 10 messages (got 0) [23101](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23102) [08-18 00:51:50.030] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.assertFail(TestProbeImpl.scala:399) [23102](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23103) [08-18 00:51:50.030] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.$anonfun$receiveMessages_internal$1(TestProbeImpl.scala:262) [23103](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23104) [08-18 00:51:50.031] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.$anonfun$receiveMessages_internal$1$adapted(TestProbeImpl.scala:257) [23104](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23105) [08-18 00:51:50.031] [info]   at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286) [23105](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23106) [08-18 00:51:50.031] [info]   at scala.collection.immutable.Range.foreach(Range.scala:158) [23106](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23107) [08-18 00:51:50.031] [info]   at scala.collection.TraversableLike.map(TraversableLike.scala:286) [23107](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23108) [08-18 00:51:50.031] [info]   at scala.collection.TraversableLike.map$(TraversableLike.scala:279) [23108](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23109) [08-18 00:51:50.031] [info]   at scala.collection.AbstractTraversable.map(Traversable.scala:108) [23109](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23110) [08-18 00:51:50.031] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.receiveMessages_internal(TestProbeImpl.scala:257) [23110](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23111) [08-18 00:51:50.031] [info]   at akka.actor.testkit.typed.internal.TestProbeImpl.receiveMessages(TestProbeImpl.scala:244) [23111](https://github.com/akka/akka/runs/7889844884?check_suite_focus=true#step:5:23112) [08-18 00:51:50.031] [info]   at akka.persistence.typed.scaladsl.EventSourcedBehaviorStashSpec.$anonfun$new$5(EventSourcedBehaviorStashSpec.scala:326) ```",akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/scaladsl/EventSourcedBehaviorStashSpec.scala,johanandren
31478,sebastian-alfers,2022-08-04T19:49:43Z,2022-09-21T11:53:50Z,patriknw,,configure stash-capacity per entity,"We have `akka.persistence.typed.stash-capacity` to configure a global limit how many commands can be stashed within a EventSourcesBehavior / DurableStateBehavior.  Provide an api to override this global config per entity.",,patriknw
31473,Daniel-Khodabakhsh,2022-07-22T04:29:33Z,2023-09-15T14:14:24Z,johanandren,Captain1653; johanandren,Feature request: `Sink.combine` for `Unzip`,"We can use `Sink.combine` for some fan-out strategies like `Broadcast`:  ```scala Source(List(0  1  2))   .to(     Sink.combine(       Sink.foreach[Int](left => println(s""left = ${left}""))        Sink.foreach[Int](right => println(s""right = ${right}""))     )(Broadcast[Int](_))   )   .run() ```  It would be neat if we can also use it with `Unzip`:  ```scala Source(List((0  ""zero"")  (1  ""one"")  (2  ""two"")))   .to(     Sink.combine(       Sink.foreach[Int](left => println(s""left = ${left}""))        Sink.foreach[String](right => println(s""right = ${right}""))     )(Unzip[Int  String]())   )   .run() ```  However this is not currently possible because `Sink.combine` expects a `UniformFanOutShape` while `Unzip` is a `FanOutShape2`.",,Captain1653; johanandren
31470,an-tex,2022-07-15T09:22:07Z,2022-07-15T12:34:44Z,an-tex,an-tex; johanandren,Run StreamRefs on top of reliable delivery,"As suggested by @patriknw in https://github.com/akka/akka/issues/24276#issuecomment-589637748 (and clarified by @johanandren in [discuss.lightbend](https://discuss.lightbend.com/t/current-state-of-bulk-stream-references/9863/2?u=antex)) it makes sense to implement the current StreamRefs (or provide a separate implementation) on top of the new [reliable delivery](https://doc.akka.io/docs/akka/current/typed/reliable-delivery.html#chunk-large-messages). This would allow to use StreamRefs for [large messages](https://doc.akka.io/docs/akka/current/stream/stream-refs.html#stream-references).  This is a follow up ticket to https://github.com/akka/akka/issues/24276 which has been closed.",,an-tex; johanandren
31466,GreyPlane,2022-07-10T09:20:54Z,2022-08-23T07:20:19Z,patriknw,patriknw,new Behavior API or Behaviors DSL like Behavior.interpret but handling Behaviors.same and Behaviors.unhandled correctly like it be used in StashBufferImpl.interpretOne,"<!-- Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka HTTP: https://github.com/akka/akka-http/issues  - Alpakka:   https://github.com/akka/alpakka/issues  - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your use case precisely  and if possible provide an example snippet.  Thanks  happy hakking! -->  ## Motivation receive message from a behavior and execute it in another then switch to that behavior can be done by using Behavior.interpret  but if the interpreter behavior return Behaviors.same or Behaviors.unhandled  it will need extra logic to handle it correctly for this scenario(mostly like interpretOne in StashBufferImpl). this extra logic is not complicate and probably bcs lack of bit understanding of how Behavior works if anyone did it wrong(no offense  i just did it wrong few days ago). but still  for a pretty common scenario(as my opinion) it requires too much knowledge for the underlying implementation.  ## Requested Feature i made a prototype implementation for clarifying the concept. https://github.com/GreyPlane/akka/commit/35fc6cc2d72917114b0d414e59c2616afd9b51ca  but there is still a question i want to have more guidance  is there should be a Behavior DSL that do the forward/interpret thing that completely same as StashBufferImpl  or just mimic interpretMessage/interpretSignal that give two respective API.  ## Alternative stash message and unstash it immediately will do the same work. or just use Behavior.interpret but with caution to make sure not messed up with returned behavior.    ",,patriknw
31463,johanandren,2022-07-07T14:30:24Z,2022-10-11T14:16:33Z,johanandren,,Use SingleConsumerOnlyUnboundedMailbox for stream ActorGraphInterpreter,"In https://github.com/akka/akka/issues/27125 we saw that SingleConsumerOnlyUnboundedMailbox was slightly faster than the default classic mailbox and set it as default for typed actors  since no balanced pool API is available there.   Stream actors are also never balanced even though the actor is classic  could be worth trying out our benches with the ActorGraphInterpreter always using SingleConsumerOnlyUnboundedMailbox and see if it makes a difference.",,johanandren
31461,patriknw,2022-07-07T11:51:47Z,2022-07-08T08:58:56Z,johanandren,,ClassCastException: class akka.actor.typed.internal.RestartSupervisor$ResetRestartCount,"When nesting two (or more) `restartWithBackoff` there can be a:  ``` ClassCastException: class akka.actor.typed.internal.RestartSupervisor$ResetRestartCount cannot be cast to class akka.actor.typed.SupervisionSpec$Command ```  A sketchy reproducer: ```       val probe = TestProbe[Event](""evt"")       val minBackoff = 20.millis       val strategy =         SupervisorStrategy.restartWithBackoff(minBackoff  10.seconds  0.0).withResetBackoffAfter(900.millis)        val strategy2 =         SupervisorStrategy.restartWithBackoff(minBackoff  10.seconds  0.0).withResetBackoffAfter(1100.millis)        val behv = supervise(supervise(targetBehavior(probe.ref)).onFailure[Exc1](strategy)).onFailure[Exc3](strategy2)       val ref = spawn(behv)        ref ! IncrementState       ref ! Throw(new Exc1)       probe.expectMessage(ReceivedSignal(PreRestart))       ref ! GetState       probe.expectMessage(State(0  Map.empty))        ref ! IncrementState       ref ! Throw(new Exc3)       probe.expectMessage(ReceivedSignal(PreRestart))       ref ! GetState       probe.expectMessage(State(0  Map.empty))        Thread.sleep(3000) ```  I think the reason is that a new instance of `RestartSupervisor` is created from the first exception via the interceptor. The first `ResetRestartCount` is still scheduled and will not have a matching `owner`.",akka-actor-typed-tests/src/test/scala/akka/actor/typed/SupervisionSpec.scala; akka-actor-typed/src/main/scala/akka/actor/typed/internal/Supervision.scala,patriknw
31454,jonathan-neufeld-asurion,2022-07-04T17:57:20Z,2022-07-27T16:05:45Z,jonathan-neufeld-asurion,jonathan-neufeld-asurion,Abrupt upstream cancellation,"This issue was [first reported](https://github.com/akka/akka-grpc/issues/1624) on _Akka-gRPC_ because it's not clear which sub-system is instigating this behaviour.  ### Versions used   <!-- add any other relevant versions here  please --> (More details available in the project's `build.sbt` file)  Akka version: 2.6.19 Akka HTTP version: 10.2.7  ### Expected Behavior  All events pump from the emitter endpoint to the sink endpoint without any errors and without any events being dropped  ### Actual Behavior  Most events are dropped and the sink endpoint reports that the upstream cancelled the stream abruptly  sometimes more than once per gRPC call.  This has only been mitigated by _dramatically_ throttling the emission of events to an unacceptable degree  and there is no proof this resolves the issue.   ### Relevant logs  The most pertinent error that occurs in the logs generated by the receiving side: ``` Error in stage [akka.stream.scaladsl.MergeHub$$anon$2$$anon$3]: Upstream producer failed with exception  removing from MergeHub now akka.stream.scaladsl.MergeHub$ProducerFailed: Upstream producer failed with exception  removing from MergeHub now 	at akka.stream.scaladsl.MergeHub$$anon$2$$anon$3.onUpstreamFailure(Hub.scala:352) 	at akka.stream.impl.fusing.GraphInterpreter.processEvent(GraphInterpreter.scala:525) 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:390) 	at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:650) 	at akka.stream.impl.fusing.GraphInterpreterShell$AsyncInput.execute(ActorGraphInterpreter.scala:521) 	at akka.stream.impl.fusing.GraphInterpreterShell.processEvent(ActorGraphInterpreter.scala:625) 	at akka.stream.impl.fusing.ActorGraphInterpreter.akka$stream$impl$fusing$ActorGraphInterpreter$$processEvent(ActorGraphInterpreter.scala:800) 	at akka.stream.impl.fusing.ActorGraphInterpreter$$anonfun$receive$1.applyOrElse(ActorGraphInterpreter.scala:818) 	at akka.actor.Actor.aroundReceive(Actor.scala:537) 	at akka.actor.Actor.aroundReceive$(Actor.scala:535) 	at akka.stream.impl.fusing.ActorGraphInterpreter.aroundReceive(ActorGraphInterpreter.scala:716) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:580) 	at akka.actor.ActorCell.invoke(ActorCell.scala:548) 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) 	at akka.dispatch.Mailbox.run(Mailbox.scala:231) 	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) 	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:295) 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1016) 	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1665) 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1598) 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) Caused by: akka.http.scaladsl.model.http2.PeerClosedStreamException: Stream with ID [???] was closed by peer with code CANCEL(0x08) ```   ### Reproducible Test Case  The issue is complex and requires configuration  so here is a link to a GitHub project that reproduces the issue: [mergehub-streaming-repo](https://github.com/jonathan-neufeld-asurion/mergehub-streaming-repro) ",,jonathan-neufeld-asurion
31455,ncreep,2022-07-04T14:18:25Z,2023-04-17T11:11:35Z,johanandren,He-Pin; patriknw; ncreep; johanandren,Idle-complete graph stage,"### Short description  Currently  the `idleTimeout` function throws an exception when reaching the timeout. In some cases it can useful to complete the  stream successfully rather than failing it. Would there be any interest in defining a new function which is just like `idleTimeout` but doesn't throw an exception? If so  I can open up a pull request.  ### Details  An example use-case is when trying to take events from an ""infinite"" stream like events from Kafka. One might want to reach the ""last"" event and then complete. Since the stream is infinite a possible surrogate is to wait until the `Source` is idle for long enough and then complete.  Although it's possible to emulate this behavior with `idleTimeout(...).recover()` it gets clunky and seems like an abuse of exceptions for the purposes of control-flow.  Thanks ",,He-Pin; patriknw; ncreep; johanandren
31445,tolomaus,2022-06-22T15:41:31Z,2022-06-22T16:06:28Z,johanandren,johanandren,akka using 100% cpu,"Hi   I'm using Play 2.8.16 and akka steam 2.6.19 on java 11.0.15 on centos 7.5 aws ec2  Since a couple of weeks one of the akka threads starts consuming 100% of one of the cpu's.  See here the relevant portion of the jstack: ``` ""application-akka.actor.default-dispatcher-61"" #608 prio=5 os_prio=0 cpu=1685873.57ms elapsed=4957.36s tid=0x00007fbc00032000 nid=0x11d8 runnable  [0x00007fbbec3f0000]    java.lang.Thread.State: RUNNABLE 	at akka.util.ByteString.isEmpty(ByteString.scala:726) 	at akka.stream.impl.io.TLSActor$ChoppingBlock.chopInto(TLSActor.scala:98) 	at akka.stream.impl.io.TLSActor.doInbound(TLSActor.scala:296) 	at akka.stream.impl.io.TLSActor.$anonfun$bidirectional$1(TLSActor.scala:233) 	at akka.stream.impl.io.TLSActor$$Lambda$2037/0x0000000840e16040.apply$mcV$sp(Unknown Source) 	at akka.stream.impl.Pump.pump(Transfer.scala:203) 	at akka.stream.impl.Pump.pump$(Transfer.scala:201) 	at akka.stream.impl.io.TLSActor.pump(TLSActor.scala:52) 	at akka.stream.impl.SimpleOutputs$$anonfun$downstreamRunning$1.applyOrElse(ActorProcessor.scala:244) 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38) 	at akka.stream.impl.SubReceive.apply(Transfer.scala:19) 	at akka.stream.impl.FanOut$OutputBunch$$anonfun$subreceive$1.applyOrElse(FanOut.scala:242) 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38) 	at akka.stream.impl.SubReceive.apply(Transfer.scala:19) 	at akka.stream.impl.SubReceive.apply(Transfer.scala:15) 	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) 	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) 	at akka.stream.impl.SubReceive.applyOrElse(Transfer.scala:15) 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) 	at akka.actor.Actor.aroundReceive(Actor.scala:537) 	at akka.actor.Actor.aroundReceive$(Actor.scala:535) 	at akka.stream.impl.io.TLSActor.aroundReceive(TLSActor.scala:52) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:580) 	at akka.actor.ActorCell.invoke(ActorCell.scala:548) 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) 	at akka.dispatch.Mailbox.run(Mailbox.scala:231) 	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) 	at java.util.concurrent.ForkJoinTask.doExec(java.base@11.0.15/ForkJoinTask.java:290) 	at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(java.base@11.0.15/ForkJoinPool.java:1020) 	at java.util.concurrent.ForkJoinPool.scan(java.base@11.0.15/ForkJoinPool.java:1656) 	at java.util.concurrent.ForkJoinPool.runWorker(java.base@11.0.15/ForkJoinPool.java:1594) 	at java.util.concurrent.ForkJoinWorkerThread.run(java.base@11.0.15/ForkJoinWorkerThread.java:183) ```  It looks like this started happening after java was upgraded from 11.0.14 to 11.0.15. I will downgrade it to 11.0.14 and see what happens in the coming days.  Meanwhile  is there anything I can do to fix or work around this problem?  Many thanks",,johanandren
31443,sergeypiachonik,2022-06-21T16:00:20Z,2022-06-23T11:28:31Z,sergeypiachonik,sergeypiachonik; johanandren,Akka-stream overlaps elements processing and implicitly changes processing thread,"Hi. Looks like very dangerous bug introduced somewhere between 2.13:2.6.0(not affected) and 2.13:2.6.10 (I didn't check intermediate versions)  latest version 2.13:2.6.19 is also affected.  Running of code below leads to next effects: 1) Flow from chainAsyncWrapped() may be stopped at any random point  then other element processing starts by chainAsyncWrapped()   then flow returns to the first one. So elements processing overlaps each other within one flow. This is reproducible permanently  2) Processing stop/start can change processing thead and as a result not synchronized objects (basically means almost all object) may be damaged. This is hard to reproduce  I was able to reproduce this only once with code below  but able to reproduce this regularly on real codebase  Issue on stackoverflow with additional details: https://stackoverflow.com/questions/72686826/akka-stream-implicitly-change-execution-thread  Environment:  java version:  openjdk zulu 11.0.12 os version:  Mac OS X 10.15.7 architecture: x86_64   ``` package foo.bar;  import akka.Done; import akka.NotUsed; import akka.actor.ActorSystem; import akka.japi.function.Predicate; import akka.stream.ActorAttributes; import akka.stream.OverflowStrategy; import akka.stream.Supervision; import akka.stream.javadsl.Flow; import akka.stream.javadsl.Keep; import akka.stream.javadsl.Sink; import akka.stream.javadsl.Source; import com.typesafe.config.Config; import com.typesafe.config.ConfigFactory; import lombok.AllArgsConstructor; import lombok.Data; import lombok.RequiredArgsConstructor; import lombok.extern.slf4j.Slf4j; import org.apache.commons.lang3.mutable.MutableInt;  import java.util.HashMap; import java.util.Map; import java.util.Objects; import java.util.concurrent.CompletableFuture; import java.util.concurrent.CompletionStage; import java.util.concurrent.ExecutionException; import java.util.concurrent.atomic.AtomicReference;  @Slf4j @RequiredArgsConstructor public class ThreadingIssueExample {   private static ActorSystem actorSystem;    static {     Map<String  Object> properties = new HashMap<>();     properties.put(""akka.stream.materializer.initial-input-buffer-size""  4);     properties.put(""akka.stream.materializer.max-input-buffer-size""  16);     Config customConf = ConfigFactory.parseMap(properties);     actorSystem = ActorSystem.create(""test""  customConf);     actorSystem.logConfiguration();   }    public static void main(String... args) throws ExecutionException  InterruptedException {     getStreamCf(20).get();   }    public static CompletableFuture<Done> getStreamCf(int count) {     CompletionStage<Done> completionStage = Source         .range(0  count)         .map(param -> new FooBarEntity(param  new MutableInt(param)))         .async()         .buffer(200  OverflowStrategy.backpressure())         .async()         .map(param -> {           log.info(""main start. {}""  param);           return param;         })         .via(chainAsyncWrapped())         .map(param -> {           log.info(""main end. {}""  param);           return param;         })         .toMat(Sink.ignore()  Keep.right())         .withAttributes(ActorAttributes.supervisionStrategy(t -> {           log.error(""Supervision strategy received an error. Stopping""  t);           return (Supervision.Directive) Supervision.stop();         }))         .run(actorSystem);     return completionStage.toCompletableFuture();   }    public static Flow<FooBarEntity  FooBarEntity  NotUsed> chainAsyncWrapped() {     AtomicReference<Integer> id = new AtomicReference<>(null);      Flow<FooBarEntity  FooBarEntity  NotUsed> chainAsyncWrapped = Flow.<FooBarEntity>create().map(param -> {       log.info(""async start. {}""  param);       if (Objects.isNull(id.get())) {         id.set(param.getId());       } else {         log.error(""Thread ovelap detected. Current: {}  cannot start: {}""  id.get()  param.getId());       }       return param;     }).via(createChainFlow()).map(param -> {       if (!param.getId().equals(id.get())) {         log.error(""Thread ovelap detected. Current: {}  cannot end: {}""  id.get()  param.getId());       } else {         id.set(null);       }       log.info(""async end. {}""  param);       return param;     });     return chainAsyncWrapped.async();   }     public static Flow<FooBarEntity  FooBarEntity  NotUsed> createChainFlow() {     Flow<FooBarEntity  FooBarEntity  NotUsed> fullFlow = Flow.create();      for (int i = 0; i < 4; i++) {       Flow<FooBarEntity  FooBarEntity  NotUsed> filter = Flow           .<FooBarEntity>create()           .filter((Predicate<FooBarEntity>) fooBarEntity -> {             spinAndUpdate(fooBarEntity);             return true;           });       fullFlow = fullFlow.via(filter);     }      return Flow.<FooBarEntity>create().map(param -> {       log.info(""chain start. {}""  param);       return param;     }).via(fullFlow).map(param -> {       log.info(""chain end. {}""  param);       return param;     });   }    public static void spinAndUpdate(FooBarEntity fooBarEntity) {     long start = System.currentTimeMillis();      while (System.currentTimeMillis() - start < 300) {       long n = 0;       for (int i = 0; i < 10000; i++) {         n = n + i;       }     }     fooBarEntity.getValue().increment();   }    @Data   @AllArgsConstructor   @RequiredArgsConstructor   public static class FooBarEntity {     private Integer id;     private MutableInt value;   } } ```  ``` plugins {     id ""java"" }  group = ""foo.bar"" sourceCompatibility = ""11""  repositories {     mavenLocal()     mavenCentral() }   dependencies {     implementation ""com.typesafe.akka:akka-stream_2.13:2.6.19""     implementation ""org.apache.commons:commons-lang3:3.11""     implementation ""org.slf4j:slf4j-api:1.7.2""     implementation ""ch.qos.logback:logback-classic:1.0.9""     implementation ""ch.qos.logback:logback-core:1.0.9""     compileOnly ""org.projectlombok:lombok:1.18.24""     annotationProcessor ""org.projectlombok:lombok:1.18.24"" } ```",,sergeypiachonik; johanandren
31438,mpdn,2022-06-15T12:49:57Z,2022-09-01T12:49:26Z,johanandren,Captain1653; johanandren,Suspicious dead code in `SourceRefImpl`,"I am investigating an issue in which streams in my application are being failed with an `SubscriptionWithCancelException.NoMoreElementsNeeded` exception. I stumbled upon some suspicious dead code  although I don't think its related to my initial issue  as I do not use stream refs.  But either way  the issue is here:  https://github.com/akka/akka/blob/3c3e8286e27564db894703ed00d371174a295a25/akka-stream/src/main/scala/akka/stream/impl/streamref/SourceRefImpl.scala#L422-L425  Here we match on `cause`  a `Throwable`  and check if it is an `SubscriptionWithCancelException`.  But the only places where this interface is implemented is these two: https://github.com/akka/akka/blob/7abc41cf4e7e8827393b181cd06c5f8ea684e696/akka-stream/src/main/scala/akka/stream/impl/fusing/ActorGraphInterpreter.scala#L448 https://github.com/akka/akka/blob/7abc41cf4e7e8827393b181cd06c5f8ea684e696/akka-stream-testkit/src/main/scala/akka/stream/testkit/StreamTestKit.scala#L892-L894  Neither of which implements `Throwable`. So there is no class that implements both `Throwable` and `SubscriptionWithCancelException`  and thus that case can never be executed (reflection shenanigans notwithstanding)  It was probably meant to be `case _: SubscriptionWithCancelException.NonFailureCancellation => completeStage()` instead.",akka-stream/src/main/scala/akka/stream/impl/streamref/SourceRefImpl.scala,Captain1653
31437,raboof,2022-06-14T09:16:48Z,2022-11-17T09:19:20Z,johanandren,raboof; johanandren; lefou,update sbt-osgi to 0.9.6,"Akka currently uses sbt-osgi 0.9.4  which does not seem to work with JDK17 (#31132)  However  when updating to 0.9.6  the `akka-protobuf-v3` artifact does not contain classes anymore  only proto files.",,raboof; johanandren; lefou
31431,raboof,2022-06-08T12:48:12Z,2022-06-14T07:22:50Z,raboof,patriknw; johanandren,keep InternalStableApi stable between 2.6.19 and 2.6.20,In https://github.com/akka/akka/pull/31129/files#diff-693b35aa5ba7e2352142084356adf38dff2a42906b7433871ee39069754ffe1aR661-R662 we changed a method marked `InternalStableApi`  perhaps we should keep that parameter (and ignore it)?,akka-stream/src/main/scala/akka/stream/impl/PhasedFusingActorMaterializer.scala,raboof
31429,lupingqiu,2022-06-07T02:45:05Z,2022-06-30T11:03:29Z,patriknw,lupingqiu; patriknw,akka cluster node unreachable when update distribute data in different nodes,"I create a cluster with 3nodes，when I update ORSetKey，the nodes will lost，this is the warnning info: `2022-06-06 18:00:44 941 WARN  akka.cluster.ClusterHeartbeat - Cluster Node [akka.tcp://datasync-service-application@127.0.0.1:2551] - Scheduled sending of heartbeat was delayed. Previous heartbeat was sent [2194] ms ago  expected interval is [1000] ms. This may cause failure detection to mark members as unreachable. The reason can be thread starvation  e.g. by running blocking tasks on the default dispatcher  CPU overload  or GC.`  akka version: 2.6.3 main code： ``` object BalanceTest extends App{    def create(port:Int) ={     val config = ConfigFactory.parseString(s""akka.remote.classic.netty.tcp.port=$port"")       .withFallback(ConfigFactory.load(""test""))     implicit val system = ActorSystem(""datasync-service-application"" config)       val workerRouter: ActorRef = {       val routerProps = ClusterRouterGroup(         RoundRobinGroup(List(""/user/WorkerActor""))          ClusterRouterGroupSettings(           totalInstances = 1000            routeesPaths = List(""/user/WorkerActor"")            allowLocalRoutees = true            useRoles = Set(""worker-node"")         )       ).props.withDispatcher(""actor-dispatcher"")       system.actorOf(routerProps  ""workerRouter"")     }      system.actorOf(Props(classOf[WorkerActor])  ""WorkerActor"")      workerRouter   }    val ref1: ActorRef = create(2551)   val ref2: ActorRef = create(2552)   val ref3: ActorRef = create(2553)    Thread.sleep(3000)   for(i<-1 to 3000){     ref1! s""hello world $i""   }  }  class WorkerActor extends Actor{    lazy val address = Cluster(context.system).selfAddress.toString   val replicator :ActorRef =  DistributedData(context.system).replicator   implicit val cluster = Cluster(context.system)   protected implicit lazy val ec: ExecutionContext = context.dispatcher    var cnt = 0   override def receive: Receive = {     case _:String =>       val jobId= ""jobId""+cnt       replicator ! Update(EventTest.Flags  ORSet()  EventTest.writeAll)(_+jobId)       cnt = cnt + 1       println(s""$address :""+cnt)     case a =>       println(a)   } }  object EventTest{    val timeout = 1000 millis   val writeAll = WriteAll(timeout)   val readAll = ReadAll(timeout)   val Flags = ORSetKey[String](""FLAGS"")   }  ```  configuration: ``` play.http.secret.key = ""abcdefghijklmnopqrstuvwxyz"" play.http.secret.key = ${?APP_SECRET}   jdbc-defaults.slick.profile = ""slick.jdbc.MySQLProfile$""   akka.actor {   serialization-bindings {     # commands won't use play-json but Akka's jackson support     ""com.shuyun.datasync.impl.DatasyncCommandSerializable""    = jackson-json   } }  akka {   #  discovery.method = akka-dns   loglevel = ""INFO""   actor {     default-dispatcher {       fork-join-executor {         parallelism-factor = 3.0         parallelism-max = 64         task-peeking-mode = LIFO       }     }      provider = ""cluster""      enable-additional-serialization-bindings = on     allow-java-serialization = off     serializers {       kryo = ""com.twitter.chill.akka.AkkaSerializer""     }     serialization-bindings {       ""java.io.Serializable"" = kryo     }   } }  akka.remote.artery.enabled=false  akka.cluster.role {   worker-node.min-nr-of-members = 1 } akka.cluster.min-nr-of-members = 1  akka {   cluster.roles = [""worker-node""]   actor {     provider = ""cluster""   }   remote.classic {     log-remote-lifecycle-events = off     netty.tcp {       hostname = ""127.0.0.1""       port = 2551     }   }    cluster {     seed-nodes = [       ""akka.tcp://datasync-service-application@127.0.0.1:2551""]      # auto downing is NOT safe for production deployments.     # you may want to use it during development  read more about it in the docs.     #     # auto-down-unreachable-after = 10s   }   discovery {     method = akka-dns   } }   akka {   loggers = [""akka.event.slf4j.Slf4jLogger""]   loglevel = ""DEBUG""   logger-startup-timeout = 30s    actor {     task-dispatcher {       executor = ""fork-join-executor""       # This will be used if you have set ""executor = ""fork-join-executor""""       fork-join-executor {         # Min number of threads to cap factor-based parallelism number to         parallelism-min = 8          # The parallelism factor is used to determine thread pool size using the         # following formula: ceil(available processors * factor). Resulting size         # is then bounded by the parallelism-min and parallelism-max values.         parallelism-factor = 5.0          # Max number of threads to cap factor-based parallelism number to         parallelism-max = 256          # Setting to ""FIFO"" to use queue like peeking mode which ""poll"" or ""LIFO"" to use stack         # like peeking mode which ""pop"".         task-peeking-mode = ""FIFO""       }     }   } }  actor-dispatcher {   executor = ""fork-join-executor""   # This will be used if you have set ""executor = ""fork-join-executor""""   fork-join-executor {     # Min number of threads to cap factor-based parallelism number to     parallelism-min = 8      # The parallelism factor is used to determine thread pool size using the     # following formula: ceil(available processors * factor). Resulting size     # is then bounded by the parallelism-min and parallelism-max values.     parallelism-factor = 3.0      # Max number of threads to cap factor-based parallelism number to     parallelism-max = 64      # Setting to ""FIFO"" to use queue like peeking mode which ""poll"" or ""LIFO"" to use stack     # like peeking mode which ""pop"".     task-peeking-mode = ""FIFO""   } } ``` ",,lupingqiu; patriknw
31428,alanbur,2022-06-03T13:15:25Z,2022-07-08T11:36:17Z,patriknw,patriknw; alanbur; johanandren,ActorAdapter logging can't be controlled,"When an exception is thrown by an Actor  `ActorAdapter.scala` always logs an error even if the exception is subsequently handled by a `onSignal` method.  If `onSignal` handles and logs the error  it ends up being logged twice. There seems to be no way of overriding this unwanted behaviour.  ``` 245          // log at Error as that is what the supervision strategy would have done. 246          ctx.log.error(logMessage  ex) ```",,patriknw; alanbur; johanandren
31422,raboof,2022-05-27T15:21:17Z,2022-06-05T16:24:37Z,raboof,,`Unsafe.java` is in `src/main/scala`,"... which is strange in itself  and also causes `javafmt` not to trigger for this file.  Seems accidental  a quick experiment doesn't reveal a reason this should be there. Let's look into this after merging #31405",akka-actor/src/main/java/akka/util/Unsafe.java; akka-actor/src/main/scala/akka/util/Unsafe.java,johanandren
31419,raboof,2022-05-24T12:59:46Z,2023-02-06T15:12:16Z,patriknw,jrudolph; raboof; adibaranga,TLS session is updated too late for TLS 1.3,"When acting as a TLS server  in `TLSActor.doUnwrap`  the `currentSession` is updated when `engine.unwrap`'s `result.getHandshakeStatus` is `FINISHED`.  However  at least with TLS 1.3  it is possible for `engine.unwrap` to return `NEED_TASK` after receiving the client authentication  then `NEED_WRAP` after reading the first chunk of application data  and only then `FINISHED`. This leads to the first chunk of application data to be delivered to the user code with the 'old'  unauthenticated session.  (this not a security concern: when the client authentication fails this application data will not be consumed at all).  ~It would be nice if we could just assume any application data will come in after the client certificate is checked  but I'm not yet confident this is the case.~  This is the root cause of https://github.com/akka/akka-http/issues/4122  see that issue for a reproducer.",akka-stream/src/main/scala/akka/stream/impl/io/TLSActor.scala,jrudolph
31414,JustinPihony,2022-05-21T00:39:45Z,2022-10-18T10:56:21Z,patriknw,He-Pin; johanandren,Add official support for JDK 17,"This is a ticket to officially support [the newest long term Java version  17](https://www.oracle.com/news/announcement/oracle-releases-java-17-2021-09-14/).  ",,He-Pin; johanandren
31411,johanandren,2022-05-19T09:52:08Z,2022-12-12T12:36:11Z,johanandren,bczoma; ankitg1984,Warnings in multinode tests - gcp auth plugin deprecated,"``` 2022-05-16T04:07:53.4971796Z To learn more  consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke 2022-05-16T04:07:53.6939472Z [error] W0516 04:07:53.693601  104660 gcp.go:120] WARNING: the gcp auth plugin is deprecated in v1.22+  unavailable in v1.25+; use gcloud instead. ```",,bczoma; ankitg1984
31403,grimlor,2022-05-12T18:00:23Z,2022-09-29T06:04:35Z,patriknw,,False positives for security vulnerability,"Viewing the results of a Fortify SCA scan & analysis  using Auditworkbench  several files have false positives for the inclusion of keys in the codebase. The vulnerability is referred to as ""Key Management: Hardcoded Encryption Key"". This is because the scan simply looks for a value/variable named `key`. The list of impacted files are:  - `RemoteInstrumentsSpec.scala:30` in akka-remote - `RemoteSettings.scala:110` in akka-remote - `InmemJournal.scala:64` in akka-persistence - `PersistentFSM.scala:41` in akka-persistence - `AutoDown.scala:62` in akka-cluster - `ClusterSettings.scala:86` in akka-cluster - `SplitBrainResolverSettings.scala:43` in akka-cluster - `ClusterReceptionistSettings.scala:29` in akka-cluster-typed - `ImmutableMapBench.scala:48` in akka-bench-jmh - `ActorSystem.scala:438` in akka-actor  After visual inspection  I have confirmed that these are not encryption keys.",,patriknw
31400,syspulse,2022-05-12T10:49:05Z,2022-05-12T14:26:04Z,syspulse,syspulse; raboof,akka.stream.Tcp outgoing connection flow restart for broken connection,"The following snippets for outgoing Tcp connection: `val flowTcp = Tcp().outgoingConnection(""127.0.0.1"" 1883).log(""TCP"")  val flowTcpRestart = RestartFlow.onFailuresWithBackoff(restartSettings)(() => flowTcp)`  1. Works for initial connection when tcp server is not available: keeps restarting the flow 2. Does not restart the flow when tcp server was shutdown or restarted.  ",,syspulse; raboof
31399,liutaon,2022-05-12T01:19:58Z,2022-05-13T04:32:12Z,patriknw,patriknw; johanandren,Jackson serializer doesn't support scala3 enum," We are trying to migrate the scala2 project to scala3  and use the enum of scala3 to define the message of akka  but there is a serialization runtime error when calling  as shown below  ``` Versions: Scala: 3.1.2 Akka: 2.6.19 SBT: 1.6.2 ```  ```scala enum Command extends Jackson:   case ToUpper(value: String  replyTo: ActorRef[StatusReply[String]]) ```  ``` Caused by: com.fasterxml.jackson.databind.exc.ValueInstantiationException:  Cannot construct instance of `Command$ToUpper`  problem: Cannot reflectively create enum objects ``` ",,patriknw; johanandren
31396,akilegaspi,2022-05-11T15:57:21Z,2022-05-24T11:02:09Z,johanandren,He-Pin; johanandren,Akka Actor: ActorContext.stop() does not cancel previously scheduled receiveTimeout,"We've encountered a bug in our application where a stopped Actor that has previously invoked `setReceiveTimeout` is still receiving a `ReceiveTimeout` message.  Upon inspection of the codebase I've noticed that on 1/19/22  this change was introduced to `akka.actor.dungeon.ReceiveTimeout`:  ``` private def cancelReceiveTimeoutTask(): Unit =     if (receiveTimeoutData._2 ne emptyCancellable) {       receiveTimeoutData._2.cancel()       receiveTimeoutData = (receiveTimeoutData._1  emptyCancellable)     } ```  This function was previously named as `cancelReceiveTimeout()`  which I believe was the function being called in `akka.actor.dungeon.FaultHandling`'s termination functions like `terminate()` or `faultCreate()` et al.  It was expected that `cancelReceiveTimeout()` would cancel the scheduled job but upon taking a closer look into the code it executes  it references directly to the function `AbstractActor.ActorContext.cancelReceiveTimeout()`  Here is a minimum project that demonstrates the bug https://github.com/akilegaspi/akka-receivetimeout-bug",,He-Pin; johanandren
31368,jrudolph,2022-04-26T09:43:26Z,2022-04-27T07:21:07Z,patriknw,,Handling stashed GetState will not process further messages from stash,When an event sourced actor receives commands while those are stashed (e.g. while persisting events)  and the first command is `GetState`  further commands will not be unstashed.,akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/scaladsl/EventSourcedBehaviorStashSpec.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/Running.scala,jrudolph
31366,octonato,2022-04-25T09:14:03Z,2023-01-10T07:55:59Z,johanandren,patriknw; pvlugter; johanandren,failed: FileSink - must allow overriding the dispatcher using Attributes ,"https://github.com/akka/akka/runs/6136665905?check_suite_focus=true#step:5:18418  ```scala [04-23 00:46:33.275] [info] - must allow overriding the dispatcher using Attributes *** FAILED *** (4 seconds  11 milliseconds) [04-23 00:46:33.276] [info]   java.lang.AssertionError: Expected Actor[akka://FileSinkSpec/system/Materializers/StreamSupervisor-1840/flow-20-2-fileSink#158914944] to use dispatcher [akka.actor.default-dispatcher]  yet used: [akka.stream.materializer.blocking-io-dispatcher] [04-23 00:46:33.276] [info]   at akka.stream.testkit.Utils$.assertDispatcher(Utils.scala:26) [04-23 00:46:33.277] [info]   at akka.stream.io.FileSinkSpec.$anonfun$new$27(FileSinkSpec.scala:192) [04-23 00:46:33.277] [info]   at akka.stream.io.FileSinkSpec.$anonfun$new$27$adapted(FileSinkSpec.scala:182) [04-23 00:46:33.277] [info]   at akka.stream.io.FileSinkSpec.targetFile(FileSinkSpec.scala:244) [04-23 00:46:33.279] [info]   at akka.stream.io.FileSinkSpec.$anonfun$new$26(FileSinkSpec.scala:182) [04-23 00:46:33.279] [info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) [04-23 00:46:33.279] [info]   at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85) [04-23 00:46:33.279] [info]   at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83) [04-23 00:46:33.279] [info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104) [04-23 00:46:33.279] [info]   at org.scalatest.Transformer.apply(Transformer.scala:22) [04-23 00:46:33.279] [info]   at org.scalatest.Transformer.apply(Transformer.scala:20) ```  ",akka-stream-testkit/src/test/scala/akka/stream/testkit/StreamSpec.scala; akka-stream-tests/src/test/scala/akka/stream/io/FileSinkSpec.scala; akka-stream-tests/src/test/scala/akka/stream/io/FileSourceSpec.scala; akka-stream-tests/src/test/scala/akka/stream/scaladsl/UnfoldResourceAsyncSourceSpec.scala,johanandren
31364,He-Pin,2022-04-23T16:01:00Z,2022-10-15T06:22:53Z,He-Pin,He-Pin; patriknw,recoverWith behavior should be fixed?,"I think the currently `recoverWith` behavior is a little unexpected  should make it a retry only once? refs:https://github.com/akka/akka/issues/20123 And I just tested with Reactor whitch works as expected with : ```java public class Test {     public static void main(String[] args) throws Exception {         Flux.error(new Exception(""test""))             .onErrorResume(e -> Flux.just(10).concatWith(Flux.error(new Exception(""test2""))))             .subscribe(System.out::println);          System.in.read();      } } ``` gives: ``` 23:56:31.691 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 10 23:56:31.751 [main] ERROR reactor.core.publisher.Operators - Operator called default onErrorDropped reactor.core.Exceptions$ErrorCallbackNotImplemented: java.lang.Exception: test2 Caused by: java.lang.Exception: test2 	at ***.Test.lambda$main$0(Test.java:13) 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94) 	at reactor.core.publisher.Operators.error(Operators.java:198) 	at reactor.core.publisher.FluxError.subscribe(FluxError.java:43) 	at reactor.core.publisher.Flux.subscribe(Flux.java:8469) 	at reactor.core.publisher.Flux.subscribeWith(Flux.java:8642) 	at reactor.core.publisher.Flux.subscribe(Flux.java:8439) 	at reactor.core.publisher.Flux.subscribe(Flux.java:8363) 	at reactor.core.publisher.Flux.subscribe(Flux.java:8306) 	at ***.Test.main(Test.java:14) ``` But   ```java public class Test2 {     public static void main(String[] args) throws Exception{         ActorSystem actorSystem = ActorSystem.create(""test"");         Source.<Integer>failed(new Exception(""test""))             .recoverWith(Throwable.class  new Supplier<Graph<SourceShape<Integer>  NotUsed>>() {                 @Override                 public Graph<SourceShape<Integer>  NotUsed> get() {                     System.out.println(""recover"");                     return Source.single(10)                         .concat(Source.failed(new Exception(""test2"")));                 }             })             .runForeach(System.out::println actorSystem);         System.in.read();     } } ``` only gives:  ``` recover recover recover recover recover recover recover recover recover recover recover recover recover recover recover recover recover ```",,He-Pin; patriknw
31363,He-Pin,2022-04-23T15:08:58Z,2023-09-12T05:47:18Z,He-Pin,Captain1653; johanandren,Add Flux#transform like operator?,"refs: https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Flux.html#transform-java.util.function.Function- This will make the syntax more fluent ",,Captain1653; johanandren
31362,He-Pin,2022-04-23T13:47:56Z,2022-09-20T14:57:13Z,He-Pin,He-Pin; patriknw,Add Sink.collect which accepts a java.util.stream.Collector for Javadsl?,"The current API is great with `fold` and `reduce` but I think it can be simpler with direct collector support. ```scala def collect[In  A  T](() => collector: java.util.stream.Collector[In  A  T]): Sink[In  CompletionStage[T]] ```",,He-Pin; patriknw
31360,OndrejSpanel,2022-04-23T08:30:47Z,2022-05-31T08:44:33Z,johanandren,Captain1653; OndrejSpanel; raboof,Example for Source.actorRef does not compile,"The [Source actorRef example](https://doc.akka.io/docs/akka/current/stream/operators/Source/actorRef.html) does not compile. The error is  > could not find implicit value for parameter materializer: akka.stream.Materializer  See [Scastie](https://scastie.scala-lang.org/EYzk3IzTTxWSVDMroG0Bng)",,Captain1653; OndrejSpanel; raboof
31359,OndrejSpanel,2022-04-22T21:28:41Z,2022-04-23T09:10:53Z,OndrejSpanel,OndrejSpanel; He-Pin; raboof,Akka Streams has transitional dependency to 2.13 library in Scala 3 version,"Note following `dependencyTree` report  from a Scala 3 SBT project using `""com.typesafe.akka"" %% ""akka-stream"" % ""2.6.19""`. It shows the library is linked against 2.13 version of _scala-parser-combinators_  while Scala 3 version exists.  ```text [info]   +-com.typesafe.akka:akka-stream_3:2.6.19 [info]   | +-com.typesafe.akka:akka-actor_3:2.6.19 [info]   | | +-com.typesafe:config:1.4.2 [info]   | | +-org.scala-lang.modules:scala-java8-compat_3:1.0.0 [info]   | | | +-org.scala-lang:scala3-library_3:3.0.0 (evicted by: 3.1.2) [info]   | | | +-org.scala-lang:scala3-library_3:3.1.2 [S] [info]   | | | [info]   | | +-org.scala-lang:scala3-library_3:3.1.1 (evicted by: 3.1.2) [info]   | | +-org.scala-lang:scala3-library_3:3.1.2 [S] [info]   | | [info]   | +-com.typesafe.akka:akka-protobuf-v3_3:2.6.19 [info]   | +-com.typesafe:ssl-config-core_2.13:0.4.3 [S] [info]   | | +-com.typesafe:config:1.4.0 (evicted by: 1.4.2) [info]   | | +-com.typesafe:config:1.4.2 [info]   | | +-org.scala-lang.modules:scala-parser-combinators_2.13:1.1.2 [S] [info]   | | [info]   | +-org.reactivestreams:reactive-streams:1.0.3 [info]   | +-org.scala-lang:scala3-library_3:3.1.1 (evicted by: 3.1.2) [info]   | +-org.scala-lang:scala3-library_3:3.1.2 [S] ```  It seems this is because of [ssl-config-core](https://mvnrepository.com/artifact/com.typesafe/ssl-config-core)  which is used in 0.4.3  and this version does not have a Scala 3 version.  I undestand the PR updating ssl-config-core https://github.com/akka/akka/pull/31046 was reverted again in https://github.com/akka/akka/pull/31252.  If ssl-config-core 0.6.1 cannot be used  could at least its transitional dependency to 2.13 parser-combinators be replaced with their 3.x counterparts for Scala 3 version?",,OndrejSpanel; He-Pin; raboof
31355,johanandren,2022-04-21T09:43:57Z,2022-09-13T13:10:16Z,johanandren,He-Pin; johanandren,Operator to pass element through resource,"An operator `withResource`/`mapWithResource` that delegates to `statefulMap` but correctly sets the safe blocking io dispatcher.  _Originally posted by @johanandren in https://github.com/akka/akka/pull/31330#discussion_r854957331_",,He-Pin; johanandren
31348,He-Pin,2022-04-16T10:33:36Z,2022-04-27T09:35:59Z,patriknw,patriknw,More detail in `akka.actor.ActorInitializationException`?,"From https://discuss.lightbend.com/t/actorcell-changing-recreate-into-create-after-akka-actor-actorinitializationexception/9686  How about adjust it a little  like: ```scala akka.actor.ActorInitializationException: akka://FaultHandlingTest/user/supervisor/$a: exception during creation  root cause message:[Boom!] at line:[jdocs.actor.FaultHandlingTest$Child.<init>(FaultHandlingTest.java:126)] ```",,patriknw
31340,johanandren,2022-04-12T19:58:49Z,2022-04-29T08:56:53Z,johanandren,jrudolph,Null messages and wrapper message types,"From report in the forums: https://discuss.lightbend.com/t/akka-distributedpubsubmediator-handle-null-values-supervisorstrategy/9683  `tell` itself throws immediately if you try to send a `null`  I think the various wrapping message types  like `DistributedPubSubMediator.Publish` should throw from their constructors on `null` messages as well rather than something further down the line failing.  Other wrapper types that comes to mind:  * `akka.actor.typed.eventstream.EventStream.Publish`  * `akka.actor.typed.pubsub.Topic.Publish`  * `akka.cluster.pubsub.DistributedPubSubMediator.Send`  * `akka.cluster.pubsub.DistributedPubSubMediator.SendToAll`  * `akka.routing.Broadcast`  * maybe `akka.pattern.StatusReply`",,jrudolph
31338,jrudolph,2022-04-12T09:33:01Z,2022-04-12T10:11:36Z,jrudolph,jrudolph,Half-closed TCP connection only reports error after writing second packet to already closed connection,"I suspect that the reason is that if a peer has already half-closed the connection (and then went away after a while)  we will not register for any events any more and as such do immediately react on a received `RST` packet:  ```  peer sends FIN PeerClosed / completion is dispatched ... no traffic for a while ... we try to send a packet peer answers with RST because in the meantime it has fully closed the connection (while waiting on our FIN/ACK) Akka IO is idle and does not check socket state  so it will not react on the fact that the socket failed in the meantime ... we try to send second packet socket write now fails and connection is finally failed -> IO responds with `WriteFailed` ```  We could instead immediately re-register for reads after half-closing the connection and then send out another `Abort` message when a `RST` was received. The disadvantage would be that such a change in the protocol might be affecting all users leading to unexpected new problems.",,jrudolph
31331,He-Pin,2022-04-09T20:37:42Z,2022-04-11T09:58:04Z,johanandren,johanandren,Should add a timer to complete the stage if the completion is deferred?,"When I was doing some defering of the upstream `completion` in https://github.com/akka/akka/pull/31330  I was thingking about what if the downstream never issue any more demonds anymore? Shold a upstream stage propagates the `upstreamFinished` timely ?  Should we add a timer which will sending the `onCompleted` to downstream after a configured time elapsed?eg: ```akka.stream.materializer.defer-completion-timeout```?  Currently I think we can combine with an `idleTimeout` to partially address this.  ",,johanandren
31329,He-Pin,2022-04-09T16:13:55Z,2023-09-15T14:13:25Z,johanandren,Captain1653; johanandren,Type parameters' order is not consistency in `unfold` and `unfoldResource`,"```scala def unfold[S  E](s: S)(f: S => Option[(S  E)]): Source[E  NotUsed] ``` and ```scala def unfoldResource[T  S](create: () => S  read: (S) => Option[T]  close: (S) => Unit): ``` I think the type parameters' order should be  ```scala def unfoldResource[S  T](create: () => S  read: (S) => Option[T]  close: (S) => Unit): ```  and then :  ```scala Source         .unfoldResource[BufferedReader  String](           () => newBufferedReader()            reader => Option(reader.readLine())            reader => reader.close()) ```  instead of  ```scala Source         .unfoldResource[String  BufferedReader](           () => newBufferedReader()            reader => Option(reader.readLine())            reader => reader.close())         .runWith(Sink.asPublisher(false)) ```",,Captain1653; johanandren
31328,He-Pin,2022-04-08T18:38:14Z,2022-04-24T18:10:49Z,He-Pin,,Add project setup in IDE guide to contribution guide,"I think this will help more people to get on borad for contributing to Akka  eg how to import the akka project in IDEA. I  was recored a video and sent it to a wechat group to help out.",,He-Pin
31323,gervaisb,2022-04-08T08:48:02Z,2022-05-31T08:46:25Z,johanandren,He-Pin; gervaisb,Fallback `copyUSAsciiStrToBytesAlgorithm` to 0 ,"This relates to this discussion: https://github.com/akka/akka/pull/23710#issuecomment-1091817062 where Akka-actor  and more precisely `akka.util.Unsafe` fail on Android because `String` has no `value` filed on Android.  Falling back to `copyUSAsciiStrToBytesAlgorithm = 0` in such cases will make the system a bit more tolerant.",,He-Pin; gervaisb
31308,nivox,2022-04-03T14:56:45Z,2022-05-05T06:27:53Z,nivox,He-Pin; johanandren,ActorFlow ask/askWithStatus with context propagation,"The `ActorFlow.ask` operator (as well as `askWithStatus`) should have a first class support for context propagation.  The rationale behind this request is to better support *asking* remote actors.  The context of a stream is not always statically known (difficult to configure serializers) or could be not serializable at all (i.e. Alpakka Kafka `ConsumerMessage.CommittableOffset`).  With the current implementation of `ActorFlow.ask` there is no way to only send the *input* part and locally recombine the *response* to the *context*.   So my proposal would be to add the following methods to `ActorFlow.scala`:  ```scala def askWithContext[I  Q  A  Ctx](       parallelism: Int     )(ref: ActorRef[Q]     )(makeMessage: (I  ActorRef[A]) => Q     )(implicit timeout: Timeout        ec: ExecutionContext     ): Flow[(I  Ctx)  (A  Ctx)  NotUsed] = {     import akka.actor.typed.scaladsl.adapter._     val classicRef = ref.toClassic      val askFlow = Flow[(I  Ctx)]       .watch(classicRef)       .mapAsync(parallelism) { case (el  ctx) =>         val res = akka.pattern.extended.ask(           classicRef            (replyTo: akka.actor.ActorRef) => makeMessage(el  replyTo)         )         // we need to cast manually (yet safely  by construction!) since otherwise we need a ClassTag          // which in Scala is fine  but then we would force JavaDSL to create one  which is a hassle in the Akka Typed DSL          // since one may say ""but I already specified the type!""  and that we have to go via the classic ask is an implementation detail         res.asInstanceOf[Future[A]].map(_ -> ctx)       }       .mapError {         case ex: AskTimeoutException =>           // in Akka Typed we use the `TimeoutException` everywhere           new java.util.concurrent.TimeoutException(ex.getMessage)          // the purpose of this recovery is to change the name of the stage in that exception         // we do so in order to help users find which stage caused the failure -- ""the ask stage""         case ex: WatchedActorTerminatedException =>           new WatchedActorTerminatedException(""ask()""  ex.ref)       }       .named(""ask"")      askFlow   }    def askWithStatusAndContext[I  Q  A  Ctx](       parallelism: Int     )(ref: ActorRef[Q]     )(makeMessage: (I  ActorRef[StatusReply[A]]) => Q     )(implicit timeout: Timeout        ec: ExecutionContext     ): Flow[(I  Ctx)  (A  Ctx)  NotUsed] = {     askWithContext[I  Q  StatusReply[A]  Ctx](parallelism)(ref)(makeMessage).map {       case (StatusReply.Success(a)  ctx) => a.asInstanceOf[A] -> ctx       case (StatusReply.Error(err)  _) => throw err       case _ => throw new RuntimeException() // compiler exhaustiveness check pleaser     } ```  The code is basically a copy-paste of the base `ask` implementation just recombining the context when the actor response future is completed thus avoiding serialization of the context.  I did not check if there would be any issue on the Java API side  but since they all are mostly proxy to the scala side I don't think there should be any issue. Maybe the only potential issue is the need for an `ExecutionContext` reference.",akka-docs/src/main/paradox/stream/operators/ActorFlow/askWithContext.md; akka-docs/src/main/paradox/stream/operators/ActorFlow/askWithStatusAndContext.md; akka-docs/src/main/paradox/stream/operators/index.md; akka-stream-typed/src/main/scala/akka/stream/typed/javadsl/ActorFlow.scala; akka-stream-typed/src/main/scala/akka/stream/typed/scaladsl/ActorFlow.scala; akka-stream-typed/src/test/java/docs/javadsl/ActorFlowCompileTest.java; akka-stream-typed/src/test/scala/docs/scaladsl/ActorFlowSpec.scala,nivox
31271,patriknw,2022-03-22T14:44:45Z,2023-03-08T07:59:02Z,patriknw,,Rolling update problem when ClusterShardingHealthCheck is enabled,I haven't fully verified this but I think a Kubernetes rolling update may stall because ClusterShardingHealthCheck is not successful until shard region registration has been completed. That may happen if a new entity type is added. Then it tries to register to the coordinator on one of the old nodes  but that coordinator doesn't exist.,akka-cluster-sharding/src/main/resources/reference.conf; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/ClusterShardingHealthCheck.scala; akka-cluster-sharding/src/test/scala/akka/cluster/sharding/ClusterShardingHealthCheckSpec.scala; akka-docs/src/main/paradox/typed/cluster-sharding.md,patriknw
31270,He-Pin,2022-03-22T12:14:46Z,2022-09-11T11:28:41Z,He-Pin,He-Pin,Extends Flow#keepAlive ability to memorizing the latest element？,"Hi  team  In my case I want to make use of the `keepAlive` to inject a heartbeat message to all my client. The message need a property I have to extract from any message from the stream. And stream itself is created without any information about which messages it will process. So I have two choices  making use of `flatMapPrefix` or extending the current `keepAlive` to make it can remember the last message(maybe N ?).  I do not need to send any keep alive message if the stream don't have any messages. ```java              source // Source<MsgAdapter>             .flatMapPrefix(1  new Function<Iterable<MsgAdapter>  Flow<MsgAdapter  MsgAdapter  NotUsed>>() {                 @Override                 public Flow<MsgAdapter  MsgAdapter  NotUsed> apply(final Iterable<MsgAdapter> param) throws Exception  Exception {                     final MsgAdapter msgAdapter = param.iterator().next();                     final int namespace = msgAdapter.getNamespace();                     final String topic = msgAdapter.getTopic();                     final MsgAdapter heartBeatMessage = createHeartBeatMessage(namespace  topic);                     return Flow.<MsgAdapter>create().prepend(Source.single(param.iterator().next()))                         .keepAlive(Duration.ofMinutes(1)  () -> heartBeatMessage);                 }             }) ```  or   ```java             .keepAlive(Duration.ofMinutes(5)  maybeLastMsg -> {                 return maybeLastMsg.map(lastMsg -> {                     final int namespace = msgAdapter.getNamespace();                     final String topic = msgAdapter.getTopic();                     final MsgAdapter heartBeatMessage = createHeartBeatMessage(namespace  topic);                     return heartBeatMessage;                 });             })             .filter(maybeMsgAdapter ->maybeMsgAdapter.isPresent() ```  How about extends the current `IdleInject`  with latest Message memorizing?  ```scala   def keepAlive[U >: Out](maxIdle: FiniteDuration  injectedElem: Option[Out] => U): Repr[U] =        via(new Timers.IdleInject[Out  U](maxIdle  injectedElem))      def keepAlive[U >: Out](maxIdle: FiniteDuration  injectedElem: () => U): Repr[U] =     keepAlive(maxIdle  _ => injectedElem())  ```  What I implemented locally is : ```java private Flow<MsgAdapter  MsgAdapter  NotUsed> injectBlankMsgFlow(final Duration timeout) {         return Flow.fromGraph(new KeepAliveInjectStage<>(             timeout              lastMsg -> {                 final String topic = lastMsg.getTopic();                 final int namespace = lastMsg.getNamespace();                 //创建空白消息                 final BizConfig bizConfig = bizConfigManager.getBizConfig(namespace);                 final String tag = bizConfig.getTag();                 final MsgAdapter blankMsg = createBlankMessage(topic  true  namespace  tag);                 return blankMsg;             }));     } ```  or with `keepAlive` and `statefulMapConcat` as : ```java             .map(Optional::ofNullable)             .keepAlive(Duration.ofMinutes(1)  Optional::empty)             .statefulMapConcat(() -> new Function<Optional<MsgAdapter>  Iterable<MsgAdapter>>() {                 private MsgAdapter last = null;                 @Override                 public Iterable<MsgAdapter> apply(final Optional<MsgAdapter> param) throws Exception {                     if(param.isPresent()) {                         last = param.get();                         return Collections.singletonList(last);                     } else {                         if (last != null) {                             final MsgAdapter msgAdapter = last;                             final String topic = msgAdapter.getTopic();                             return Collections.singletonList(createBlankMessage(topic));                         } else {                             return Collections.<MsgAdapter>emptyList();                         }                     }                 }             }) ```",,He-Pin
31268,He-Pin,2022-03-21T18:52:35Z,2023-09-12T10:07:13Z,patriknw,Captain1653; patriknw; johanandren,Support behavior like API in stageActor?,Currently the Stage actor's receive api is more lke the classical one  and is not easy to change the behavior of it. I think it would be great to support a subset of the the current typed behavior like api when get a stageActor  which can change its behavior after processing a message,,Captain1653; patriknw; johanandren
31266,jrudolph,2022-03-21T12:36:06Z,2022-08-12T13:02:08Z,patriknw,raboof,Scala 3 source incompatibilities around implicit ActorSystem," * `Tcp()` does not work any more but requires an explicit ActorSystem.  * Automatic conversion between classic and typed ActorSystem does not work implicitly any more  e.g. `Http()` does not work sometimes when only a classic ActorSystem is implicitly in scope.",akka-stream-tests/src/test/scala/akka/stream/io/TcpSpec.scala; akka-stream/src/main/mima-filters/2.6.19.backwards.excludes/31266-simplify-tcp-apply.excludes; akka-stream/src/main/scala-2.12/akka/stream/impl/ImplicitExtensionIdApply.scala; akka-stream/src/main/scala-2.13/akka/stream/impl/ImplicitExtensionIdApply.scala; akka-stream/src/main/scala-3/akka/stream/impl/ImplicitExtensionIdApply.scala; akka-stream/src/main/scala/akka/stream/scaladsl/Tcp.scala; akka-stream/src/main/scala/com/typesafe/sslconfig/akka/AkkaSSLConfig.scala,jrudolph
31263,pvlugter,2022-03-21T00:26:05Z,2022-10-31T10:20:30Z,johanandren,jrudolph; guiwoda-inviu; pvlugter; octonato; patriknw; johanandren; He-Pin; raboof,Failed: ReliableDeliveryShardingSpec,"https://github.com/akka/akka/runs/5608122450?check_suite_focus=true#step:5:35271  ``` [info] - must deliver unconfirmed if ShardingConsumerController is terminated *** FAILED *** (1 second  730 milliseconds) [info]   Job(msg-3) did not equal Job(msg-4) (ReliableDeliveryShardingSpec.scala:402) [info]   org.scalatest.exceptions.TestFailedException: [info]   at org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:339) [info]   at org.scalatest.matchers.should.Matchers$AnyShouldWrapper.should(Matchers.scala:6922) [info]   at akka.cluster.sharding.typed.delivery.ReliableDeliveryShardingSpec.$anonfun$new$15(ReliableDeliveryShardingSpec.scala:402) ```  Similar to #30664  but failing at the check after the one fixed in #31234.",akka-cluster-sharding-typed/src/test/java/jdocs/akka/cluster/sharding/typed/AccountExampleDocTest.java; akka-cluster-sharding-typed/src/test/scala/akka/cluster/sharding/typed/delivery/ReliableDeliveryShardingSpec.scala; akka-actor-typed/src/main/scala/akka/actor/typed/delivery/internal/ConsumerControllerImpl.scala; akka-cluster-sharding-typed/src/test/scala/akka/cluster/sharding/typed/delivery/ReliableDeliveryShardingSpec.scala,patriknw
31260,He-Pin,2022-03-19T11:57:00Z,2022-04-20T09:24:09Z,johanandren,,Add javadsl method to CancellationStrategy？,"The current method is so long. ```java akka.stream.Attributes#cancellationStrategyCompleteState akka.stream.Attributes#cancellationStrategyPropagateFailure ``` How about:  ```java akka.stream.Attributes.CancellationStrategy#completeStage akka.stream.Attributes.CancellationStrategy#propagateFailure ```",,johanandren
31256,He-Pin,2022-03-18T15:19:37Z,2022-04-19T12:39:27Z,He-Pin,He-Pin,StreamOperatorsIndexGenerator generate wrong related path on windows PC when invoke paradox,"When run `sbt paradox`  it will generate wrong related path on Windows PC. such as: ``` [error] |Source/Flow|<a name=""scanasync""></a>@ref[scanAsync](Source-or-Flow/scanAsync.md)|Just like @ref[`scan`](C:UsershepinIdeaProjectsakkaakka-docssrcmainparadoxstreamoperatorsSource-or-FlowscanAsync.md./scan.md) but receives a function that results in a @scala[`Future`] @java[`CompletionStage`] to the next value.|  ```",,He-Pin
31250,patriknw,2022-03-17T10:40:44Z,2022-10-31T10:19:22Z,johanandren,jrudolph; pvlugter; octonato; patriknw; johanandren; raboof,failed: RemoteFailureSpec,"With Aeron: https://github.com/akka/akka/runs/5546435083?check_suite_focus=true#step:5:3117  ``` [WARN] [03/15/2022 00:22:50.638] [pool-1-thread-1-ScalaTest-running-RemoteFailureSpec] [akka.actor.ActorSystemImpl(RemoteFailureSpec-remote-0)] Failed to load JFR flight recorder  falling back to noop. Exception: java.lang.ClassNotFoundException: akka.remote.artery.jfr.JFRRemotingFlightRecorder 3105 [WARN] [03/15/2022 00:22:50.638] [pool-1-thread-1-ScalaTest-running-RemoteFailureSpec] [akka.remote.RemoteActorRefProvider] Akka Cluster not in use - Using Akka Cluster is recommended if you need remote watch and deploy. 3106 [WARN] [03/15/2022 00:22:50.685] [pool-1-thread-1-ScalaTest-running-RemoteFailureSpec] [akka.actor.ActorSystemImpl(RemoteFailureSpec-remote-1)] Failed to load JFR flight recorder  falling back to noop. Exception: java.lang.ClassNotFoundException: akka.remote.artery.jfr.JFRRemotingFlightRecorder 3107 [WARN] [03/15/2022 00:22:50.685] [pool-1-thread-1-ScalaTest-running-RemoteFailureSpec] [akka.remote.RemoteActorRefProvider] Akka Cluster not in use - Using Akka Cluster is recommended if you need remote watch and deploy. 3108 [WARN] [03/15/2022 00:22:50.725] [pool-1-thread-1-ScalaTest-running-RemoteFailureSpec] [akka.actor.ActorSystemImpl(RemoteFailureSpec-remote-2)] Failed to load JFR flight recorder  falling back to noop. Exception: java.lang.ClassNotFoundException: akka.remote.artery.jfr.JFRRemotingFlightRecorder 3109 [WARN] [03/15/2022 00:22:50.726] [pool-1-thread-1-ScalaTest-running-RemoteFailureSpec] [akka.remote.RemoteActorRefProvider] Akka Cluster not in use - Using Akka Cluster is recommended if you need remote watch and deploy. 3110 [WARN] [03/15/2022 00:22:50.769] [pool-1-thread-1-ScalaTest-running-RemoteFailureSpec] [akka.actor.ActorSystemImpl(RemoteFailureSpec-remote-3)] Failed to load JFR flight recorder  falling back to noop. Exception: java.lang.ClassNotFoundException: akka.remote.artery.jfr.JFRRemotingFlightRecorder 3111 [WARN] [03/15/2022 00:22:50.769] [pool-1-thread-1-ScalaTest-running-RemoteFailureSpec] [akka.remote.RemoteActorRefProvider] Akka Cluster not in use - Using Akka Cluster is recommended if you need remote watch and deploy. 3112 [WARN] [03/15/2022 00:22:50.827] [pool-1-thread-1-ScalaTest-running-RemoteFailureSpec] [akka.actor.ActorSystemImpl(RemoteFailureSpec-remote-4)] Failed to load JFR flight recorder  falling back to noop. Exception: java.lang.ClassNotFoundException: akka.remote.artery.jfr.JFRRemotingFlightRecorder 3113 [WARN] [03/15/2022 00:22:50.827] [pool-1-thread-1-ScalaTest-running-RemoteFailureSpec] [akka.remote.RemoteActorRefProvider] Akka Cluster not in use - Using Akka Cluster is recommended if you need remote watch and deploy. 3114 [WARN] [03/15/2022 00:23:12.469] [RemoteFailureSpec-akka.remote.default-remote-dispatcher-7] [Association(akka://RemoteFailureSpec)] Outbound control stream to [akka://RemoteFailureSpec-remote-2@localhost:55981] failed. Restarting it. akka.remote.artery.OutboundHandshake$HandshakeTimeoutException: Handshake with [akka://RemoteFailureSpec-remote-2@localhost:55981] did not complete within 20000 ms 3115 [WARN] [03/15/2022 00:23:13.425] [RemoteFailureSpec-akka.remote.default-remote-dispatcher-13] [Association(akka://RemoteFailureSpec)] Outbound message stream to [akka://RemoteFailureSpec-remote-2@localhost:55981] failed. Restarting it. akka.remote.artery.OutboundHandshake$HandshakeTimeoutException: Handshake with [akka://RemoteFailureSpec-remote-2@localhost:55981] did not complete within 20000 ms 3116 [WARN] [03/15/2022 00:23:13.839] [RemoteFailureSpec-remote-2-akka.remote.default-remote-dispatcher-12] [ArteryTransport(akka://RemoteFailureSpec-remote-2)] Inbound message stream failed. Restarting it. java.lang.IllegalStateException: outboundControlIngress for [akka://RemoteFailureSpec@localhost:51581] not initialized yet 3117 [info] - should not be exhausted by sending to broken connections *** FAILED *** (31 seconds  861 milliseconds) 3118 [info]   java.lang.AssertionError: assertion failed: timeout (9999977000 nanoseconds) while expecting 200 messages (got 180) 3119 [info]   at scala.Predef$.assert(Predef.scala:279) 3120 [info]   at akka.testkit.TestKitBase.$anonfun$receiveN_internal$1(TestKit.scala:841) 3121 [info]   at akka.testkit.TestKitBase.$anonfun$receiveN_internal$1$adapted(TestKit.scala:838) 3122 [info]   at scala.collection.immutable.Range.map(Range.scala:59) 3123 [info]   at akka.testkit.TestKitBase.receiveN_internal(TestKit.scala:838) 3124 [info]   at akka.testkit.TestKitBase.receiveN(TestKit.scala:829) 3125 [info]   at akka.testkit.TestKitBase.receiveN$(TestKit.scala:829) 3126 [info]   at akka.testkit.TestKit.receiveN(TestKit.scala:973) 3127 [info]   at akka.remote.artery.RemoteFailureSpec.$anonfun$new$7(RemoteFailureSpec.scala:50) 3128 [info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) 3129 [info]   at akka.testkit.TestKitBase.within(TestKit.scala:418) 3130 [info]   at akka.testkit.TestKitBase.within$(TestKit.scala:406) 3131 [info]   at akka.testkit.TestKit.within(TestKit.scala:973) 3132 [info]   at akka.testkit.TestKitBase.within(TestKit.scala:433) 3133 [info]   at akka.testkit.TestKitBase.within$(TestKit.scala:433) 3134 [info]   at akka.testkit.TestKit.within(TestKit.scala:973) 3135 [info]   at akka.remote.artery.RemoteFailureSpec.$anonfun$new$2(RemoteFailureSpec.scala:50) ```",akka-remote/src/test/scala/akka/remote/artery/RemoteFailureSpec.scala,patriknw
31221,patriknw,2022-03-09T07:07:30Z,2022-10-31T10:19:44Z,johanandren,patriknw; pvlugter; johanandren; octonato,failed: RememberEntitiesAndStartEntitySpec,"With Scala 3: https://github.com/akka/akka/runs/5473100312?check_suite_focus=true#step:5:1868  ``` --> [Sharding must remember entities started with StartEntity] Start of log messages of test that [Failed(java.lang.AssertionError: assertion failed: timeout (6 seconds) during expectMsgClass waiting for class akka.actor.ActorRef)] 1806 | [DEBUG] [03/09/2022 00:18:22.006] [pool-1-thread-1-ScalaTest-running-RememberEntitiesAndStartEntitySpec] [WithLogCapturing(akka://RememberEntitiesAndStartEntitySpec)] Logging started for test [Sharding must remember entities started with StartEntity] 1807 | [DEBUG] [03/09/2022 00:18:22.009] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-2] [akka.serialization.Serialization(akka://RememberEntitiesAndStartEntitySpec)] Using serializer [akka.cluster.ddata.protobuf.ReplicatorMessageSerializer] for message [akka.cluster.ddata.Replicator$Internal$DataEnvelope] 1808 | [DEBUG] [03/09/2022 00:18:22.009] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-4] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity] startEntity: Entities will not be passivated automatically because 'rememberEntities' is enabled. 1809 | [DEBUG] [03/09/2022 00:18:22.010] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-2] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity] startEntity: Coordinator moved from [] to [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203] 1810 | [INFO] [akkaClusterSingletonStarted][03/09/2022 00:18:22.012] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-3] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator] Singleton manager starting singleton actor [akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntityCoordinator/singleton] 1811 | [INFO] [03/09/2022 00:18:22.012] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-3] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator] ClusterSingletonManager state change [Start -> Oldest] 1812 | [DEBUG] [03/09/2022 00:18:22.013] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-12] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: Starting remember entities store from provider akka.cluster.sharding.internal.DDataRememberEntitiesProvider@7f6e754a 1813 | [DEBUG] [03/09/2022 00:18:22.016] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-2] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity] startEntity: Request shard [1] home. Coordinator [None] 1814 | [DEBUG] [03/09/2022 00:18:22.016] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-5] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator] Received Get for key [shard-startEntity-all]. 1815 | [DEBUG] [03/09/2022 00:18:22.017] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-12] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: ShardRegion tried to register but ShardCoordinator not initialized yet: [Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity#1553889424]] 1816 | [DEBUG] [03/09/2022 00:18:22.017] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-5] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator] Received Get for key [startEntityCoordinatorState]. 1817 | [DEBUG] [03/09/2022 00:18:22.017] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-5] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator/$a] ReadMajorityPlus [startEntityCoordinatorState] [1] of [1]. 1818 | [DEBUG] [03/09/2022 00:18:22.017] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-6] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: Received [0] remembered shard ids (when waitingForInitialState) 1819 | [DEBUG] [03/09/2022 00:18:22.017] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-6] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: Initial coordinator is empty. 1820 | [INFO] [03/09/2022 00:18:22.017] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-6] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: ShardCoordinator was moved to the active state with [0] shards 1821 | [DEBUG] [03/09/2022 00:18:22.017] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-6] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: Full ShardCoordinator initial state State(Map()) 1822 | [DEBUG] [03/09/2022 00:18:22.279] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-14] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: ShardRegion registered: [Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity#1553889424]] 1823 | [DEBUG] [03/09/2022 00:18:22.279] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-14] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: Storing new coordinator state [State(Map())] 1824 | [DEBUG] [03/09/2022 00:18:22.280] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-4] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator] Received Update for key [startEntityCoordinatorState]. 1825 | [DEBUG] [03/09/2022 00:18:22.280] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-4] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator/$b] WriteMajorityPlus [startEntityCoordinatorState] [1] of [1]. 1826 | [DEBUG] [03/09/2022 00:18:22.280] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-14] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: The coordinator state was successfully updated with ShardRegionRegistered(Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity#1553889424]) 1827 | [DEBUG] [03/09/2022 00:18:22.280] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-14] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: New coordinator state after [ShardRegionRegistered(Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity#1553889424])]: [State(Map())] 1828 | [DEBUG] [03/09/2022 00:18:22.280] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-3] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity] startEntity: Requesting shard home for [1] from coordinator at [Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntityCoordinator/singleton/coordinator#-473371648]]. [1] buffered messages. 1829 | [DEBUG] [03/09/2022 00:18:22.280] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-15] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: Storing new coordinator state [State(Map())] 1830 | [DEBUG] [03/09/2022 00:18:22.280] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-15] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: Remembering shard allocation [1] 1831 | [DEBUG] [03/09/2022 00:18:22.280] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-3] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator] Received Update for key [startEntityCoordinatorState]. 1832 | [DEBUG] [03/09/2022 00:18:22.281] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-3] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator] Received Update for key [shard-startEntity-all]. 1833 | [DEBUG] [03/09/2022 00:18:22.281] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-4] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator/$c] WriteMajorityPlus [startEntityCoordinatorState] [1] of [1]. 1834 | [DEBUG] [03/09/2022 00:18:22.281] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-10] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator/RememberEntitiesStore] The coordinator shards state was successfully updated with 1 1835 | [DEBUG] [03/09/2022 00:18:22.281] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-10] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: The coordinator state was successfully updated with ShardHomeAllocated(1 Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity#1553889424])  waiting for remember shard update 1836 | [DEBUG] [03/09/2022 00:18:22.281] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-10] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: The ShardCoordinator saw remember shard start successfully written ShardHomeAllocated(1 Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity#1553889424]) 1837 | [DEBUG] [akkaShardAllocated][03/09/2022 00:18:22.281] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-10] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: Shard [1] allocated at [Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity#1553889424]] 1838 | [DEBUG] [03/09/2022 00:18:22.281] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-10] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntityCoordinator/singleton/coordinator] startEntity: New coordinator state after [ShardHomeAllocated(1 Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity#1553889424])]: [State(Map(1 -> Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity#1553889424]))] 1839 | [DEBUG] [03/09/2022 00:18:22.281] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-3] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity] startEntity: Host Shard [1]  1840 | [DEBUG] [akkaShardStarted][03/09/2022 00:18:22.281] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-3] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity] startEntity: Starting shard [1] in region 1841 | [DEBUG] [03/09/2022 00:18:22.282] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-3] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity] startEntity: Shard [1] located at [Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity#1553889424]] 1842 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-15] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1/RememberEntitiesStore] Starting up DDataRememberEntitiesStore  read timeout: [2.000 s]  write timeout: [5.000 s]  majority min cap: [5] 1843 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-4] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator] Received Get for key [shard-startEntity-1-0]. 1844 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-4] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator] Received Get for key [shard-startEntity-1-1]. 1845 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-4] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator] Received Get for key [shard-startEntity-1-2]. 1846 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-4] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator] Received Get for key [shard-startEntity-1-3]. 1847 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-4] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator] Received Get for key [shard-startEntity-1-4]. 1848 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-14] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1/RememberEntitiesStore] Got remembered entities  waiting for shard to request them 1849 | [WARN] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-2] [akka.actor.ActorSystemImpl(RememberEntitiesAndStartEntitySpec)] Failed to load JFR flight recorder  falling back to noop. Exception: java.lang.ClassNotFoundException: akka.cluster.sharding.internal.jfr.JFRShardingFlightRecorder 1850 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-2] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1] startEntity: Waiting for load of entity ids using [Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity/1/RememberEntitiesStore#1109139337]] to complete 1851 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-15] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1/RememberEntitiesStore] Got request from shard  sending remembered entities 1852 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-2] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1] startEntity: Shard initialized 1853 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-2] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity] startEntity: Shard was initialized [1] 1854 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-2] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity] startEntity: Deliver [1] buffered messages for shard [1] 1855 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-2] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1] startEntity: Request to start entity [1] and ack to [Some(Actor[akka://RememberEntitiesAndStartEntitySpec/system/testActor-279#-1246667212])] 1856 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-2] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1] startEntity: Remember update [1] and stops [] triggered 1857 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-5] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/replicator] Received Update for key [shard-startEntity-1-4]. 1858 | [DEBUG] [03/09/2022 00:18:22.283] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-13] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1/RememberEntitiesStore] The DDataShard state was successfully updated for [Set(Started(1))] 1859 | [DEBUG] [03/09/2022 00:18:22.284] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-5] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1] startEntity: Update done for ids  started [1]  stopped []. Duration 0 ms 1860 | [DEBUG] [03/09/2022 00:18:22.284] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-5] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1] startEntity: Started entity [Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity/1/1#111717014]] with entity id [1] in shard [1] 1861 | [DEBUG] [03/09/2022 00:18:22.284] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-5] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1] startEntity: Update complete  no pending updates  going to idle 1862 | [DEBUG] [03/09/2022 00:18:22.285] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-5] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity/1] startEntity: Shard [1] shutting down 1863 | [INFO] [03/09/2022 00:18:22.287] [pool-1-thread-1-ScalaTest-running-RememberEntitiesAndStartEntitySpec] [akka.actor.ActorSystemImpl(RememberEntitiesAndStartEntitySpec)] Starting shard again 1864 | [WARN] [03/09/2022 00:18:22.288] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-14] [akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity/1] EntityEnvelope(11 give-me-shard) 1865 | [DEBUG] [03/09/2022 00:18:22.288] [RememberEntitiesAndStartEntitySpec-akka.actor.internal-dispatcher-5] [akka://RememberEntitiesAndStartEntitySpec@10.1.0.242:41203/system/sharding/startEntity] startEntity: Shard [1]  terminated while not being handed off 1866 | [INFO] [akkaDeadLetter][03/09/2022 00:18:22.288] [RememberEntitiesAndStartEntitySpec-akka.actor.default-dispatcher-14] [akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity/1] Message [akka.cluster.sharding.RememberEntitiesAndStartEntitySpec$EntityEnvelope] from Actor[akka://RememberEntitiesAndStartEntitySpec/system/testActor-279#-1246667212] to Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity/1#-1930894266] was not delivered. [1] dead letters encountered. If this is not an expected behavior then Actor[akka://RememberEntitiesAndStartEntitySpec/system/sharding/startEntity/1#-1930894266] may have terminated unexpectedly. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'. 1867 <-- [Sharding must remember entities started with StartEntity] End of log messages of test that [Failed(java.lang.AssertionError: assertion failed: timeout (6 seconds) during expectMsgClass waiting for class akka.actor.ActorRef)] 1868 [info] - must remember entities started with StartEntity *** FAILED *** (6 seconds  292 milliseconds) 1869 [info]   java.lang.AssertionError: assertion failed: timeout (6 seconds) during expectMsgClass waiting for class akka.actor.ActorRef 1870 [info]   at scala.runtime.Scala3RunTime$.assertFailed(Scala3RunTime.scala:8) 1871 [info]   at akka.testkit.TestKitBase.expectMsgClass_internal(TestKit.scala:571) 1872 [info]   at akka.testkit.TestKitBase.expectMsgType(TestKit.scala:543) 1873 [info]   at akka.testkit.TestKitBase.expectMsgType$(TestKit.scala:159) 1874 [info]   at akka.testkit.TestKit.expectMsgType(TestKit.scala:973) 1875 [info]   at akka.cluster.sharding.RememberEntitiesAndStartEntitySpec.f$proxy1$1(RememberEntitiesAndStartEntitySpec.scala:95) 1876 [info]   at akka.cluster.sharding.RememberEntitiesAndStartEntitySpec.$init$$$anonfun$1$$anonfun$1(RememberEntitiesAndStartEntitySpec.scala:76) ```",akka-cluster-sharding/src/test/scala/akka/cluster/sharding/RememberEntitiesAndStartEntitySpec.scala; akka-cluster-sharding/src/test/scala/akka/cluster/sharding/RememberEntitiesAndStartEntitySpec.scala,johanandren; patriknw
31185,He-Pin,2022-02-23T08:28:09Z,2022-09-02T07:27:27Z,patriknw,,`priority` in `Flow#mergePreferred` should be `preferred`,"![image](https://user-images.githubusercontent.com/501740/155283974-6eda4088-1b90-49ff-8194-7b0049e50d37.png) It's `preferred` in JavaDSL",,patriknw
31132,pvlugter,2022-02-17T05:00:07Z,2022-11-18T13:47:40Z,patriknw,patriknw; raboof; pvlugter,Publishing with JDK17 fails due to sbt-osgi,"The JDK 17 builds are failing with `ConcurrentModificationException`s for the `osgiBundle` task.  https://github.com/akka/akka/runs/5225034561?check_suite_focus=true  https://github.com/akka/akka/runs/5225034721?check_suite_focus=true  ``` [error] java.util.ConcurrentModificationException [error] 	at java.base/java.util.TreeMap.callMappingFunctionWithCheck(TreeMap.java:750) [error] 	at java.base/java.util.TreeMap.computeIfAbsent(TreeMap.java:604) [error] 	at aQute.bnd.osgi.Jar.putResource(Jar.java:259) [error] 	at aQute.bnd.osgi.Jar$1.visitFile(Jar.java:186) [error] 	at aQute.bnd.osgi.Jar$1.visitFile(Jar.java:167) [error] 	at java.base/java.nio.file.Files.walkFileTree(Files.java:2811) [error] 	at aQute.bnd.osgi.Jar.buildFromDirectory(Jar.java:166) [error] 	at aQute.bnd.osgi.Jar.<init>(Jar.java:109) [error] 	at aQute.bnd.osgi.Jar.<init>(Jar.java:138) [error] 	at aQute.bnd.osgi.Analyzer.setClasspath(Analyzer.java:1465) [error] 	at com.typesafe.sbt.osgi.Osgi$.bundleTask(Osgi.scala:57) [error] 	at com.typesafe.sbt.osgi.SbtOsgi$.$anonfun$defaultOsgiSettings$1(SbtOsgi.scala:55) [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49) [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62) [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:68) [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:282) [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:23) [error] 	at sbt.Execute.work(Execute.scala:291) [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:282) [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:265) [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:64) [error] 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) [error] 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [error] 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) [error] 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [error] 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [error] 	at java.base/java.lang.Thread.run(Thread.java:833) ```",.github/workflows/nightly-builds.yml; .github/workflows/nightly-builds.yml,patriknw
31130,mehmetsalgar,2022-02-16T12:00:00Z,2024-09-25T14:57:24Z,patriknw,mehmetsalgar; patriknw; johanandren,Missing M1/aarch64 support for lmdbjava,"Hi   this library has problems with JDK17 and I don't see anything done about it.  #30341   Today I also discovered I can't develop with Akka with my new Mac Pro with M1 chip because of lmdbjava....  They have a one year old issue  [M1 support lmdbjava](https://github.com/lmdbjava/native/issues/10) and no action  I think you can't rely a library like this.",,mehmetsalgar; patriknw; johanandren
31100,mehmetsalgar,2022-02-01T10:15:43Z,2022-09-16T10:52:44Z,patriknw,mehmetsalgar; patriknw; pvlugter; johanandren,UpdateDone leaks after the update to Akka Version 2.6.17 to 2.6.18,"I previously reported a similar Issue #31091  which is classified as Bug and fixed while ShardsUpdated Event leaked to MessageExtractor.  Now during my regression tests  another version submerged  UpdateDone is also leaking to MessageExtractor.  [PR for 31091](https://github.com/johanandren/akka/commit/ff4295ddd96908f781966c58d6fa5cca13451348) introduces a new case statement for 'ShardUpdated' in Shard Class but UpdateDone is still not handled  I don't know this is the correct fix but my 2 cents.  java.lang.ClassCastException: class akka.cluster.sharding.internal.RememberEntitiesShardStore$UpdateDone cannot be cast to class org.example.TestActor$TestActorEvent (akka.cluster.sharding.internal.RememberEntitiesShardStore$UpdateDone and org.example.TestActor$TestEvent are in unnamed module of loader 'app') 	at org.example.TestActorGuardian$$anon$1.entityId(CreditScoreSMGuardian.scala:197) 	at akka.cluster.sharding.typed.internal.ExtractorAdapter.entityId(ClusterShardingImpl.scala:58) 	at akka.cluster.sharding.typed.internal.ClusterShardingImpl$$anonfun$1.isDefinedAt(ClusterShardingImpl.scala:168) 	at akka.cluster.sharding.Shard$$anonfun$idle$1.applyOrElse(Shard.scala:626)   ",,mehmetsalgar; patriknw; pvlugter; johanandren
31097,counter2015,2022-01-29T08:35:48Z,2022-09-16T10:37:03Z,patriknw,raboof,Jackson version too old which lead to version conflict.,"Now used jackson version is `2.11.4` https://github.com/akka/akka/blob/9b97614b959a37dbffb3b4579b258d3e0d2e7055/project/Dependencies.scala#L28  I'm using akka projection with many akka commponts  it will lead error to   ``` ╥ ╠══╦══╗ ║  ║  ║ ║  ║  ╠─A checked error was not handled. ║  ║  ║ com.fasterxml.jackson.databind.JsonMappingException: Scala module 2.11.4 requires Jackson Databind version >= 2.11.0 and < 2.12.0 ║  ║  ║ 	at com.fasterxml.jackson.module.scala.JacksonModule.setupModule(JacksonModule.scala:61) ║  ║  ║ 	at com.fasterxml.jackson.module.scala.JacksonModule.setupModule$(JacksonModule.scala:46) ║  ║  ║ 	at com.fasterxml.jackson.module.scala.DefaultScalaModule.setupModule(DefaultScalaModule.scala:17) ║  ║  ║ 	at com.fasterxml.jackson.databind.ObjectMapper.registerModule(ObjectMapper.java:835) ║  ║  ║ 	at akka.serialization.jackson.JacksonObjectMapperProvider$.$anonfun$configureObjectMapperModules$4(JacksonObjectMapperProvider.scala:242) ║  ║  ║ 	at akka.serialization.jackson.JacksonObjectMapperProvider$.$anonfun$configureObjectMapperModules$4$adapted(JacksonObjectMapperProvider.scala:241) ║  ║  ║ 	at scala.collection.immutable.List.foreach(List.scala:333) ```   My Dependencies ```scala  object Versions {     val akka = ""2.6.18""     val akkaManagement = ""1.1.3""     val akkaProjection = ""1.2.3""   }  val akka = Seq(     ""com.typesafe.akka"" %% ""akka-persistence""           % Versions.akka      ""com.typesafe.akka"" %% ""akka-persistence-cassandra"" % ""1.0.5""      ""com.typesafe.akka"" %% ""akka-persistence-query""     % Versions.akka      ""com.typesafe.akka"" %% ""akka-persistence-typed""     % Versions.akka      ""com.typesafe.akka"" %% ""akka-persistence-testkit""   % Versions.akka % Test      ""com.typesafe.akka"" %% ""akka-serialization-jackson"" % Versions.akka   )    val akkaActor = Seq(     ""com.typesafe.akka"" %% ""akka-actor-typed""            % Versions.akka      ""com.typesafe.akka"" %% ""akka-cluster-sharding-typed"" % Versions.akka      ""com.typesafe.akka"" %% ""akka-cluster-tools""          % Versions.akka      ""com.typesafe.akka"" %% ""akka-discovery""              % Versions.akka   )    val akkaStream = Seq(     ""com.typesafe.akka"" %% ""akka-stream""       % Versions.akka      ""com.typesafe.akka"" %% ""akka-stream-kafka"" % ""3.0.0""   )    val akkaManagement = Seq(     ""com.lightbend.akka.management"" %% ""akka-management-cluster-bootstrap"" % Versions.akkaManagement      ""com.lightbend.akka.discovery"" %% ""akka-discovery-kubernetes-api""      % Versions.akkaManagement   )    val akkaProjection = Seq(     ""com.lightbend.akka"" %% ""akka-projection-cassandra""     % Versions.akkaProjection      ""com.lightbend.akka"" %% ""akka-projection-core""          % Versions.akkaProjection      ""com.lightbend.akka"" %% ""akka-projection-durable-state"" % Versions.akkaProjection      ""com.lightbend.akka"" %% ""akka-projection-eventsourced""  % Versions.akkaProjection      ""com.lightbend.akka"" %% ""akka-projection-kafka""         % Versions.akkaProjection      ""com.lightbend.akka"" %% ""akka-projection-testkit""       % Versions.akkaProjection % Test   ) ```  And latest version is `2.13.1` https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-core  Is scala-steward still works or there is other reason for stay jackson verison to 2.11.4?    How about update jackson dependcy to latest version ?   ",akka-docs/src/main/paradox/project/migration-guide-2.6.x-2.7.x.md; akka-serialization-jackson/src/main/scala/akka/serialization/jackson/JacksonObjectMapperProvider.scala; project/Dependencies.scala,patriknw
31095,fredfp,2022-01-27T09:59:27Z,2023-08-18T07:29:49Z,patriknw,fredfp; yufei-cai; source-nerd; patriknw; nodefactory-bk,Clustering issues leading to all nodes being downed.,"We had a case where an issue on a single node lead to the whole akka-cluster being taken down.  ### Here's a summary of what happened:  1. Healthy cluster made of 20ish nodes  running on k8s 2. Node A: encounters issues  triggers CoordinatedShutdown 3. Node A: experiences high CPU usage  maybe GC pause  4. Node A: sees B as unreachable  broadcasts it (B is certainly reachable  but detected as such because of high CPU usage  GC pause  or similar issues) 5. Cluster state: A Leaving  B seen unreachable by A  all the other nodes are Up 6. Leader can currently not perform its duties (remove A)  reachability status (B seen unreachable by A) 7. Node A: times out some coordinated shutdown phases. Hypothesis: timed out because leader could not remove A. 8. Node A: finishes coordinated shutdown nonetheless. 9. hypothesis - Node A: quarantined associations to other cluster nodes 10. Nodes B  C  D  E: SBR took decision DownSelfQuarantinedByRemote and is downing [...] including myself 11. hypothesis - Node B  C  D  E: quarantined associations to other cluster nodes 12. in a few steps  all remaining cluster nodes down themselves: SBR took decision DownSelfQuarantinedByRemote 13. the whole cluster is down  ### Discussions  potential issues:  Considering the behaviour of CoordinatedShutdown (phases can time out and shutdown continues)  shouldn't the leader ignore unreachabilities added by a Leaving node and be allowed to perform its duties? At step 6 above  the Leader was blocked from removing A  but A still continued its shutdown process. The catastrophic ending could have been stopped here.  DownSelfQuarantinedByRemote: @patriknw 's [comment](https://github.com/akka/akka/pull/29737#discussion_r515906571) seems spot on. At step 9  nodes B  C  D  E should probably not take into account the `Quarantined` from a node that is Leaving.  DownSelfQuarantinedByRemote: another case where Patrik's [comment](https://github.com/akka/akka/pull/29737#discussion_r515906571) also seems to apply  `Quarantined` from nodes downing themselves because of DownSelfQuarantinedByRemote should probably not be taken into account.  At steps 10 and 12. Any cluster singletons running on affected nodes wouldn't be gracefully shutdown using the configured termination message. This is probably the right thing to do but I'm adding this note here nonetheless.",akka-cluster/src/multi-jvm/scala/akka/cluster/DowningWhenOtherHasQuarantinedThisActorSystemSpec.scala; akka-remote/src/main/mima-filters/2.8.4.backwards.excludes/issue-31095-quarantine-harmless.excludes; akka-remote/src/main/scala/akka/remote/artery/ArteryTransport.scala; akka-remote/src/main/scala/akka/remote/artery/Association.scala; akka-remote/src/main/scala/akka/remote/artery/InboundQuarantineCheck.scala; akka-remote/src/test/scala/akka/remote/artery/TestContext.scala,patriknw
31087,johanandren,2022-01-25T16:14:05Z,2022-10-18T10:56:00Z,patriknw,,Document arguments needed for running on JDK 17,"Follow up to #31079    Out of the box no special flags are needed but for some specific modules opening up reflective access using the `opens` flag is needed.  We should add docs about the needed ""opens"" flags needed and when those are needed. As far as I know akka-remote with Aeron  akka-persistence with leveldb (deprecated)  akka-distributed-data using lmdb for storage. Or see if there are versions of those third parties that can avoid the reflective access. ",akka-docs/src/main/paradox/persistence.md; akka-docs/src/main/paradox/remoting-artery.md; akka-docs/src/main/paradox/typed/cluster-sharding.md; akka-docs/src/main/paradox/typed/distributed-data.md,patriknw
31077,johanandren,2022-01-20T12:50:02Z,2022-08-23T07:06:32Z,patriknw,He-Pin; johanandren,On upstream end for statefulMapConcat,"In many use cases where `statefulMapConcat` could be useful the fact that it can only react on element coming from upstream and not upstream completing is a show stopper  think some form of batching/caching/grouping  when the stream ends the in-progress aggregate is lost.  Would be nice with an added lambda `() => Seq[Out]` that is invoked when the upstream ends  where the returned seq is emitted downstream before the statefulMapConcat completes.",,He-Pin; johanandren
31068,aaabramov,2022-01-15T20:18:12Z,2023-09-19T07:03:55Z,johanandren,Captain1653; johanandren,Broken link in docs,"Source file: https://github.com/akka/akka/blob/v2.6.18/akka-docs/src/main/paradox/typed/choosing-cluster.md  Page: https://doc.akka.io/docs/akka/current/typed/choosing-cluster.html#distributed-monolith Link: https://www.microservices.com/talks/dont-build-a-distributed-monolith/ ![image](https://user-images.githubusercontent.com/11317222/149636484-07e8645b-16dc-4eca-932e-308a6c7c61bb.png) ",akka-docs/src/main/paradox/typed/choosing-cluster.md,Captain1653
31058,patriknw,2022-01-12T14:15:16Z,2022-09-20T07:48:48Z,johanandren,patriknw; johanandren,Persistence plugin-dispatcher defaults to pinned dispatcher,Would be better to use the default dispatcher as default. Would it be too risky to change that in a patch version?,akka-docs/src/main/paradox/persistence-journals.md; akka-docs/src/main/paradox/project/migration-guide-2.6.x-2.7.x.md; akka-docs/src/test/scala/docs/persistence/PersistencePluginDocSpec.scala; akka-persistence/src/main/resources/reference.conf,patriknw
31053,johanandren,2022-01-10T16:07:31Z,2024-01-23T12:53:45Z,johanandren,patriknw; johanandren,ActorSystem local registry for topics,"The current topic API expects users to spawn and keep track of their topics themselves (multiple instances of the same topic in the same actor system is allowed).   Often when using topics  in a clustered app  I expect that you are after one topic actor instance per node and topic. Implementing that isn't a lot of work but it could be nice with an extension spawning topics making sure the same topic only spawns one actor  and that the protocol is the same (at runtime)  something like:  ``` val topic: ActorRef[T] = PubSubTopics(system).topic[T](name) ```",akka-actor-typed-tests/src/test/scala/akka/actor/typed/pubsub/LocalPubSubSpec.scala; akka-actor-typed/src/main/scala/akka/actor/typed/internal/pubsub/TopicImpl.scala; akka-actor-typed/src/main/scala/akka/actor/typed/pubsub/Topic.scala; akka-actor-typed-tests/src/test/java/jdocs/akka/typed/pubsub/PubSubExample.java; akka-actor-typed-tests/src/test/scala/akka/actor/typed/pubsub/LocalTopicSpec.scala; akka-actor-typed-tests/src/test/scala/akka/actor/typed/pubsub/PubSubSpec.scala; akka-actor-typed-tests/src/test/scala/docs/akka/typed/pubsub/PubSubExample.scala; akka-actor-typed/src/main/scala/akka/actor/typed/internal/pubsub/TopicImpl.scala; akka-actor-typed/src/main/scala/akka/actor/typed/pubsub/PubSub.scala; akka-actor-typed/src/main/scala/akka/actor/typed/pubsub/Topic.scala; akka-docs/src/main/paradox/typed/distributed-pub-sub.md,johanandren
30989,He-Pin,2021-12-14T02:53:11Z,2022-06-06T12:52:44Z,johanandren,Captain1653,schedulePeriodically* in stream-customize.html#using-timers  doc needs update ,"![image](https://user-images.githubusercontent.com/501740/145924404-1b9ff6d8-df6a-4826-8f8c-4ba4c596da12.png) https://doc.akka.io/docs/akka/current/stream/stream-customize.html#using-timers  These methods are deprecated",,Captain1653
30978,He-Pin,2021-12-10T08:46:36Z,2023-09-12T14:24:13Z,johanandren,Captain1653; He-Pin; johanandren,Add context/attachment to akka.stream.stage.TimerGraphStageLogic#onTimer?,"```scala   /**    * Will be called when the scheduled timer is triggered.    *    * @param timerKey key of the scheduled timer    */   @throws(classOf[Exception])   protected def onTimer(@unused timerKey: Any): Unit = () ```  It would be great if the method can carray some context information about this scheduling  ```scala   /**    * Will be called when the scheduled timer is triggered.    *    * @param timerKey key of the scheduled timer    * @param attachment the attachment of this scheduling    */   @throws(classOf[Exception])   protected def onTimer(@unused timerKey: Any  attachment: Any): Unit = () ```",,Captain1653; He-Pin; johanandren
30864,He-Pin,2021-11-06T10:10:57Z,2023-09-15T23:35:55Z,He-Pin,Captain1653,Add some diagram to the MergeHub and BroadcastHub,"![image](https://user-images.githubusercontent.com/501740/140605925-76035d6b-8f55-4757-b120-c8afe765c5fd.png) like something from [here](https://www.oreilly.com/library/view/scala-reactive-programming/9781787288645/22d1a175-d0d0-4233-954e-fdb8e7024816.xhtml)  The current [document](https://doc.akka.io/docs/akka/current/stream/stream-dynamic.html#using-the-mergehub) is not that intuitionistic.",,Captain1653
30859,agemooij,2021-11-05T09:16:39Z,2022-09-01T10:22:06Z,patriknw,agemooij; dwickern; johanandren,RestartSource.onFailuresWithBackoff should support failing on (custom) fatal errors,"I have several use cases that generally run as follows:  - we retrieve a valid OAuth token for some API - we start a never ending stream to fetch data from that API (using akka-http) to stay in sync - when we run into most errors  it should just restart with backoff  even if it takes a long time (e.g. API/network downtime) - but when for instance some external factor invalidates the OAuth token  our stream starts continuously failing with 401 or 403 responses.   In such special error cases the stream should clearly be stopped since it is no use to continue  e.g. we have encountered a fatal error scenario that needs to be handled with some other behavior than mindless restarting the stream.  We currently solve this issue using custom graph stages because  as far as we can work out  there is no version of `RestartSource` (or `RestartFlow`) that supports retrying only on some errors but failing on others.  It would be great if the various `.onFailuresWithBackoff` methods (or a new method) would support some way to express which errors should be retried and which ones should lead to failure.",,agemooij; dwickern; johanandren
30831,baltiyskiy,2021-10-27T20:09:43Z,2022-09-05T07:07:44Z,patriknw,johanandren,StreamConverters.asInputStream() uses IODispatcher without the need for a blocking dispatcher,"Documentation for StreamConverters.asInputStream() currently reads:  > You can configure the default dispatcher for this Source by changing the akka.stream.materializer.blocking-io-dispatcher or set it for a given Source by using ActorAttributes.  https://github.com/akka/akka/blob/main/akka-stream/src/main/scala/akka/stream/javadsl/StreamConverters.scala#L109  And `DefaultAttributes.inputStreamSink` indeed adds `IODispatcher` attribute.  But the resulting Sink does not in fact block: it is the users of the materialized value  `InputStream`  who will block :) The stage itself does not block when the `LinkedBlockingDeque` is full  but rather backpressures. It also takes care to leave space for the final `Finished/Failed` messages.  Given `Source` in the quote  I suspect that this is simply copypasta from the `fromOutputStream()` that indeed blocks. ",,johanandren
30802,patriknw,2021-10-20T06:11:29Z,2023-11-27T15:22:52Z,patriknw,patriknw,Investigate multi-node tests using DisposableSystem with aeron-udp,"In https://github.com/akka/akka/pull/30706 we had problems with Kubernetes OOM for the two tests that are using DisposableSystem; RandomizedSplitBrainResolverIntegrationSpec and SplitBrainResolverIntegrationSpec  Those test are currently disabled when running with aeron-udp in multi-node CI.",,patriknw
30739,FlorianSchaetz,2021-10-02T09:52:21Z,2023-09-11T10:42:27Z,johanandren,Captain1653; johanandren,Replace Receive in AbstractBehavior with Behavior for Java ,"`AbstractBehavior `in Java has one very important drawback: You have to override `createReceive `as an entry point  which returns a Receive instead of a Behavior. This makes a lot of easy things hard:  - Starting with a stash (can be done via constructor injection  still annoying) - Cannot start out supervising  since Behaviors.supervise will not return a Receive  only a Behavior  Is there really any need for this Receive in Akka Typed? Wouldn't it be more streamlined to rely soley on Behavior?",,Captain1653; johanandren
30723,pedromdias,2021-09-28T13:30:19Z,2023-09-11T10:41:48Z,johanandren,Captain1653; johanandren,SplitWhen skips the first element.,"In an attempt to aggregate a Source we created a groupWhile method. Note: This method assumes the Stream is sorted. It works well  except in the scenario where the first element is its own group of just one element  because SplitWhen does not evaluate the first element. If you uncomment the _println_ in the _groupWhile_ example below  you'll see that the first element is never evaluated. This leads to the first element always being grouped with the second element.   For example: A list of ints (1 2 3 4 5)  with the number as the key  would group the 1 with the 2. Expected: ((1  (1)) (2 (2))  (3 (3))  (4 (4))  (5 (5)))  Result:       ((1  (1 2))  (3 (3))  (4 (4))  (5 (5)))    Below you will find the code to reproduce this issue. ``` def groupWhile[I  K](key: I => K): Flow[I  (K  Seq[I])  NotUsed] = {     Flow[I]       .splitWhen(SubstreamCancelStrategy.drain) {         var lastKey: Option[K] = None         item =>           //println(item)           val currentItemKey        = key(item)           val shouldTriggerNewGroup = lastKey.exists(current => current != currentItemKey)           lastKey = Some(currentItemKey)           shouldTriggerNewGroup       }       .fold(Seq.empty[I])((acc  interest) => acc :+ interest)       .filterNot(_.isEmpty)       .map(filteredItems => (key(filteredItems.head)  filteredItems))       .mergeSubstreams   }  // Source(List(1 2 3 4 5))           .via(groupWhile(identity))           .runWith(Sink.seq) //Expected: Vector((1 List(1))  (2 List(2))  (3 List(3))  (4 List(4))  (5 List(5))) //Result: Vector((1 List(1  2))  (3 List(3))  (4 List(4))  (5 List(5)))  val result = Source(List(1 2 2 3 3 4 5))           .via(groupWhile(identity))           .runWith(Sink.seq) //Expected: Vector((1 List(1))  (2 List(2  2))  (3 List(3  3))  (4 List(4))  (5 List(5))) //Result: Vector((1 List(1  2  2))  (3 List(3  3))  (4 List(4))  (5 List(5)))  val result = Source(List(1 1 2 3 3 4 5))           .via(groupWhile(identity))           .runWith(Sink.seq) //Expected : Vector((1 List(1  1))  (2 List(2))  (3 List(3  3))  (4 List(4))  (5 List(5))) //Result: Vector((1 List(1  1))  (2 List(2))  (3 List(3  3))  (4 List(4))  (5 List(5))) `  ```  For clarity  we ended up working around this by using statefulMapConcat() with a similar logic. ",,Captain1653; johanandren
30568,marcospereira,2021-08-24T14:36:21Z,2023-09-11T10:38:39Z,johanandren,Captain1653; johanandren,Avoid using marcospereira/action-surefire-report fork in nightly builds,"_Originally posted by @johanandren in https://github.com/akka/akka/pull/30551#discussion_r694672818_ ",,Captain1653; johanandren
30564,hseeberger,2021-08-24T08:22:44Z,2023-09-11T10:39:44Z,johanandren,Captain1653; hseeberger; johanandren,Use WARN level instead of ERROR for abrupt termination logging,"When terminating an actor system abruptly  Akka Streams issues logging like this at ERROR level:  ``` Error: akka.stream.AbruptStageTerminationException: GraphStage [akka.stream.impl.fusing.GraphStages$IgnoreSink$$anon$10-ignoreSink] terminated abruptly  caused by for example materializer or actor system termination. ```  Abrupt termination is not ideal  but nevertheless a normal production case  in particular in cloud/k8s environments. Therefore this kind of logging (which usually is not interesting at all) should not report ERRORs  but at most WARNINGs.",,Captain1653; hseeberger; johanandren
30447,ignasi35,2021-07-30T15:27:41Z,2023-08-22T06:16:21Z,patriknw,patriknw,[Persistence] Expose type_hint and entity_id,"It's been already a source of issues in downstream plugins (https://github.com/akka/akka-persistence-spanner/issues/146) and an actual long-standing request to expose the `typeHint` and the `entityId` or a [`PersistenceId`](https://github.com/akka/akka/blob/master/akka-persistence-typed/src/main/scala/akka/persistence/typed/PersistenceId.scala#L37).  IIUC  `PersistenceId` was introduced only on Akka Persistence Typed and so it can't be accessed from the Akka Persistence TCK (which may still need to serve both the classic and the typoed APIs?).  It would be very useful to turn the `typeHint` and `entityId` into first class citizens. That would reduce the need for tags since certain queries over the journal and stateStore would no longer use tags but the typeHint.",,patriknw
30446,ignasi35,2021-07-30T14:03:53Z,2022-09-06T12:32:08Z,patriknw,bdoyle0182; octonato; jausmann-wc; patriknw; ignasi35,Delete durable state,"See #30277  Delete API wasn't included in the initial implementation. This is a feature request to support deletes.  -----------------  If Durable State feature introduces `def deleteObject` we should also consider how that becomes visible in projections. The usual implementation on plugins for that operation is to physically delete the entity from the database (as a regular CRUD operation would do).   This hard delete has implications from a projections point of view. By storing multiple revisions of the same entity in-place and then deleting the following can happen:  ``` ... entity123-rev7 <--- last value read when polling via changes(tag offset) entity123-rev8 entity123-rev9 (deleted row) ```  From a query point of view (e.g. `changes(tag  offset)`)  imagine an iteration reads rev7  then rev8  rev9 and the deletion happens. In that case  the information on rev8  rev9 and the actual deletion are lost on the projection side.  -----------------  For a CRUD-minded user point of view first arriving into CQRS-like (durable-state with akka-projections) the case above is likely to lead to corrupted projections.  A potential solution would be to require all implementations to implement `deleteObject` as a soft deletion and include a `def hardDelete` on the API. Another option would be to replace the `payload` on the database with a `case object Tombstone`. Still another option is to document this situation and recommend users to model deletion as a domain command that doesn't remove data from the database and warn about the implications of invoking `deleteObject` when using durable state in combination with projections. ",,bdoyle0182; octonato; jausmann-wc; patriknw; ignasi35
30412,dounine,2021-07-20T09:31:36Z,2023-02-07T10:37:20Z,johanandren,raboof; ignasi35,Source.queue bug?,"My code is below ``` val (chromeQueue  chromeSources) =   Source     .queue[Int](1  OverflowStrategy.dropNew)     .preMaterialize()  val (orderQueue  orderSources) =   Source     .queue[String](1  OverflowStrategy.dropNew)     .preMaterialize()  orderSources   .zip(chromeSources)   .to(Sink.ignore)   .run()  Source(Seq(""a""  ""b""  ""c""  ""d""))   .mapAsync(1) { i =>     orderQueue.offer(i).map {       case result: QueueCompletionResult => println(""completion"")       case QueueOfferResult.Enqueued     => println(""enqueued"")       case QueueOfferResult.Dropped      => println(""dropped"")     }   }   .runWith(Sink.ignore) ``` I Expected code results ``` enqueued dropped dropped dropped ``` But actual results ``` enqueued enqueued enqueued enqueued ```  akka version: 2.6.15",,raboof; ignasi35
30358,kulinux,2021-07-02T09:54:31Z,2023-09-11T07:24:34Z,patriknw,Captain1653; kulinux; patriknw; johanandren,Is this a bug of akka cluster?,"In the image attached  there is a akka cluster with localMember with the same address in Down and Weakly Up states (10.124.12.204:8976)  When trying to put the node down  never works  because in ClusterDaemon.scala::downing only use the first address found. So the cluster never get healed and the only solution is restart all akka system.      localMembers.find(_.address == address) match {       case Some(m) if m.status != Down =>         if (localReachability.isReachable(m.uniqueAd   ![image](https://user-images.githubusercontent.com/8877900/124256600-c891b100-db2b-11eb-9e79-85ff5ff986c4.png)   ",,Captain1653; kulinux; patriknw; johanandren
30333,francisdb,2021-06-18T07:25:02Z,2022-11-08T12:02:59Z,johanandren,craffit; francisdb; patriknw; SakulK; johanandren; He-Pin; aumann,AssertionError: assertion failed: Timer should have triggered only after deadline,"`Akka 2.6.10` `openjdk:11-jdk`  The last 3 days we have seen 4 of these on one of our services running in Kubernetes (Google cloud)  https://github.com/akka/akka/commit/01603ccc90befb5f7ce27f3c7e240f54f7ce675f seems to have introduced this assertion (First released in `Akka 2.6.6`)  According to this blog post `System.nanoTime()` can be adjusted by NTP  > Monotonic clocks are also not completely safe. NTP servers can speed up or slow down the clocks (known as slewing) by around 0.05% but they cannot cause the clock to jump forward or backwards.” — @khare_khote https://codeburst.io/why-shouldnt-you-trust-system-clocks-72a82a41df93  But probably there could be other reasons for this assertion to trigger?  ### Possible fixes  - Change the assertion to a WARN or ERROR log message - Allow some drift in the assertion  ### These are the diffs we encountered  ``` now is 1518903501995345 and deadline was 1518903502183533 diff -188188. now is 1518903502002808 and deadline was 1518903502197734 diff -194926. now is 1518903502047087 and deadline was 1518903502157208 diff -110121. now is 1892025571210405 and deadline was 1892025632127525 diff -60917120. ```  ### Full stack trace  ``` java.util.concurrent.ExecutionException: Boxed Exception     at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)     at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:242)     at scala.concurrent.Promise.tryFailure(Promise.scala:117)     at scala.concurrent.Promise.tryFailure$(Promise.scala:117)     at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:104)     at akka.http.impl.util.StreamUtils$$anon$4$$anon$5.onUpstreamFailure(StreamUtils.scala:83)     at akka.stream.impl.fusing.GraphInterpreter.processEvent(GraphInterpreter.scala:524)     at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:390)     at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:625)     at akka.stream.impl.fusing.GraphInterpreterShell$AsyncInput.execute(ActorGraphInterpreter.scala:502)     at akka.stream.impl.fusing.GraphInterpreterShell.processEvent(ActorGraphInterpreter.scala:600)     at akka.stream.impl.fusing.ActorGraphInterpreter.akka$stream$impl$fusing$ActorGraphInterpreter$$processEvent(ActorGraphInterpreter.scala:769)     at akka.stream.impl.fusing.ActorGraphInterpreter$$anonfun$receive$1.applyOrElse(ActorGraphInterpreter.scala:784)     at akka.actor.Actor.aroundReceive(Actor.scala:537)     at akka.actor.Actor.aroundReceive$(Actor.scala:535)     at akka.stream.impl.fusing.ActorGraphInterpreter.aroundReceive(ActorGraphInterpreter.scala:691)     at akka.actor.ActorCell.receiveMessage(ActorCell.scala:577)     at akka.actor.ActorCell.invoke(ActorCell.scala:547)     at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)     at akka.dispatch.Mailbox.run(Mailbox.scala:231)     at akka.dispatch.Mailbox.exec(Mailbox.scala:243)     at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)     at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)     at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)     at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)     at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)  java.lang.AssertionError: assertion failed: Timer should have triggered only after deadline but now is 1518903501995345 and deadline was 1518903502183533 diff -188188.     at scala.Predef$.assert(Predef.scala:280)     at akka.stream.impl.Timers$IdleInject$$anon$7.onTimer(Timers.scala:276)     at akka.stream.stage.TimerGraphStageLogic.onInternalTimer(GraphStage.scala:1602)     at akka.stream.stage.TimerGraphStageLogic.$anonfun$getTimerAsyncCallback$1(GraphStage.scala:1591)     at akka.stream.stage.TimerGraphStageLogic.$anonfun$getTimerAsyncCallback$1$adapted(GraphStage.scala:1591)     at akka.stream.impl.fusing.GraphInterpreter.runAsyncInput(GraphInterpreter.scala:466)     at akka.stream.impl.fusing.GraphInterpreterShell$AsyncInput.execute(ActorGraphInterpreter.scala:498)     at akka.stream.impl.fusing.GraphInterpreterShell.processEvent(ActorGraphInterpreter.scala:600)     at akka.stream.impl.fusing.ActorGraphInterpreter.akka$stream$impl$fusing$ActorGraphInterpreter$$processEvent(ActorGraphInterpreter.scala:769)     at akka.stream.impl.fusing.ActorGraphInterpreter$$anonfun$receive$1.applyOrElse(ActorGraphInterpreter.scala:784)     at akka.actor.Actor.aroundReceive(Actor.scala:537)     at akka.actor.Actor.aroundReceive$(Actor.scala:535)     at akka.stream.impl.fusing.ActorGraphInterpreter.aroundReceive(ActorGraphInterpreter.scala:691)     at akka.actor.ActorCell.receiveMessage(ActorCell.scala:577)     at akka.actor.ActorCell.invoke(ActorCell.scala:547)     at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)     at akka.dispatch.Mailbox.run(Mailbox.scala:231)     at akka.dispatch.Mailbox.exec(Mailbox.scala:243)     at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)     at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)     at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)     at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)     at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) ```",,craffit; francisdb; patriknw; SakulK; johanandren; He-Pin; aumann
30310,hizumisen,2021-06-10T08:18:03Z,2023-09-15T14:14:04Z,johanandren,Captain1653; hizumisen; johanandren,Restart backoff source does not backoff if the source takes longer than the min backoff,"```scala import akka.actor.ActorSystem import akka.event.Logging.DebugLevel import akka.stream.scaladsl.{RestartSource  Sink  Source} import java.util.concurrent.Executors import scala.concurrent.duration._ import scala.concurrent.{ExecutionContext  Future} val system = ActorSystem() system.eventStream.setLogLevel(DebugLevel) val materializer = Materializer.createMaterializer(system) val ec1 = ExecutionContext.fromExecutor(Executors.newCachedThreadPool()) RestartSource.withBackoff(RestartSettings(   100.millis    1000.millis    0.2 ))(() => Source.future(Future { Thread.sleep(1000); 1 }(ec1)))   .runWith(Sink.ignore)(materializer) ```  prints this ``` [DEBUG] [06/10/2021 10:03:57.220] [default-akka.actor.default-dispatcher-4] [RestartWithBackoffSource(akka://default)] Last restart attempt was more than 100 milliseconds ago  resetting restart count [DEBUG] [06/10/2021 10:03:57.225] [default-akka.actor.default-dispatcher-4] [RestartWithBackoffSource(akka://default)] Restarting graph in 109583581 nanoseconds [DEBUG] [06/10/2021 10:03:58.358] [default-akka.actor.default-dispatcher-5] [RestartWithBackoffSource(akka://default)] Last restart attempt was more than 100 milliseconds ago  resetting restart count [DEBUG] [06/10/2021 10:03:58.358] [default-akka.actor.default-dispatcher-5] [RestartWithBackoffSource(akka://default)] Restarting graph in 108899298 nanoseconds [DEBUG] [06/10/2021 10:03:59.482] [default-akka.actor.default-dispatcher-4] [RestartWithBackoffSource(akka://default)] Last restart attempt was more than 100 milliseconds ago  resetting restart count [DEBUG] [06/10/2021 10:03:59.482] [default-akka.actor.default-dispatcher-4] [RestartWithBackoffSource(akka://default)] Restarting graph in 114223714 nanoseconds ```  as you can seen for every backoff iteration the systems restarts leading to no backoff basically.",,Captain1653; hizumisen; johanandren
30249,andreaTP,2021-05-21T16:19:28Z,2023-09-15T14:07:16Z,johanandren,Captain1653; johanandren,RestartFlow is not restarted as expected in presence of async boundaries,"The behavior can be reproduced with this repro: https://github.com/andreaTP/repro-restart-stream  Or even in this Scalafiddle: https://scalafiddle.io/sf/lXKtnnu/2  Adding and removing the `async` boundary from the `Flow` change the behavior of the Restart:  - without `async` the stream gets restarted as expected  - with `async` the stream is not restarted  ",,Captain1653; johanandren
30245,andreaTP,2021-05-18T13:12:42Z,2023-02-08T12:51:05Z,johanandren,,scala 3: remove compiler plugin for SerialVersionUID,"Starting from the next release of Scala 3 we can(and should) remove the compiler plugin used for removing `SerialVersionUID`.  Ref: https://github.com/lampepfl/dotty/pull/12505/files",plugins/serialversion-remover-plugin/src/main/scala/akka/Plugin.scala,johanandren
30205,bdoyle0182,2021-04-29T01:38:29Z,2023-03-10T15:23:37Z,johanandren,He-Pin; thomasschoeftner; johanandren,groupBy improperly throws too many substreams exception when maxStreams used and element comes in on closed substream,"So first the bug is that when groupBy has the max number of streams open and one is subsequently closed  if a new element comes in on that closed sub stream; then groupBy is going to throw `TooManySubstreamsOpenException`. Which I believe the behavior should be that if a new element comes in on a closed substream  the element should be dropped like occurs if `maxSubstreams` is not opened. The way we hit this is that we have strictly defined maxSubstreams based on the number of partitions in our kafka source. 1 partition per substream running infinitely. And somehow one substream seemingly ends up closing   The issue is with this line  https://github.com/akka/akka/blob/master/akka-stream/src/main/scala/akka/stream/impl/fusing/StreamOfStreams.scala#L354  ```       override def onPush(): Unit =         try {           val elem = grab(in)           val key = keyFor(elem)           require(key != null  ""Key cannot be null"")           val substreamSource = activeSubstreamsMap.get(key)           if (substreamSource != null) {             if (substreamSource.isAvailable) substreamSource.push(elem)             else {               nextElementKey = key               nextElementValue = elem             }           } else {             if (activeSubstreamsMap.size + closedSubstreams.size == maxSubstreams)               throw tooManySubstreamsOpenException             else if (closedSubstreams.contains(key) && !hasBeenPulled(in))               pull(in)             else runSubstream(key  elem)           }         } catch {           case NonFatal(ex) =>             decider(ex) match {               case Supervision.Stop                         => fail(ex)               case Supervision.Resume | Supervision.Restart => if (!hasBeenPulled(in)) pull(in)             }         } ```  In the onPush  if the key does not have an active substream it goes to the else. But if this key is in the `closedSubstreams` set   it does the check on if you have too many substreams open first. You're not really trying to open a ""new"" substream past the limit because this element is tied to an already closed substream.   **FIX**: Put the `else if (closedSubstreams.contains(key) && !hasBeenPulled(in))` statement before the check on too many substreams.  Also a couple quick questions on `groupBy` guarantees. So as I can see if a substream is somehow closed  any new elements  tied to that group that come in on it are just swallowed and never emitted down stream. I ask because in the documentation (https://doc.akka.io/docs/akka/current/stream/operators/Source-or-Flow/groupBy.html)  it makes it sound like by setting `allowClosedSubstreamRecreation` to true you're losing a guarantee that is there if it is set to false. But if it's set to false and a substream is closed and an element comes in on the closed substream  that element is also lost. So is there really any more risk in setting `allowClosedSubstreamRecreation` or not because both can seemingly silently lose elements.  Going off that  this bug is actually kind of helping us because we always have the max streams open so if any substream closes it will throw this exception ultimately recreating the entire stream instead of eating any elements and silently losing elements. Continuing to process off the same kafka partition after missing something is bad for us. But that's an us problem  I still think this is a bug.  ",akka-stream-tests/src/test/scala/akka/stream/scaladsl/FlowGroupBySpec.scala; akka-stream/src/main/scala/akka/stream/impl/fusing/StreamOfStreams.scala,johanandren
30201,pashashiz,2021-04-26T07:09:35Z,2023-02-16T13:00:37Z,patriknw,jrudolph; patriknw; ekazakas; johanandren,Akka Streams NPE during postStop,"Hi  I am getting the following error when the computation graph which has inside either `mapAsync` or `flatMapConcat`and wrapped into `RestartSources.onFailuresWithBackoff` fails. This happens when multiple async operations fail at the same time.   Unfortunately  I did not yet come up with a synthetic example to reproduce that. Few words about how we use it. In our project  we use akka streams to wrap Azure ServiceBus reactive library. The library itself is quite unstable so we had to restart it when we cannot acknowledge the messages (we just propagate the error upstream to the source). In case there are multiple errors during async parallel message acknowledgment the graph fails with NPE and the Azure ServiceBus source is not canceled because of that  it leads to resource leaks  and our services just hang after some period of time. In case we make `parallelism = 1` for `mapAsync` or `flatMapConcat` the issue disappears  but that leads to poor performance.  Akka version `2.6.14`  ``` 26-04-2021 09:53:51.725 [consumer-akka.actor.default-dispatcher-5] ERROR akka.actor.RepointableActorRef - Error during postStop in [akka.stream.impl.fusing.GraphStages$IgnoreSink$$anon$10-ignoreSink]: null java.lang.NullPointerException: null 	at akka.stream.stage.GraphStageLogic.afterPostStop(GraphStage.scala:1366) 	at akka.stream.impl.fusing.GraphInterpreter.finalizeStage(GraphInterpreter.scala:600) 	at akka.stream.impl.fusing.GraphInterpreter.afterStageHasRun(GraphInterpreter.scala:579) 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:394) 	at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:625) 	at akka.stream.impl.fusing.GraphInterpreterShell$AsyncInput.execute(ActorGraphInterpreter.scala:502) 	at akka.stream.impl.fusing.GraphInterpreterShell.processEvent(ActorGraphInterpreter.scala:600) 	at akka.stream.impl.fusing.ActorGraphInterpreter.akka$stream$impl$fusing$ActorGraphInterpreter$$processEvent(ActorGraphInterpreter.scala:775) 	at akka.stream.impl.fusing.ActorGraphInterpreter.akka$stream$impl$fusing$ActorGraphInterpreter$$shortCircuitBatch(ActorGraphInterpreter.scala:762) 	at akka.stream.impl.fusing.ActorGraphInterpreter$$anonfun$receive$1.applyOrElse(ActorGraphInterpreter.scala:791) 	at akka.actor.Actor.aroundReceive(Actor.scala:537) 	at akka.actor.Actor.aroundReceive$(Actor.scala:535) 	at akka.stream.impl.fusing.ActorGraphInterpreter.aroundReceive(ActorGraphInterpreter.scala:691) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579) 	at akka.actor.ActorCell.invoke(ActorCell.scala:547) 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) 	at akka.dispatch.Mailbox.run(Mailbox.scala:231) 	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289) 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056) 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692) 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175) ``` ",akka-stream-typed/src/test/scala/akka/stream/typed/scaladsl/Bug30201ReproducerSpec.scala; akka-stream/src/main/scala/akka/stream/impl/fusing/GraphInterpreter.scala,johanandren
30133,makkarpov,2021-03-18T18:06:23Z,2023-09-10T19:54:45Z,makkarpov,Captain1653; makkarpov; johanandren,Add overloaded versions of `typed.AskPattern.ask` with explicit timeouts,"Same kind of issue like explicit actor system: implicit timeouts are too verbose when there are few ask's.  Something like `askT[R](f: RecipientRef[R] => T  timeout: FiniteDuration): Future[R]` and corresponding `askWithStatusT` would be very useful in one-liners.",,Captain1653; makkarpov; johanandren
30077,Zhen-hao,2021-03-04T09:41:45Z,2023-09-12T11:20:19Z,patriknw,Captain1653; patriknw; Zhen-hao; octonato,add an option to ignore deserialization failures from the snapshot store,"The current behavior is that a persistent actor keeps retrying if there is a deserialization exception when loading states from the snapshot store.  when breaking changes in schemas are unavoidable  I have to use both `eventAdapter` and `snapshotAdapter`   while `eventAdapter` should be enough because states can always be built on events.   With this new option  it can save a lot of work when dealing with breaking changes in schemas.",,Captain1653; patriknw; Zhen-hao; octonato
30002,michaeljmarshall,2021-02-04T19:18:39Z,2023-03-08T15:15:06Z,patriknw,patriknw; michaeljmarshall; johanandren,"Cluster Receptionist ""Loses"" All References to Running Actors After Node(s) Leave Cluster","### Problem Description I am running an akka cluster with 5 to 20 nodes. The cluster scales up and down frequently  depending on load. It normally scales up and down without issue. About 10 times over the past 3 months  the Cluster Receptionist has incorrectly distributed empty `Listings` to subscribers when there are definitely actors running for those `ServiceKeys` (even local actors). Based on looking at the debug logs from the receptionist  it appears that the replicator actor is sending an empty `Map` to the receptionist  and that triggers delivery of the empty `Listings` to subscribers. The only correlation is that it only happens when a node is being removed  and the problematic state (from the replicator) always seems to come from a node that is being removed. That state is then distributed to other nodes (replicators and then receptionists) and that renders our group routers (and other `ServiceKey` subscribers) useless. For reference  we've had about 4000 scaling events (up and down) in the past 3 weeks and we've only run into this problem 3 times  so it is stable most of the time.  This behavior has happened when scaling down from 12 nodes to 10  from 6 to 5  and from 7 to 5--it doesn't appear tied to a specific node count  and in general the nodes leaving are not the oldest. There doesn't appear to be any relevant SBR logging either (config below).  We're not yet able to reproduce this issue intentionally. I'm hopeful that you might be able to gain insight from the debug logs below. Please let me know if there is any additional information you would like or need.  ### Configuration We have seen this behavior when running with akka `2.6.9` and `2.6.11`. It doesn't appear that `2.6.12` has released any changes to the Cluster Receptionist or any of its dependencies.  We are using the default configuration for the `akka.cluster.typed.receptionist` and for `akka.cluster.ddata.typed` provided by the `akka-cluster-typed` module.  Here is the SBR config  in case it is relevant (we're not running with any roles defined):  ```    split-brain-resolver {       active-strategy = keep-oldest       keep-oldest {         down-if-alone = ""on""         role = """"       }     } ```  ### Possibly Related Issues I see that https://github.com/akka/akka/issues/26284 describes a similar problem where the receptionist ends up with zero actors for each service even though there are still actors running. Although  I am seeing this behavior when a node is gracefully removed from the cluster  not added  and I am not seeing the behavior mentioned in issue https://github.com/akka/akka/issues/26283.  ### Some Logs Here are some relevant logs that at least demonstrate the problem. Because my examples have many nodes  I've curated the collection of logs. I think this should be helpful in showing the problem  but please let me know if more information would be helpful.  #### Example logs from perspective of node leaving and a peer node staying  In the run up to this example  several nodes were removed successfully without an empty map getting distributed by the replicator. The first log block shows the first occurrence of the empty map and the second shows one of the other nodes receiving it.  In the following block  pod `10.100.185.178` receives a `SIGTERM` (logging not shown)  which triggers two actors to stop (during the coordinated shutdown). The next thing the receptionist logs is an update from the replicator with an empty `Map`. These are the final logs from this receptionist. Based on looking at the logs from all nodes  this is the first time the `Map()` is distributed from a replicator. The origination of the empty map is the node that has one actor unregister and one terminated as the node is preparing to leave the cluster.  ``` 2021-01-24 05:41:37 583 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.185.178:2552] - Change from replicator: [Map(ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) -> Set(akka://my-app-prod@10.100.212.222:2552/user/Application/LocalCallRouterManager#40012617 @ -743261628060693816  akka://my-app-prod@10.100.159.169:2552/user/Application/LocalCallRouterManager#-2094153561 @ 418384113807029226  akka://my-app-prod/user/Application/LocalCallRouterManager#894936084 @ -2759525557872818481  akka://my-app-prod@10.100.208.164:2552/user/Application/LocalCallRouterManager#461891314 @ -2308737100824387714  akka://my-app-prod@10.100.209.236:2552/user/Application/LocalCallRouterManager#503652784 @ 889971137735637201  akka://my-app-prod@10.100.153.160:2552/user/Application/LocalCallRouterManager#-804358190 @ -250641555047075505  akka://my-app-prod@10.100.159.206:2552/user/Application/LocalCallRouterManager#-1132538476 @ -1823237937034187381  akka://my-app-prod@10.100.213.178:2552/user/Application/LocalCallRouterManager#-513599504 @ -9165526144140741561  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-1882489242 @ -1470262058782795741  akka://my-app-prod@10.100.154.229:2552/user/Application/LocalCallRouterManager#-1837414838 @ 3530969158248915835  akka://my-app-prod@10.100.156.141:2552/user/Application/LocalCallRouterManager#-1250351967 @ 5399617832396662577)  ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) -> Set(akka://my-app-prod@10.100.212.222:2552/user/Application/LocalCtxManager#2137718447 @ -743261628060693816  akka://my-app-prod@10.100.213.178:2552/user/Application/LocalCtxManager#-1578044368 @ -9165526144140741561  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#1587849711 @ -1470262058782795741  akka://my-app-prod@10.100.209.236:2552/user/Application/LocalCtxManager#-832250946 @ 889971137735637201  akka://my-app-prod@10.100.156.141:2552/user/Application/LocalCtxManager#79196896 @ 5399617832396662577  akka://my-app-prod@10.100.154.229:2552/user/Application/LocalCtxManager#-298819366 @ 3530969158248915835  akka://my-app-prod@10.100.159.206:2552/user/Application/LocalCtxManager#1107508580 @ -1823237937034187381  akka://my-app-prod/user/Application/LocalCtxManager#1073023567 @ -2759525557872818481  akka://my-app-prod@10.100.159.169:2552/user/Application/LocalCtxManager#1804738704 @ 418384113807029226  akka://my-app-prod@10.100.208.164:2552/user/Application/LocalCtxManager#-2059427551 @ -2308737100824387714  akka://my-app-prod@10.100.153.160:2552/user/Application/LocalCtxManager#-1302275306 @ -250641555047075505))]  changes: [(localCallRouterManagers [akka://my-app-prod@10.100.212.222:2552/user/Application/LocalCallRouterManager#40012617 @ -743261628060693816  akka://my-app-prod@10.100.159.169:2552/user/Application/LocalCallRouterManager#-2094153561 @ 418384113807029226  akka://my-app-prod/user/Application/LocalCallRouterManager#894936084 @ -2759525557872818481  akka://my-app-prod@10.100.208.164:2552/user/Application/LocalCallRouterManager#461891314 @ -2308737100824387714  akka://my-app-prod@10.100.209.236:2552/user/Application/LocalCallRouterManager#503652784 @ 889971137735637201  akka://my-app-prod@10.100.153.160:2552/user/Application/LocalCallRouterManager#-804358190 @ -250641555047075505  akka://my-app-prod@10.100.159.206:2552/user/Application/LocalCallRouterManager#-1132538476 @ -1823237937034187381  akka://my-app-prod@10.100.213.178:2552/user/Application/LocalCallRouterManager#-513599504 @ -9165526144140741561  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-1882489242 @ -1470262058782795741  akka://my-app-prod@10.100.154.229:2552/user/Application/LocalCallRouterManager#-1837414838 @ 3530969158248915835  akka://my-app-prod@10.100.156.141:2552/user/Application/LocalCallRouterManager#-1250351967 @ 5399617832396662577])  (localCtxLeaseManagers [akka://my-app-prod@10.100.212.222:2552/user/Application/LocalCtxManager#2137718447 @ -743261628060693816  akka://my-app-prod@10.100.213.178:2552/user/Application/LocalCtxManager#-1578044368 @ -9165526144140741561  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#1587849711 @ -1470262058782795741  akka://my-app-prod@10.100.209.236:2552/user/Application/LocalCtxManager#-832250946 @ 889971137735637201  akka://my-app-prod@10.100.156.141:2552/user/Application/LocalCtxManager#79196896 @ 5399617832396662577  akka://my-app-prod@10.100.154.229:2552/user/Application/LocalCtxManager#-298819366 @ 3530969158248915835  akka://my-app-prod@10.100.159.206:2552/user/Application/LocalCtxManager#1107508580 @ -1823237937034187381  akka://my-app-prod/user/Application/LocalCtxManager#1073023567 @ -2759525557872818481  akka://my-app-prod@10.100.159.169:2552/user/Application/LocalCtxManager#1804738704 @ 418384113807029226  akka://my-app-prod@10.100.208.164:2552/user/Application/LocalCtxManager#-2059427551 @ -2308737100824387714  akka://my-app-prod@10.100.153.160:2552/user/Application/LocalCtxManager#-1302275306 @ -250641555047075505])]  tombstones [] 2021-01-24 05:56:36 016 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.185.178:2552] - Registered actor terminated: [localCtxLeaseManagers] [akka://my-app-prod/user/Application/LocalCtxManager#1073023567 @ -2759525557872818481] 2021-01-24 05:56:36 019 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.185.178:2552] - Unregister actor: [localCallRouterManagers] [akka://my-app-prod/user/Application/LocalCallRouterManager#894936084 @ -2759525557872818481] 2021-01-24 05:56:36 183 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.185.178:2552] - Change from replicator: [Map()]  changes: [(localCallRouterManagers [])  (localCtxLeaseManagers [])]  tombstones [Actor[akka://my-app-prod/user/Application/LocalCtxManager#1073023567] -> Set((ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) Deadline(86400000 milliseconds)))  Actor[akka://my-app-prod/user/Application/LocalCallRouterManager#894936084] -> Set((ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) Deadline(86400000 milliseconds)))] 2021-01-24 05:56:51 555 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.185.178:2552] - terminated/removed 2021-01-24 05:56:51 557 DEBUG akka://my-app-prod/system/clusterReceptionist - Cancel all timers ```  Next  node `10.100.154.229` is a peer to the node `10.100.185.178` above (notice the timestamps). This example shows the propagation of the empty map (this was observable on all remaining nodes in the cluster  too)  and it also shows that there were still actors running for each `ServiceKey`. These are the final log lines from this receptionist before it shuts down. Notice that the terminated actors were in the initial state propagated in the first log line. (This behavior is not entirely surprising  because the cluster receptionist uses the replicator's changes as a source of truth. The log lines about actors being terminated come because the actors were still being watched by the cluster receptionist. It simply proves the point that the actors were still running.)   ``` 2021-01-24 05:41:37 704 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.154.229:2552] - Change from replicator: [Map(ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) -> Set(akka://my-app-prod@10.100.212.222:2552/user/Application/LocalCtxManager#2137718447 @ -743261628060693816  akka://my-app-prod@10.100.213.178:2552/user/Application/LocalCtxManager#-1578044368 @ -9165526144140741561  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#1587849711 @ -1470262058782795741  akka://my-app-prod@10.100.209.236:2552/user/Application/LocalCtxManager#-832250946 @ 889971137735637201  akka://my-app-prod@10.100.156.141:2552/user/Application/LocalCtxManager#79196896 @ 5399617832396662577  akka://my-app-prod/user/Application/LocalCtxManager#-298819366 @ 3530969158248915835  akka://my-app-prod@10.100.159.206:2552/user/Application/LocalCtxManager#1107508580 @ -1823237937034187381  akka://my-app-prod@10.100.185.178:2552/user/Application/LocalCtxManager#1073023567 @ -2759525557872818481  akka://my-app-prod@10.100.159.169:2552/user/Application/LocalCtxManager#1804738704 @ 418384113807029226  akka://my-app-prod@10.100.208.164:2552/user/Application/LocalCtxManager#-2059427551 @ -2308737100824387714  akka://my-app-prod@10.100.153.160:2552/user/Application/LocalCtxManager#-1302275306 @ -250641555047075505)  ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) -> Set(akka://my-app-prod@10.100.212.222:2552/user/Application/LocalCallRouterManager#40012617 @ -743261628060693816  akka://my-app-prod@10.100.159.169:2552/user/Application/LocalCallRouterManager#-2094153561 @ 418384113807029226  akka://my-app-prod@10.100.185.178:2552/user/Application/LocalCallRouterManager#894936084 @ -2759525557872818481  akka://my-app-prod@10.100.208.164:2552/user/Application/LocalCallRouterManager#461891314 @ -2308737100824387714  akka://my-app-prod@10.100.209.236:2552/user/Application/LocalCallRouterManager#503652784 @ 889971137735637201  akka://my-app-prod@10.100.153.160:2552/user/Application/LocalCallRouterManager#-804358190 @ -250641555047075505  akka://my-app-prod@10.100.159.206:2552/user/Application/LocalCallRouterManager#-1132538476 @ -1823237937034187381  akka://my-app-prod@10.100.213.178:2552/user/Application/LocalCallRouterManager#-513599504 @ -9165526144140741561  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-1882489242 @ -1470262058782795741  akka://my-app-prod/user/Application/LocalCallRouterManager#-1837414838 @ 3530969158248915835  akka://my-app-prod@10.100.156.141:2552/user/Application/LocalCallRouterManager#-1250351967 @ 5399617832396662577))]  changes: [(localCtxLeaseManagers [akka://my-app-prod@10.100.212.222:2552/user/Application/LocalCtxManager#2137718447 @ -743261628060693816  akka://my-app-prod@10.100.213.178:2552/user/Application/LocalCtxManager#-1578044368 @ -9165526144140741561  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#1587849711 @ -1470262058782795741  akka://my-app-prod@10.100.209.236:2552/user/Application/LocalCtxManager#-832250946 @ 889971137735637201  akka://my-app-prod@10.100.156.141:2552/user/Application/LocalCtxManager#79196896 @ 5399617832396662577  akka://my-app-prod/user/Application/LocalCtxManager#-298819366 @ 3530969158248915835  akka://my-app-prod@10.100.159.206:2552/user/Application/LocalCtxManager#1107508580 @ -1823237937034187381  akka://my-app-prod@10.100.185.178:2552/user/Application/LocalCtxManager#1073023567 @ -2759525557872818481  akka://my-app-prod@10.100.159.169:2552/user/Application/LocalCtxManager#1804738704 @ 418384113807029226  akka://my-app-prod@10.100.208.164:2552/user/Application/LocalCtxManager#-2059427551 @ -2308737100824387714  akka://my-app-prod@10.100.153.160:2552/user/Application/LocalCtxManager#-1302275306 @ -250641555047075505])  (localCallRouterManagers [akka://my-app-prod@10.100.212.222:2552/user/Application/LocalCallRouterManager#40012617 @ -743261628060693816  akka://my-app-prod@10.100.159.169:2552/user/Application/LocalCallRouterManager#-2094153561 @ 418384113807029226  akka://my-app-prod@10.100.185.178:2552/user/Application/LocalCallRouterManager#894936084 @ -2759525557872818481  akka://my-app-prod@10.100.208.164:2552/user/Application/LocalCallRouterManager#461891314 @ -2308737100824387714  akka://my-app-prod@10.100.209.236:2552/user/Application/LocalCallRouterManager#503652784 @ 889971137735637201  akka://my-app-prod@10.100.153.160:2552/user/Application/LocalCallRouterManager#-804358190 @ -250641555047075505  akka://my-app-prod@10.100.159.206:2552/user/Application/LocalCallRouterManager#-1132538476 @ -1823237937034187381  akka://my-app-prod@10.100.213.178:2552/user/Application/LocalCallRouterManager#-513599504 @ -9165526144140741561  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-1882489242 @ -1470262058782795741  akka://my-app-prod/user/Application/LocalCallRouterManager#-1837414838 @ 3530969158248915835  akka://my-app-prod@10.100.156.141:2552/user/Application/LocalCallRouterManager#-1250351967 @ 5399617832396662577])]  tombstones [] 2021-01-24 05:56:37 405 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.154.229:2552] - Change from replicator: [Map()]  changes: [(localCtxLeaseManagers [])  (localCallRouterManagers [])]  tombstones [] 2021-01-25 02:25:38 088 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.154.229:2552] - Registered actor terminated: [localCtxLeaseManagers] [akka://my-app-prod/user/Application/LocalCtxManager#-298819366 @ 3530969158248915835] 2021-01-25 02:25:38 091 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.154.229:2552] - Registered actor terminated: [localCallRouterManagers] [akka://my-app-prod/user/Application/LocalCallRouterManager#-1837414838 @ 3530969158248915835] 2021-01-25 02:25:40 946 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.154.229:2552] - terminated/removed ```   #### Example with replicator debug logging turned on  In this example from a different cluster  I had the replicator's debug logging turned on.  The cluster starts out with 7 nodes  and is scaling down to 5 nodes. We start with node `10.100.209.44` receiving a `SIGTERM` and starting to shut down  and then `10.100.180.26` receives a `SIGTERM`. Notice that the empty map is first distributed at `02:12:26 332`. As you can see  before that  all of the changes from the replicator are non empty. Eventually  group routers start dead lettering messages  but that's not shown here.  ``` 10.100.209.44:2552 Caught SIGTERM 2021-01-31 02:12:25 618 INFO   - Notifying the App actor to drain the LocalCtxManager. 2021-01-31 02:12:25 619 INFO  akka://my-app-prod@10.100.209.44:2552/user/Application - Received DrainLocalCtxManager. Draining now. 2021-01-31 02:12:25 621 INFO  akka://my-app-prod/user/Application/LocalCtxManager - Received Stop without children; stopping now. 2021-01-31 02:12:25 621 INFO  akka://my-app-prod/user/Application/LocalCtxManager - Stopped 2021-01-31 02:12:25 622 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.209.44:2552] - Registered actor terminated: [localCtxLeaseManagers] [akka://my-app-prod/user/Application/LocalCtxManager#141296455 @ 2454496888910058018] 2021-01-31 02:12:25 622 INFO   - Result of draining LocalCtxManager: [Done] 2021-01-31 02:12:25 622 INFO  akka://my-app-prod@10.100.209.44:2552/user/Application - Result for DrainLocalCtxManager: Success(true) 2021-01-31 02:12:25 623 INFO  akka://my-app-prod/user/Application/LocalCallRouterManager - Received Stop. Stopping 3 children and then self. 2021-01-31 02:12:25 622 INFO   - Notifying the App actor to drain the LocalCallRouterManager. 2021-01-31 02:12:25 623 INFO  akka://my-app-prod@10.100.209.44:2552/user/Application - Received DrainLocalCallRouterManager. Draining now. 2021-01-31 02:12:25 624 DEBUG akka://my-app-prod@10.100.209.44:2552/system/clusterReceptionist/replicator - Received Update for key [ReceptionistKey_2]. 2021-01-31 02:12:25 624 INFO  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager/3/callRouter - Received Done; stopping actor and children... 2021-01-31 02:12:25 624 INFO  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager/1/callRouter - Received Done; stopping actor and children... 2021-01-31 02:12:25 624 INFO  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager/2/callRouter - Received Done; stopping actor and children... 2021-01-31 02:12:25 625 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.209.44:2552] - Unregister actor: [localCallRouterManagers] [akka://my-app-prod/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018] 2021-01-31 02:12:25 625 DEBUG akka://my-app-prod@10.100.209.44:2552/system/clusterReceptionist/replicator - Received Update for key [ReceptionistKey_2]. 10.100.180.26:2552 Caught SIGTERM 2021-01-31 02:12:25 634 INFO  akka://my-app-prod@10.100.180.26:2552/user/Application - Received DrainLocalCtxManager. Draining now. 2021-01-31 02:12:25 634 INFO   - Notifying the App actor to drain the LocalCtxManager. 2021-01-31 02:12:25 635 INFO  akka://my-app-prod/user/Application/LocalCtxManager - Received Stop without children; stopping now. 2021-01-31 02:12:25 635 INFO  akka://my-app-prod/user/Application/LocalCtxManager - Stopped 2021-01-31 02:12:25 636 INFO  akka://my-app-prod@10.100.180.26:2552/user/Application - Result for DrainLocalCtxManager: Success(true) 2021-01-31 02:12:25 637 INFO  akka://my-app-prod@10.100.180.26:2552/user/Application - Received DrainLocalCallRouterManager. Draining now. 2021-01-31 02:12:25 636 INFO   - Result of draining LocalCtxManager: [Done] 2021-01-31 02:12:25 637 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.180.26:2552] - Registered actor terminated: [localCtxLeaseManagers] [akka://my-app-prod/user/Application/LocalCtxManager#1134266383 @ 822827292567174640] 2021-01-31 02:12:25 637 INFO  akka://my-app-prod/user/Application/LocalCallRouterManager - Received Stop. Stopping 3 children and then self. 2021-01-31 02:12:25 637 INFO   - Notifying the App actor to drain the LocalCallRouterManager. 2021-01-31 02:12:25 638 INFO  akka://my-app-prod@10.100.180.26:2552/user/Application/LocalCallRouterManager/1/callRouter - Received Done; stopping actor and children... 2021-01-31 02:12:25 638 INFO  akka://my-app-prod@10.100.180.26:2552/user/Application/LocalCallRouterManager/2/callRouter - Received Done; stopping actor and children... 2021-01-31 02:12:25 638 INFO  akka://my-app-prod@10.100.180.26:2552/user/Application/LocalCallRouterManager/3/callRouter - Received Done; stopping actor and children... 2021-01-31 02:12:25 638 DEBUG akka://my-app-prod@10.100.180.26:2552/system/clusterReceptionist/replicator - Received Update for key [ReceptionistKey_2]. 2021-01-31 02:12:25 639 DEBUG akka://my-app-prod@10.100.190.6:2552/system/clusterReceptionist/replicator - Skipping DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552] because that node has been removed 2021-01-31 02:12:25 639 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.180.26:2552] - Unregister actor: [localCallRouterManagers] [akka://my-app-prod/user/Application/LocalCallRouterManager#767740981 @ 822827292567174640] 2021-01-31 02:12:25 639 DEBUG akka://my-app-prod@10.100.190.6:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552]  containing [ReceptionistKey_2 3-4]. 2021-01-31 02:12:25 640 DEBUG akka://my-app-prod@10.100.180.26:2552/system/clusterReceptionist/replicator - Received Update for key [ReceptionistKey_2]. 2021-01-31 02:12:25 645 DEBUG akka://my-app-prod@10.100.190.6:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552]  containing [ReceptionistKey_2 3-4]. 2021-01-31 02:12:25 645 DEBUG akka://my-app-prod@10.100.190.6:2552/system/clusterReceptionist/replicator - Applying DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552] for [ReceptionistKey_2] with sequence numbers [3-4]  current was [2] 2021-01-31 02:12:25 645 DEBUG akka://my-app-prod@10.100.209.44:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552]  containing [ReceptionistKey_2 3-4]. 2021-01-31 02:12:25 645 DEBUG akka://my-app-prod@10.100.209.44:2552/system/clusterReceptionist/replicator - Applying DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552] for [ReceptionistKey_2] with sequence numbers [3-4]  current was [2] 2021-01-31 02:12:25 812 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.180.26:2552] - Change from replicator: [Map(ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) -> Set(akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCtxManager#141296455 @ 2454496888910058018)  ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) -> Set(akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802))]  changes: [(localCtxLeaseManagers [akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCtxManager#141296455 @ 2454496888910058018])  (localCallRouterManagers [akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802])]  tombstones [Actor[akka://my-app-prod/user/Application/LocalCtxManager#1134266383] -> Set((ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) Deadline(86400000 milliseconds)))  Actor[akka://my-app-prod/user/Application/LocalCallRouterManager#767740981] -> Set((ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) Deadline(86400000 milliseconds)))] 2021-01-31 02:12:26 002 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.190.6:2552] - Change from replicator: [Map(ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) -> Set(akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802)  ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) -> Set(akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCtxManager#141296455 @ 2454496888910058018))]  changes: [(localCallRouterManagers [akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802])  (localCtxLeaseManagers [akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCtxManager#141296455 @ 2454496888910058018])]  tombstones [] 2021-01-31 02:12:26 058 DEBUG akka://my-app-prod@10.100.154.14:2552/system/clusterReceptionist/replicator - Skipping DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552] because that node has been removed 2021-01-31 02:12:26 058 DEBUG akka://my-app-prod@10.100.153.226:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552]  containing [ReceptionistKey_2 3-4]. 2021-01-31 02:12:26 058 DEBUG akka://my-app-prod@10.100.154.14:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552]  containing [ReceptionistKey_2 3-4]. 2021-01-31 02:12:26 058 DEBUG akka://my-app-prod@10.100.153.226:2552/system/clusterReceptionist/replicator - Skipping DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552] because that node has been removed 2021-01-31 02:12:26 064 DEBUG akka://my-app-prod@10.100.153.226:2552/system/clusterReceptionist/replicator - Applying DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552] for [ReceptionistKey_2] with sequence numbers [3-4]  current was [2] 2021-01-31 02:12:26 064 DEBUG akka://my-app-prod@10.100.153.226:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552]  containing [ReceptionistKey_2 3-4]. 2021-01-31 02:12:26 064 DEBUG akka://my-app-prod@10.100.154.14:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552]  containing [ReceptionistKey_2 3-4]. 2021-01-31 02:12:26 064 DEBUG akka://my-app-prod@10.100.154.14:2552/system/clusterReceptionist/replicator - Applying DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552] for [ReceptionistKey_2] with sequence numbers [3-4]  current was [2] 2021-01-31 02:12:26 083 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.153.226:2552] - Change from replicator: [Map(ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) -> Set(akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802)  ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) -> Set(akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCtxManager#141296455 @ 2454496888910058018))]  changes: [(localCallRouterManagers [akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802])  (localCtxLeaseManagers [akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCtxManager#141296455 @ 2454496888910058018])]  tombstones [] 2021-01-31 02:12:26 109 DEBUG akka://my-app-prod@10.100.153.226:2552/system/clusterReceptionist/replicator - adding removed node [UniqueAddress(akka://my-app-prod@10.100.185.100:2552 -344885494066259298)] from MemberRemoved 2021-01-31 02:12:26 109 INFO  Cluster(akka://my-app-prod) - Cluster Node [akka://my-app-prod@10.100.153.226:2552] - Leader is removing confirmed Exiting node [akka://my-app-prod@10.100.185.100:2552] 2021-01-31 02:12:26 109 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.153.226:2552] - Leader node observed removed node [UniqueAddress(akka://my-app-prod@10.100.185.100:2552 -344885494066259298)] 2021-01-31 02:12:26 136 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.209.44:2552] - Change from replicator: [Map(ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) -> Set(akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod/user/Application/LocalCtxManager#141296455 @ 2454496888910058018)  ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) -> Set(akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802))]  changes: [(localCallRouterManagers [akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802])  (localCtxLeaseManagers [akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod/user/Application/LocalCtxManager#141296455 @ 2454496888910058018])]  tombstones [Actor[akka://my-app-prod/user/Application/LocalCtxManager#141296455] -> Set((ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) Deadline(86400000 milliseconds)))  Actor[akka://my-app-prod/user/Application/LocalCallRouterManager#526129629] -> Set((ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) Deadline(86400000 milliseconds)))] 2021-01-31 02:12:26 137 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.209.44:2552] - Saw ActorRefs that were tomstoned [Actor[akka://my-app-prod/user/Application/LocalCallRouterManager#526129629]]  re-removing. 2021-01-31 02:12:26 138 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.209.44:2552] - Saw ActorRefs that were tomstoned [Actor[akka://my-app-prod/user/Application/LocalCtxManager#141296455]]  re-removing. 2021-01-31 02:12:26 139 DEBUG akka://my-app-prod@10.100.209.44:2552/system/clusterReceptionist/replicator - Received Update for key [ReceptionistKey_2]. 2021-01-31 02:12:26 140 DEBUG akka://my-app-prod@10.100.209.44:2552/system/clusterReceptionist/replicator - Received Update for key [ReceptionistKey_2]. 2021-01-31 02:12:26 186 DEBUG akka://my-app-prod@10.100.180.26:2552/system/clusterReceptionist/replicator - Received gossip status from [akka://my-app-prod@10.100.209.44:2552]  chunk [1] of [1] containing [ReceptionistKey_2  ReceptionistKey_1  ReceptionistKey_0]. 2021-01-31 02:12:26 187 DEBUG akka://my-app-prod@10.100.180.26:2552/system/clusterReceptionist/replicator - Created [1] Gossip messages from [1] data entries. 2021-01-31 02:12:26 187 DEBUG akka://my-app-prod@10.100.180.26:2552/system/clusterReceptionist/replicator - Sending gossip to [akka://my-app-prod@10.100.209.44:2552]  containing [ReceptionistKey_2] 2021-01-31 02:12:26 189 DEBUG akka://my-app-prod@10.100.209.44:2552/system/clusterReceptionist/replicator - Received gossip from [akka://my-app-prod@10.100.180.26:2552]  containing [ReceptionistKey_2]. 2021-01-31 02:12:26 190 DEBUG akka://my-app-prod@10.100.209.44:2552/system/clusterReceptionist/replicator - Created [1] Gossip messages from [1] data entries. 2021-01-31 02:12:26 191 DEBUG akka://my-app-prod@10.100.180.26:2552/system/clusterReceptionist/replicator - Received gossip from [akka://my-app-prod@10.100.209.44:2552]  containing [ReceptionistKey_2]. 2021-01-31 02:12:26 332 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.180.26:2552] - Change from replicator: [Map()]  changes: [(localCtxLeaseManagers [])  (localCallRouterManagers [])]  tombstones [Actor[akka://my-app-prod/user/Application/LocalCtxManager#1134266383] -> Set((ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) Deadline(86400000 milliseconds)))  Actor[akka://my-app-prod/user/Application/LocalCallRouterManager#767740981] -> Set((ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) Deadline(86400000 milliseconds)))] 2021-01-31 02:12:26 342 DEBUG akka://my-app-prod@10.100.153.226:2552/system/clusterReceptionist/replicator - Received gossip status from [akka://my-app-prod@10.100.190.6:2552]  chunk [1] of [1] containing [ReceptionistKey_2  ReceptionistKey_1  ReceptionistKey_0]. 2021-01-31 02:12:26 343 DEBUG akka://my-app-prod@10.100.180.26:2552/system/clusterReceptionist/replicator - Sending gossip to [akka://my-app-prod@10.100.157.79:2552]  containing [ReceptionistKey_2] 2021-01-31 02:12:26 343 DEBUG akka://my-app-prod@10.100.180.26:2552/system/clusterReceptionist/replicator - Received gossip status from [akka://my-app-prod@10.100.157.79:2552]  chunk [1] of [1] containing [ReceptionistKey_2  ReceptionistKey_1  ReceptionistKey_0]. 2021-01-31 02:12:26 343 DEBUG akka://my-app-prod@10.100.180.26:2552/system/clusterReceptionist/replicator - Created [1] Gossip messages from [1] data entries. 2021-01-31 02:12:26 345 DEBUG akka://my-app-prod@10.100.157.79:2552/system/clusterReceptionist/replicator - Received gossip from [akka://my-app-prod@10.100.180.26:2552]  containing [ReceptionistKey_2]. 2021-01-31 02:12:26 346 DEBUG akka://my-app-prod@10.100.157.79:2552/system/clusterReceptionist/replicator - Created [1] Gossip messages from [1] data entries. 2021-01-31 02:12:26 347 DEBUG akka://my-app-prod@10.100.180.26:2552/system/clusterReceptionist/replicator - Received gossip from [akka://my-app-prod@10.100.157.79:2552]  containing [ReceptionistKey_2]. 2021-01-31 02:12:26 353 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.157.79:2552] - Change from replicator: [Map()]  changes: [(localCallRouterManagers [])  (localCtxLeaseManagers [])]  tombstones [] 2021-01-31 02:12:26 394 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.154.14:2552] - Change from replicator: [Map(ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) -> Set(akka://my-app-prod/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802)  ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) -> Set(akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCtxManager#141296455 @ 2454496888910058018))]  changes: [(localCallRouterManagers [akka://my-app-prod/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802])  (localCtxLeaseManagers [akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod@10.100.156.157:2552/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCtxManager#141296455 @ 2454496888910058018])]  tombstones [] 2021-01-31 02:12:26 423 DEBUG akka://my-app-prod@10.100.156.157:2552/system/clusterReceptionist/replicator - Created [1] Gossip messages from [1] data entries. 2021-01-31 02:12:26 423 DEBUG akka://my-app-prod@10.100.156.157:2552/system/clusterReceptionist/replicator - Received gossip status from [akka://my-app-prod@10.100.153.226:2552]  chunk [1] of [1] containing [ReceptionistKey_2  ReceptionistKey_0  ReceptionistKey_1]. 2021-01-31 02:12:26 423 DEBUG akka://my-app-prod@10.100.156.157:2552/system/clusterReceptionist/replicator - Sending gossip to [akka://my-app-prod@10.100.153.226:2552]  containing [ReceptionistKey_2] 2021-01-31 02:12:26 425 DEBUG akka://my-app-prod@10.100.153.226:2552/system/clusterReceptionist/replicator - Received gossip from [akka://my-app-prod@10.100.156.157:2552]  containing [ReceptionistKey_2]. 2021-01-31 02:12:26 426 DEBUG akka://my-app-prod@10.100.153.226:2552/system/clusterReceptionist/replicator - Created [1] Gossip messages from [1] data entries. 2021-01-31 02:12:26 428 DEBUG akka://my-app-prod@10.100.156.157:2552/system/clusterReceptionist/replicator - Received gossip from [akka://my-app-prod@10.100.153.226:2552]  containing [ReceptionistKey_2]. 2021-01-31 02:12:26 478 DEBUG akka://my-app-prod@10.100.157.79:2552/system/clusterReceptionist/replicator - Skipping DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552] because that node has been removed 2021-01-31 02:12:26 478 DEBUG akka://my-app-prod@10.100.156.157:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552]  containing [ReceptionistKey_2 3-6]. 2021-01-31 02:12:26 478 DEBUG akka://my-app-prod@10.100.157.79:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552]  containing [ReceptionistKey_2 3-6]. 2021-01-31 02:12:26 478 DEBUG akka://my-app-prod@10.100.156.157:2552/system/clusterReceptionist/replicator - Skipping DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552] because that node has been removed 2021-01-31 02:12:26 484 DEBUG akka://my-app-prod@10.100.157.79:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552]  containing [ReceptionistKey_2 3-4]. 2021-01-31 02:12:26 484 DEBUG akka://my-app-prod@10.100.157.79:2552/system/clusterReceptionist/replicator - Skipping DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552] for [ReceptionistKey_2] because toSeqNr [4] already handled [4] 2021-01-31 02:12:26 485 DEBUG akka://my-app-prod@10.100.156.157:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552]  containing [ReceptionistKey_2 3-4]. 2021-01-31 02:12:26 485 DEBUG akka://my-app-prod@10.100.156.157:2552/system/clusterReceptionist/replicator - Skipping DeltaPropagation from [akka://my-app-prod@10.100.180.26:2552] for [ReceptionistKey_2] because toSeqNr [4] already handled [4] 2021-01-31 02:12:26 622 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.156.157:2552] - Change from replicator: [Map(ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) -> Set(akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCtxManager#141296455 @ 2454496888910058018)  ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) -> Set(akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802))]  changes: [(localCtxLeaseManagers [akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCtxManager#-33037600 @ -8141931844151411976  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCtxManager#1746485139 @ -5792725560272786467  akka://my-app-prod/user/Application/LocalCtxManager#-1504653330 @ 2506746364285588802  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCtxManager#-819939032 @ -2477274232542777140  akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCtxManager#-2092618568 @ 4785710581796845663  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCtxManager#141296455 @ 2454496888910058018])  (localCallRouterManagers [akka://my-app-prod@10.100.154.14:2552/user/Application/LocalCallRouterManager#-179557146 @ 4785710581796845663  akka://my-app-prod@10.100.190.6:2552/user/Application/LocalCallRouterManager#1555411639 @ -5792725560272786467  akka://my-app-prod@10.100.209.44:2552/user/Application/LocalCallRouterManager#526129629 @ 2454496888910058018  akka://my-app-prod@10.100.153.226:2552/user/Application/LocalCallRouterManager#-1322632180 @ -2477274232542777140  akka://my-app-prod@10.100.157.79:2552/user/Application/LocalCallRouterManager#-620362223 @ -8141931844151411976  akka://my-app-prod/user/Application/LocalCallRouterManager#684517585 @ 2506746364285588802])]  tombstones [] 2021-01-31 02:12:26 623 INFO  akka://my-app-prod@10.100.156.157:2552/user/contextManager/singleton - Received an updated localCallRouterManagers list with 6 actor(s). 2021-01-31 02:12:26 656 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.209.44:2552] - Change from replicator: [Map()]  changes: [(localCtxLeaseManagers [])  (localCallRouterManagers [])]  tombstones [Actor[akka://my-app-prod/user/Application/LocalCtxManager#141296455] -> Set((ServiceKey[com.my-app.workflow.LocalManager$Request](localCtxLeaseManagers) Deadline(86400000 milliseconds)))  Actor[akka://my-app-prod/user/Application/LocalCallRouterManager#526129629] -> Set((ServiceKey[com.my-app.workflow.LocalManager$Request](localCallRouterManagers) Deadline(86400000 milliseconds)))] 2021-01-31 02:12:26 670 DEBUG akka://my-app-prod@10.100.180.26:2552/system/clusterReceptionist/replicator - adding removed node [UniqueAddress(akka://my-app-prod@10.100.185.100:2552 -344885494066259298)] from MemberRemoved 2021-01-31 02:12:26 679 DEBUG akka://my-app-prod@10.100.154.14:2552/system/clusterReceptionist/replicator - adding removed node [UniqueAddress(akka://my-app-prod@10.100.185.100:2552 -344885494066259298)] from MemberRemoved 2021-01-31 02:12:26 795 DEBUG akka://my-app-prod@10.100.153.226:2552/system/clusterReceptionist/replicator - Received gossip status from [akka://my-app-prod@10.100.154.14:2552]  chunk [1] of [1] containing [ReceptionistKey_2  ReceptionistKey_1  ReceptionistKey_0]. 2021-01-31 02:12:26 829 DEBUG akka://my-app-prod@10.100.209.44:2552/system/clusterReceptionist/replicator - adding removed node [UniqueAddress(akka://my-app-prod@10.100.185.100:2552 -344885494066259298)] from MemberRemoved 2021-01-31 02:12:26 852 DEBUG akka://my-app-prod@10.100.157.79:2552/system/clusterReceptionist/replicator - adding removed node [UniqueAddress(akka://my-app-prod@10.100.185.100:2552 -344885494066259298)] from MemberRemoved 2021-01-31 02:12:26 862 DEBUG akka://my-app-prod@10.100.157.79:2552/system/clusterReceptionist/replicator - Sending gossip to [akka://my-app-prod@10.100.156.157:2552]  containing [ReceptionistKey_2] 2021-01-31 02:12:26 862 DEBUG akka://my-app-prod@10.100.157.79:2552/system/clusterReceptionist/replicator - Created [1] Gossip messages from [1] data entries. 2021-01-31 02:12:26 862 DEBUG akka://my-app-prod@10.100.157.79:2552/system/clusterReceptionist/replicator - Received gossip status from [akka://my-app-prod@10.100.156.157:2552]  chunk [1] of [1] containing [ReceptionistKey_2  ReceptionistKey_0  ReceptionistKey_1]. 2021-01-31 02:12:26 863 DEBUG akka://my-app-prod@10.100.156.157:2552/system/clusterReceptionist/replicator - Received gossip from [akka://my-app-prod@10.100.157.79:2552]  containing [ReceptionistKey_2]. 2021-01-31 02:12:26 864 DEBUG akka://my-app-prod@10.100.156.157:2552/system/clusterReceptionist/replicator - Created [1] Gossip messages from [1] data entries. 2021-01-31 02:12:26 865 DEBUG akka://my-app-prod@10.100.157.79:2552/system/clusterReceptionist/replicator - Received gossip from [akka://my-app-prod@10.100.156.157:2552]  containing [ReceptionistKey_2]. 2021-01-31 02:12:26 899 DEBUG akka://my-app-prod@10.100.154.14:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552]  containing [ReceptionistKey_2 5-6]. 2021-01-31 02:12:26 899 DEBUG akka://my-app-prod@10.100.153.226:2552/system/clusterReceptionist/replicator - Skipping DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552] because that node has been removed 2021-01-31 02:12:26 899 DEBUG akka://my-app-prod@10.100.154.14:2552/system/clusterReceptionist/replicator - Skipping DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552] because that node has been removed 2021-01-31 02:12:26 899 DEBUG akka://my-app-prod@10.100.153.226:2552/system/clusterReceptionist/replicator - Received DeltaPropagation from [akka://my-app-prod@10.100.209.44:2552]  containing [ReceptionistKey_2 5-6]. 2021-01-31 02:12:27 018 DEBUG akka://my-app-prod@10.100.190.6:2552/system/clusterReceptionist/replicator - adding removed node [UniqueAddress(akka://my-app-prod@10.100.185.100:2552 -344885494066259298)] from MemberRemoved 2021-01-31 02:12:27 093 DEBUG akka://my-app-prod@10.100.156.157:2552/system/clusterReceptionist/replicator - adding removed node [UniqueAddress(akka://my-app-prod@10.100.185.100:2552 -344885494066259298)] from MemberRemoved 2021-01-31 02:12:27 105 INFO  akka://my-app-prod@10.100.156.157:2552/user/contextManager - Member removed [akka://my-app-prod@10.100.185.100:2552] 2021-01-31 02:12:27 142 DEBUG akka://my-app-prod/system/clusterReceptionist - ClusterReceptionist [akka://my-app-prod@10.100.156.157:2552] - Change from replicator: [Map()]  changes: [(localCtxLeaseManagers [])  (localCallRouterManagers [])]  tombstones [] 2021-01-31 02:12:27 142 INFO  akka://my-app-prod@10.100.156.157:2552/user/contextManager/singleton - Received an updated localCallRouterManagers list with 0 actor(s). ```",akka-distributed-data/src/main/scala/akka/cluster/ddata/Replicator.scala,patriknw
29993,RiccardoCalifano,2021-02-02T16:16:58Z,2023-09-08T21:20:32Z,leviramsey,Captain1653; patriknw; RiccardoCalifano,Akka SLF4J vulnerability found on dependency slf4j-api-1.7.30,"I faced a critical issue on one of dependencies of Akka SLF4J. It is related to slf4j-api-1.7.30. The code of vulnerability is CVE-2018-8088. In the mvn repository the last stable version of slf4j is 1.7.30. Anyway the next releases fix this vulnerability but they are in alpha or beta version. Have you planned any action to resolve this issue?",,Captain1653; patriknw; RiccardoCalifano
29951,AustinHash,2021-01-14T17:04:50Z,2022-05-30T10:06:23Z,johanandren,Captain1653; He-Pin; johanandren,FishingOutcomes.continue() cannot be used in Java code due to reserved word,"""continue"" is a reserved word in Java. As such any attempt to use FishingOutcomes.continue() from akka.actor.testkit.typed.javadsl.FishingOutcomes in Java code will cause compile failures.  Current workarounds are to use FishingOutcomes.continueAndIgnore() (prevents showing a list of processed messages in the fishForMessage failure output) or reflection to invoke the method (nasty but gives desirable behavior).",akka-actor-testkit-typed/src/main/mima-filters/2.6.19.backwards.excludes/rename-fishing-outcomes-continue-java.excludes; akka-actor-testkit-typed/src/main/scala/akka/actor/testkit/typed/javadsl/TestProbe.scala,Captain1653
29933,octonato,2021-01-07T15:43:25Z,2023-10-04T11:38:07Z,patriknw,patriknw; johanandren; octonato,EventSourcedBehavior exposed to stack overflow when lots of read-only commands are in the stash,"I got a report from a situation in which EventSourcedBehavior runs into a stack overflow when handling lots of read-only commands.   It turns out that after handling a read-only command (no persistent effect and only side-effects)  we call `tryUnstashOne` when the handling is complete.   However  `tryUnstashOne` will  after a few steps  call the `onCommand` method that in turn will call `tryUnstashOne`. And so forth...  This only happens on special situations. For that the stash must have lots of read-only commands. As soon we have one that does return a persistent effect the chain is broken since persistent acknowledgement comes from the plugin via the mailbox. In other words  `tryUnstashOne` is not called internally.   There was an attempt to fix it in #29437  but In don't think it really addressed the issue. It moved the call to `tryUnstashOne` from `applyEffects` to `onCommand`  but that doesn't change much the call stack.    Stack overflow fragment for illustration.  ```scala java.lang.StackOverflowError: null at scala.collection.immutable.HashMap$HashTrieMap.contains0(HashMap.scala:349) at scala.collection.immutable.HashMap$HashTrieMap.contains0(HashMap.scala:349) at scala.collection.immutable.HashMap.contains(HashMap.scala:59) at akka.event.SubchannelClassification.publish(EventBus.scala:169) at akka.event.SubchannelClassification.publish$(EventBus.scala:166) at akka.event.EventStream.publish(EventStream.scala:26) at akka.actor.DeadLetterActorRef.$bang(ActorRef.scala:696) at akka.remote.RemoteActorRefProvider$RemoteDeadLetterActorRef.$bang(RemoteActorRefProvider.scala:132) at akka.pattern.PromiseActorRef.$bang(AskSupport.scala:606) at akka.actor.typed.internal.adapter.ActorRefAdapter.tell(ActorRefAdapter.scala:27) at akka.actor.typed.ActorRef$ActorRefOps$.$bang$extension(ActorRef.scala:67) at akka.persistence.typed.internal.ReplyEffectImpl$$anonfun$$lessinit$greater$1.apply(SideEffect.scala:32) at akka.persistence.typed.internal.ReplyEffectImpl$$anonfun$$lessinit$greater$1.apply(SideEffect.scala:32) at akka.persistence.typed.internal.Running.applySideEffect(Running.scala:914) at akka.persistence.typed.internal.Running.applySideEffects(Running.scala:892) at akka.persistence.typed.internal.Running$HandlingCommands.applyEffects(Running.scala:597) at akka.persistence.typed.internal.Running$HandlingCommands.onCommand(Running.scala:271) at akka.persistence.typed.internal.Running$HandlingCommands.onMessage(Running.scala:250) at akka.persistence.typed.internal.Running$HandlingCommands.onMessage(Running.scala:239) at akka.actor.typed.scaladsl.AbstractBehavior.receive(AbstractBehavior.scala:84) at akka.actor.typed.Behavior$.interpret(Behavior.scala:274) at akka.actor.typed.Behavior$.interpretMessage(Behavior.scala:230) at akka.actor.typed.internal.StashBufferImpl.interpretUnstashedMessage(StashBufferImpl.scala:110) at akka.actor.typed.internal.StashBufferImpl.interpretOne$1(StashBufferImpl.scala:177) at akka.actor.typed.internal.StashBufferImpl.interpretUnstashedMessages(StashBufferImpl.scala:213) at akka.actor.typed.internal.StashBufferImpl.unstash(StashBufferImpl.scala:154) at akka.persistence.typed.internal.StashManagement.tryUnstashOne(StashManagement.scala:77) at akka.persistence.typed.internal.StashManagement.tryUnstashOne$(StashManagement.scala:67) at akka.persistence.typed.internal.Running.tryUnstashOne(Running.scala:227) at akka.persistence.typed.internal.Running$HandlingCommands.onCommand(Running.scala:272) at akka.persistence.typed.internal.Running$HandlingCommands.onMessage(Running.scala:250) at akka.persistence.typed.internal.Running$HandlingCommands.onMessage(Running.scala:239) at akka.actor.typed.scaladsl.AbstractBehavior.receive(AbstractBehavior.scala:84) at akka.actor.typed.Behavior$.interpret(Behavior.scala:274) at akka.actor.typed.Behavior$.interpretMessage(Behavior.scala:230) at akka.actor.typed.internal.StashBufferImpl.interpretUnstashedMessage(StashBufferImpl.scala:110) at akka.actor.typed.internal.StashBufferImpl.interpretOne$1(StashBufferImpl.scala:177) at akka.actor.typed.internal.StashBufferImpl.interpretUnstashedMessages(StashBufferImpl.scala:213) at akka.actor.typed.internal.StashBufferImpl.unstash(StashBufferImpl.scala:154) at akka.persistence.typed.internal.StashManagement.tryUnstashOne(StashManagement.scala:77) at akka.persistence.typed.internal.StashManagement.tryUnstashOne$(StashManagement.scala:67) at akka.persistence.typed.internal.Running.tryUnstashOne(Running.scala:227) ``` ",akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/scaladsl/EventSourcedStashOverflowSpec.scala; akka-persistence-typed-tests/src/test/scala/akka/persistence/typed/state/scaladsl/DurableStateStashOverflowSpec.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/EventSourcedBehaviorImpl.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/ReplayingEvents.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/ReplayingSnapshot.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/Running.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/internal/StashManagement.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/state/internal/DurableStateBehaviorImpl.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/state/internal/Recovering.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/state/internal/Running.scala; akka-persistence-typed/src/main/scala/akka/persistence/typed/state/internal/StashManagement.scala,patriknw
29922,maxcom,2020-12-30T07:49:19Z,2023-06-21T11:34:35Z,johanandren,jrudolph; istreeter; maxcom; patriknw; MaggieLeber; tolomaus; raboof; dimap-tr,Infinite loop in TLSActor,"We found that several threads in our application stuck in infinite loop in TLSActor. It happens without any active TCP connection (all connections was closed more than 10 minutes ago). Here is few thread dumps:  ``` ""application-akka.actor.default-dispatcher-11"" #53 prio=5 os_prio=0 cpu=85937645.88ms elapsed=97848.06s tid=0x00007fa74c002000 nid=0x1a1b runnable  [0x00007fa77849c000]    java.lang.Thread.State: RUNNABLE         at akka.util.ByteString.isEmpty(ByteString.scala:758)         at akka.util.ByteString$ByteString1C.$plus$plus(ByteString.scala:210)         at akka.stream.impl.io.TLSActor$ChoppingBlock.putBack(TLSActor.scala:125)         at akka.stream.impl.io.TLSActor.doUnwrap(TLSActor.scala:400)         at akka.stream.impl.io.TLSActor.doInbound(TLSActor.scala:297)         at akka.stream.impl.io.TLSActor.$anonfun$bidirectional$1(TLSActor.scala:232)         at akka.stream.impl.io.TLSActor$$Lambda$2467/0x0000000840ee7840.apply$mcV$sp(Unknown Source)         at akka.stream.impl.Pump.pump(Transfer.scala:203)         at akka.stream.impl.Pump.pump$(Transfer.scala:201)         at akka.stream.impl.io.TLSActor.pump(TLSActor.scala:52)         at akka.stream.impl.SimpleOutputs$$anonfun$downstreamRunning$1.applyOrElse(ActorProcessor.scala:244)         at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)         at akka.stream.impl.SubReceive.apply(Transfer.scala:19)         at akka.stream.impl.FanOut$OutputBunch$$anonfun$subreceive$1.applyOrElse(FanOut.scala:242)         at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)         at akka.stream.impl.SubReceive.apply(Transfer.scala:19)         at akka.stream.impl.SubReceive.apply(Transfer.scala:15)         at scala.PartialFunction.applyOrElse(PartialFunction.scala:189)         at scala.PartialFunction.applyOrElse$(PartialFunction.scala:188)         at akka.stream.impl.SubReceive.applyOrElse(Transfer.scala:15)         at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:244)         at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:245)         at akka.actor.Actor.aroundReceive(Actor.scala:537)         at akka.actor.Actor.aroundReceive$(Actor.scala:535)         at akka.stream.impl.io.TLSActor.aroundReceive(TLSActor.scala:52)         at akka.actor.ActorCell.receiveMessage(ActorCell.scala:577)         at akka.actor.ActorCell.invoke(ActorCell.scala:547)         at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)         at akka.dispatch.Mailbox.run(Mailbox.scala:231)         at akka.dispatch.Mailbox.exec(Mailbox.scala:243)         at java.util.concurrent.ForkJoinTask.doExec(java.base@11.0.8/ForkJoinTask.java:290)         at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(java.base@11.0.8/ForkJoinPool.java:1020)         at java.util.concurrent.ForkJoinPool.scan(java.base@11.0.8/ForkJoinPool.java:1656)         at java.util.concurrent.ForkJoinPool.runWorker(java.base@11.0.8/ForkJoinPool.java:1594)         at java.util.concurrent.ForkJoinWorkerThread.run(java.base@11.0.8/ForkJoinWorkerThread.java:183)  ```  and another one:  ``` ""application-akka.actor.default-dispatcher-11"" #53 prio=5 os_prio=0 cpu=92535619.77ms elapsed=104543.86s tid=0x00007fa74c002000 nid=0x1a1b runnable  [0x00007fa77849c000]    java.lang.Thread.State: RUNNABLE         at akka.stream.impl.io.TLSActor.doUnwrap(TLSActor.scala:394)         at akka.stream.impl.io.TLSActor.doInbound(TLSActor.scala:297)         at akka.stream.impl.io.TLSActor.$anonfun$bidirectional$1(TLSActor.scala:232)         at akka.stream.impl.io.TLSActor$$Lambda$2467/0x0000000840ee7840.apply$mcV$sp(Unknown Source)         at akka.stream.impl.Pump.pump(Transfer.scala:203)         at akka.stream.impl.Pump.pump$(Transfer.scala:201)         at akka.stream.impl.io.TLSActor.pump(TLSActor.scala:52)         at akka.stream.impl.SimpleOutputs$$anonfun$downstreamRunning$1.applyOrElse(ActorProcessor.scala:244)         at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)         at akka.stream.impl.SubReceive.apply(Transfer.scala:19)         at akka.stream.impl.FanOut$OutputBunch$$anonfun$subreceive$1.applyOrElse(FanOut.scala:242)         at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)         at akka.stream.impl.SubReceive.apply(Transfer.scala:19)         at akka.stream.impl.SubReceive.apply(Transfer.scala:15)         at scala.PartialFunction.applyOrElse(PartialFunction.scala:189)         at scala.PartialFunction.applyOrElse$(PartialFunction.scala:188)         at akka.stream.impl.SubReceive.applyOrElse(Transfer.scala:15)         at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:244)         at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:245)         at akka.actor.Actor.aroundReceive(Actor.scala:537)         at akka.actor.Actor.aroundReceive$(Actor.scala:535)         at akka.stream.impl.io.TLSActor.aroundReceive(TLSActor.scala:52)         at akka.actor.ActorCell.receiveMessage(ActorCell.scala:577)         at akka.actor.ActorCell.invoke(ActorCell.scala:547)         at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)         at akka.dispatch.Mailbox.run(Mailbox.scala:231)         at akka.dispatch.Mailbox.exec(Mailbox.scala:243)         at java.util.concurrent.ForkJoinTask.doExec(java.base@11.0.8/ForkJoinTask.java:290)         at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(java.base@11.0.8/ForkJoinPool.java:1020)         at java.util.concurrent.ForkJoinPool.scan(java.base@11.0.8/ForkJoinPool.java:1656)         at java.util.concurrent.ForkJoinPool.runWorker(java.base@11.0.8/ForkJoinPool.java:1594)         at java.util.concurrent.ForkJoinWorkerThread.run(java.base@11.0.8/ForkJoinWorkerThread.java:183) ```  I do not know the way to reproduce this problem. It happens sometimes after we run load test cycle on our application.  Initially we saw this problem on Akka 2.6.8 with Akka HTTP 10.1.12 running on JDK 11.0.6 on Centos 7. We updated our application and now we see the same problem on Akka 2.6.10 and Akka HTTP 10.2.2  running on JDK 11.0.8 on CentOS 7.9.  Application is REST endpoint with client TLS authentication.",akka-stream/src/main/scala/akka/stream/impl/io/TLSActor.scala; akka-stream/src/main/scala/akka/stream/impl/io/TLSActor.scala,jrudolph
29892,makesh91,2020-12-14T02:33:55Z,2023-09-12T11:16:32Z,patriknw,Captain1653; patriknw; johanandren,No alternative for RemotingLifecycleEvent in Artery,"<!-- Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka HTTP: https://github.com/akka/akka-http/issues  - Alpakka:   https://github.com/akka/alpakka/issues  - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your issue precisely  and if possible provide a reproducer snippet (this helps resolve issues much quicker).  Thanks  happy hakking! -->  We use akka Classic Remoting and have subscribed to the RemotingLifecycleEvent. Now we are in process of migrating to Artery  but we see only the below information for that class ""Classic remoting is deprecated  use Artery""  We can't see any alternate events to subscribe in Artery  .i.e. AssociationErrorEvent  Please assist.  Regards  Makesh          ",,Captain1653; patriknw; johanandren
29865,He-Pin,2020-12-07T06:29:20Z,2023-08-22T06:17:22Z,patriknw,He-Pin; patriknw; johanandren,Wire Protocol Compatibility section is missing in `Migration Guide 2.5.x to 2.6.x`,"It's very clear that in https://doc.akka.io/docs/akka/2.5/project/migration-guide-2.4.x-2.5.x.html#wire-protocol-compatibility but this section in https://doc.akka.io/docs/akka/current/project/migration-guide-2.5.x-2.6.x.html#remoting  ",,He-Pin; patriknw; johanandren
29850,ennru,2020-12-01T11:08:46Z,2022-09-15T14:00:12Z,patriknw,,Stream TestKit: Deprecate old API,For Akka 2.7 the Stream TestKit APIs which got new variants in https://github.com/akka/akka/pull/29831 should be deprecated.,akka-docs/src/test/java/jdocs/actor/ActorDocTest.java; akka-docs/src/test/java/jdocs/stream/operators/SourceOrFlow.java; akka-docs/src/test/scala/docs/stream/RateTransformationDocSpec.scala; akka-docs/src/test/scala/docs/stream/StreamTestKitDocSpec.scala; akka-persistence-query/src/test/scala/akka/persistence/query/journal/leveldb/AllPersistenceIdsSpec.scala; akka-persistence-query/src/test/scala/akka/persistence/query/journal/leveldb/EventsByPersistenceIdSpec.scala; akka-persistence-query/src/test/scala/akka/persistence/query/journal/leveldb/EventsByTagSpec.scala; akka-persistence-testkit/src/test/scala/akka/persistence/testkit/query/EventsByPersistenceIdSpec.scala; akka-remote/src/test/scala/akka/remote/artery/DuplicateFlushSpec.scala; akka-remote/src/test/scala/akka/remote/artery/DuplicateHandshakeSpec.scala; akka-remote/src/test/scala/akka/remote/artery/InboundControlJunctionSpec.scala; akka-remote/src/test/scala/akka/remote/artery/InboundHandshakeSpec.scala; akka-remote/src/test/scala/akka/remote/artery/OutboundControlJunctionSpec.scala; akka-remote/src/test/scala/akka/remote/artery/OutboundHandshakeSpec.scala; akka-remote/src/test/scala/akka/remote/artery/SendQueueSpec.scala; akka-remote/src/test/scala/akka/remote/artery/SystemMessageAckerSpec.scala; akka-remote/src/test/scala/akka/remote/artery/SystemMessageDeliverySpec.scala; akka-stream-testkit/src/main/scala/akka/stream/testkit/javadsl/TestSink.scala; akka-stream-testkit/src/main/scala/akka/stream/testkit/javadsl/TestSource.scala; akka-stream-testkit/src/main/scala/akka/stream/testkit/scaladsl/TestSink.scala; akka-stream-testkit/src/main/scala/akka/stream/testkit/scaladsl/TestSource.scala; akka-stream-testkit/src/test/scala/akka/stream/testkit/StreamTestKitSpec.scala; akka-stream-tests/src/test/java/akka/stream/javadsl/FlowTest.java; akka-stream-tests/src/test/scala/akka/stream/impl/GraphStageLogicSpec.scala; akka-stream-tests/src/test/scala/akka/stream/io/FileSourceSpec.scala; akka-stream-tests/src/test/scala/akka/stream/io/InputStreamSinkSpec.scala; akka-stream-tests/src/test/scala/akka/stream/io/InputStreamSourceSpec.scala; akka-stream-tests/src/test/scala/akka/stream/io/OutputStreamSourceSpec.scala; akka-stream-tests/src/test/scala/akka/stream/scaladsl/ActorRefBackpressureSinkSpec.scala; akka-stream-tests/src/test/scala/akka/stream/scaladsl/ActorRefBackpressureSourceSpec.scala,patriknw
29795,patriknw,2020-11-05T08:06:01Z,2023-09-18T10:15:22Z,johanandren,nitikagarw; franciscolopezsancho,Deadletter logging is confusing for context.ask,"If the actor performing `context.ask` is stopped the reply message will result in logging  ``` akka.actor.DeadLetterActorRef - Message [ask.Worker$Done] to Actor[akka://example-ask/deadLetters] was not delivered. [1] dead letters encountered. If this is not an expected behavior then Actor[akka://example-ask/deadLetters] may have terminated unexpectedly. ```  The confusing part is that the destination is written as `/deadLetters` instead of the temporary ref and then it may be interpreted as if the message wasn't even delivered to deadLetters.",akka-actor-typed-tests/src/test/scala/akka/actor/typed/AskSpec.scala; akka-actor/src/main/scala/akka/pattern/AskSupport.scala,Roiocam
29791,chbatey,2020-11-03T07:56:23Z,2023-09-12T14:48:09Z,ennru,ennru; raboof; ignasi35; johanandren,Build tool assistence for keeping Akka version in sync,We currently have checks at runtime. This ticket is for adding build tool support to override all Akka dependencies to the same version ,,ennru; raboof; ignasi35; johanandren
29685,octonato,2020-10-01T07:36:30Z,2024-02-20T08:03:03Z,johanandren,leviramsey; ptrdom; fluxlife; patriknw; jturnergresham; johanandren; tomb50,Add support for event deletion on snapshot predicate,"Currently  it's only possible to delete events when using a snapshot strategy based on a counter and retention criteria. The predicated variant doesn't offer this option.   Being able to save a snapshot and deleted previous events with a predicate is particularly useful. One can implement tombstones:  > when that event happens  transition to that state  save a snapshot and delete previous events  This is partially triggered by this other issue: #29684  but I believe that it has value in itself. Even if we realise that it can't be used in the context of #29684.",,leviramsey; ptrdom; fluxlife; patriknw; jturnergresham; johanandren; tomb50
29557,jrudolph,2020-09-07T08:43:21Z,2022-09-16T16:11:01Z,johanandren,patriknw; johanandren,Async callback tracking in GraphStage can lead to OOM if callbacks cannot be processed fast enough,"Most prominently  this is an issue with `Source.queue` as seen here: #25798.  Currently  GraphStage keeps an `AtomicReference[List[Promise[Done]]]` to track in-flight async callbacks. The behavior is like this:   * when an async callback is invoked the promise is added to the list with CAS (ok-ish)  * when the async callback has executed  the list is not immediately cleaned up but only after 256 callbacks are executed after which the list is scanned for already completed promises and CAS-ed to the cleanup list  This is problematic for various reasons:  * the list is not bounded  so regardless of the exact mechanism  elements might be appended faster than they can be removed later on  * due to the mechanism of the second step above  it's likely that the CAS fails because scanning the list for completed elements is much slower than adding something  so that stage is basically stalled trying to clean up that list  while the producer is able to add more and more elements  amplifying the problem of cleanup.  I think we should do multiple things:   * The number of ongoing tracked async callbacks needs to be limited  if you try to run > 100s or even 1000s of concurrent async callbacks  a stage is implemented the wrong way. Async callbacks are no super high-throughput messaging channel. Use other explicit side-channels for that.  * The tracking of ongoing async callbacks can be done more efficiently with less potential for contention.  * Shedding load like dropping elements with `Source.queue` must be done immediately and not only after the async callback is being processed. Regardless of whether we have a tracking mechanism here or not  users might want to track the result of the offer and if those offers are not rejected immediately they might still accumulate in memory.  * `Source.queue` should be reimplemented in a more efficient way that removes pressure from the async callback mechanism (#29558).",,patriknw; johanandren
29414,makkarpov,2020-07-21T19:46:23Z,2023-09-08T06:32:40Z,patriknw,Captain1653; patriknw; makkarpov; johanandren,Misleading API differences between Scheduler.scheduleOnce and .scheduleXXX (repeated versions),"In `Scheduler.scala` method `scheduleOnce` has following signature (omitting the execution context):  ``` final def scheduleOnce(delay: FiniteDuration)(f: => Unit): Cancellable ```  so you should call it via   ``` scheduler.scheduleOnce(...) {   ... code ... } ```  However  repeated `schedule...` methods (e.g. `scheduleAtFixedRate`) have the following signature:  ``` def scheduleWithFixedDelay(initialDelay: FiniteDuration  delay: FiniteDuration)(runnable: Runnable): Cancellable ```  so you should call it via  ``` scheduler.scheduleWithFixedDelay(...  ...) { () =>   ... } ```  The problem ==========  The problem arises when you acidentally call `scheduleOnce` with `() => ...` syntax. It will give no warnings  no errors  nothing at all  but task will be ignored silently (technically  lambda construction will be invoked). I spent a hour figuring out what is wrong and why my tasks don't get invoked.  I don't know how to fix it without breaking backward compatibility. I see the possible ways:  1. Deprecate repeated `scheduleXXX` methods once again and introduce new versions with `f: => Unit` syntax (I think that this syntax is cleaner than `Runnable`s) 2. Deprecate `scheduleOnce` method and introduce new version with `Runnable` syntax. 3. (very dirty hack) Make `scheduleOnce` accept `f: => Any` instead of `f: => Unit`. This should not break neither source nor binary compatibility. Then  save the return value from `f` and check if it is of type `scala.Function0`. If it is  then invoke that function.",,Captain1653; patriknw; makkarpov; johanandren
29330,mgutmanis,2020-06-30T17:44:48Z,2023-09-08T06:31:00Z,patriknw,jrudolph; mgutmanis; nparekh127; Captain1653; alewando; patriknw; johanandren; jypma,SelectionHandler unhandled ChannelReadable message,"Once Akka version was upgraded from 2.5.30 to 2.6.4 following messages are constantly being logged.  `INFO a.a.LocalActorRef Message [akka.io.SelectionHandler$ChannelReadable$] to Actor[akka://app/system/IO-TCP/selectors/$b/209816#765382547] was unhandled. [9] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.`  Messages appears to have no effect on functionality  but logs are flooded with messages.",akka-actor/src/main/scala/akka/io/TcpConnection.scala,jrudolph
29277,kpritam,2020-06-19T13:33:23Z,2023-09-08T06:29:06Z,patriknw,Captain1653; patriknw; johanandren,BehaviorTestKit fails to process concurrent messages since akka 2.6.6,"<!-- Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka HTTP: https://github.com/akka/akka-http/issues  - Alpakka:   https://github.com/akka/alpakka/issues  - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your issue precisely  and if possible provide a reproducer snippet (this helps resolve issues much quicker).  Thanks  happy hakking! -->  Following test used to work just fine prior to akka 2.6.6 but after migrating started failing.  ```scala test(""BehaviorTestKit should process two messages concurrently"") {     import typedSystem.executionContext      case class Echo(msg: String  replyTo: ActorRef[String])      val echoBeh = Behaviors.receiveMessage[Echo] { msg =>       println(s""Rec: $msg"")       msg.replyTo ! msg.msg       Behaviors.same     }      val testkit = BehaviorTestKit(echoBeh)     val replyTo = TestProbe[String]      Future(testkit.run(Echo(s""Hello 1""  replyTo.ref)))     Future(testkit.run(Echo(s""Hello 2""  replyTo.ref)))      replyTo.expectMessageType[String]     replyTo.expectMessageType[String]   } ``` ",,Captain1653; patriknw; johanandren
29261,chbatey,2020-06-18T08:46:05Z,2024-08-30T07:14:10Z,patriknw,,Migration from event sourced behavior to replicated,Either a method of reading events written by event sourced behavior or docs for how to stream events from an existing event sourced behaviour to a active active one,,patriknw
29143,patriknw,2020-05-28T07:36:00Z,2022-04-11T07:12:33Z,johanandren,jxnu-liguobin; johanandren,Expose SnapshotTestKit in EventSourcedBehaviorTestKit,For example to be able to start from a snapshot.,,jxnu-liguobin; johanandren
29134,eyalfa,2020-05-27T05:31:41Z,2023-03-07T11:21:06Z,johanandren,patriknw; johanandren,Flow.fromMaterializer + Flow.addAttributes may result with the added attributes ignored,"the following test case uses `Flow.fromMaterializer` in order to create a flow (prefixAndTail) with an overridden subscription timeout mode  it fails with a stack trace that demonstrates that the default mode was used (cancel). what's even more surprising  if uncommenting the `map(identity)` operation inside the `Flow.fromMaterializer` block everything works as expected.  I personally suspect a bug in the linear traversal builder  but I can't really say I fully understand the thing.  the test code ``` ""respect added attributes"" in {       //import scala.concurrent.duration._       val fl = Flow.fromMaterializer{ (_  atts) =>         Flow[Int]           .prefixAndTail(0)           .addAttributes(             Attributes(               atts                 .mandatoryAttribute[StreamSubscriptionTimeout]                 .copy(mode = StreamSubscriptionTimeoutTerminationMode.warn)             )           )           //uncomment this to magically 'fix' the issue           //.map(identity)       }       .mapMaterializedValue(_ => NotUsed)       val fLst = Source(1 to 10)         .via(fl)         .map{p =>           Thread.sleep(6000)           p         }         .flatMapConcat(_._2)         .runWith(Sink.seq)        Thread.sleep(7000)       fLst.futureValue should equal(1 to 10)     } ```  the thrown exception: ``` The future returned an exception of type: akka.stream.impl.SubscriptionTimeoutException  with message: Substream Source(TailSource) has not been materialized in 5000 milliseconds. ScalaTestFailureLocation: akka.stream.scaladsl.FromMaterializerSpec at (FromMaterializationSpec.scala:257) org.scalatest.exceptions.TestFailedException: The future returned an exception of type: akka.stream.impl.SubscriptionTimeoutException  with message: Substream Source(TailSource) has not been materialized in 5000 milliseconds. 	at org.scalatest.concurrent.Futures$FutureConcept.tryTryAgain$1(Futures.scala:531) 	at org.scalatest.concurrent.Futures$FutureConcept.futureValueImpl(Futures.scala:550) 	at org.scalatest.concurrent.Futures$FutureConcept.futureValueImpl$(Futures.scala:479) 	at org.scalatest.concurrent.ScalaFutures$$anon$1.futureValueImpl(ScalaFutures.scala:275) 	at org.scalatest.concurrent.Futures$FutureConcept.futureValue(Futures.scala:476) 	at org.scalatest.concurrent.Futures$FutureConcept.futureValue$(Futures.scala:475) 	at org.scalatest.concurrent.ScalaFutures$$anon$1.futureValue(ScalaFutures.scala:275) 	at akka.stream.scaladsl.FromMaterializerSpec.$anonfun$new$58(FromMaterializationSpec.scala:257) 	at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85) 	at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83) 	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104) 	at org.scalatest.Transformer.apply(Transformer.scala:22) 	at org.scalatest.Transformer.apply(Transformer.scala:20) 	at org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076) 	at org.scalatest.TestSuite.withFixture(TestSuite.scala:196) 	at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195) 	at akka.stream.testkit.StreamSpec.withFixture(StreamSpec.scala:33) 	at org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074) 	at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086) 	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306) 	at org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086) 	at org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068) 	at akka.testkit.AkkaSpec.runTest(AkkaSpec.scala:54) 	at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145) 	at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413) 	at scala.collection.immutable.List.foreach(List.scala:392) 	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401) 	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390) 	at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427) 	at scala.collection.immutable.List.foreach(List.scala:392) 	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401) 	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396) 	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475) 	at org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145) 	at org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144) 	at akka.testkit.AkkaSpec.runTests(AkkaSpec.scala:54) 	at org.scalatest.Suite.run(Suite.scala:1112) 	at org.scalatest.Suite.run$(Suite.scala:1094) 	at akka.testkit.AkkaSpec.org$scalatest$wordspec$AnyWordSpecLike$$super$run(AkkaSpec.scala:54) 	at org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190) 	at org.scalatest.SuperEngine.runImpl(Engine.scala:535) 	at org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190) 	at org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188) 	at akka.testkit.AkkaSpec.org$scalatest$BeforeAndAfterAll$$super$run(AkkaSpec.scala:54) 	at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213) 	at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210) 	at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208) 	at akka.testkit.AkkaSpec.run(AkkaSpec.scala:54) 	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:45) 	at org.scalatest.tools.Runner$.$anonfun$doRunRunRunDaDoRunRun$13(Runner.scala:1320) 	at org.scalatest.tools.Runner$.$anonfun$doRunRunRunDaDoRunRun$13$adapted(Runner.scala:1314) 	at scala.collection.immutable.List.foreach(List.scala:392) 	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1314) 	at org.scalatest.tools.Runner$.$anonfun$runOptionallyWithPassFailReporter$24(Runner.scala:993) 	at org.scalatest.tools.Runner$.$anonfun$runOptionallyWithPassFailReporter$24$adapted(Runner.scala:971) 	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1480) 	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:971) 	at org.scalatest.tools.Runner$.run(Runner.scala:798) 	at org.scalatest.tools.Runner.run(Runner.scala) 	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:133) 	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:27) Caused by: akka.stream.impl.SubscriptionTimeoutException: Substream Source(TailSource) has not been materialized in 5000 milliseconds 	at akka.stream.impl.fusing.SubSource.timeout(StreamOfStreams.scala:797) 	at akka.stream.stage.GraphStageLogic$SubSourceOutlet.timeout(GraphStage.scala:1481) 	at akka.stream.impl.fusing.PrefixAndTail$PrefixAndTailLogic.onTimer(StreamOfStreams.scala:173) 	at akka.stream.stage.TimerGraphStageLogic.onInternalTimer(GraphStage.scala:1602) 	at akka.stream.stage.TimerGraphStageLogic.$anonfun$getTimerAsyncCallback$1(GraphStage.scala:1591) 	at akka.stream.stage.TimerGraphStageLogic.$anonfun$getTimerAsyncCallback$1$adapted(GraphStage.scala:1591) 	at akka.stream.impl.fusing.GraphInterpreter.runAsyncInput(GraphInterpreter.scala:466) 	at akka.stream.impl.fusing.GraphInterpreterShell$AsyncInput.execute(ActorGraphInterpreter.scala:498) 	at akka.stream.impl.fusing.GraphInterpreterShell.processEvent(ActorGraphInterpreter.scala:600) 	at akka.stream.impl.fusing.ActorGraphInterpreter.akka$stream$impl$fusing$ActorGraphInterpreter$$processEvent(ActorGraphInterpreter.scala:769) 	at akka.stream.impl.fusing.ActorGraphInterpreter$$anonfun$receive$1.applyOrElse(ActorGraphInterpreter.scala:784) 	at akka.actor.Actor.aroundReceive(Actor.scala:535) 	at akka.actor.Actor.aroundReceive$(Actor.scala:533) 	at akka.stream.impl.fusing.ActorGraphInterpreter.aroundReceive(ActorGraphInterpreter.scala:691) 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:575) 	at akka.actor.ActorCell.invoke(ActorCell.scala:545) 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) 	at akka.dispatch.Mailbox.run(Mailbox.scala:231) 	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) 	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290) 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020) 	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656) 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594) 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:177) ```",,patriknw; johanandren
29109,patriknw,2020-05-25T07:19:14Z,2023-10-10T07:15:22Z,johanandren,muskan3006; johanandren,Add reference docs for the EventStream,"I don't think we mention it in the reference docs.  It's accessible from `ActorSystem.eventStream` and API docs: https://doc.akka.io/api/akka/2.6.5/akka/actor/typed/eventstream/EventStream$.html",akka-actor-typed-tests/src/test/java/akka/actor/typed/eventstream/LoggingDocTest.java; akka-actor-typed-tests/src/test/scala/akka/actor/typed/eventstream/LoggingDocSpec.scala; akka-docs/src/main/paradox/event-bus.md; akka-docs/src/main/paradox/general/message-delivery-reliability.md; akka-docs/src/main/paradox/index-utilities.md; akka-docs/src/main/paradox/typed/event-stream.md; akka-docs/src/main/paradox/typed/logging.md; akka-docs/src/test/java/jdocs/event/LoggingDocTest.java,Roiocam
29078,johanandren,2020-05-15T08:33:08Z,2023-10-20T12:45:42Z,patriknw,Captain1653; patriknw; raboof; chbatey,Investigate if we can support JFR on Openjdk8,"JFR was backported to OpenJDK 8  not sure if it is the full thing or a subset  we should check if we can allow the JFR metrics collection to work with that  it is currently only loaded on JDK 11.  Backport was added in openjdk8u262 https://bugs.java.com/bugdatabase/view_bug.do?bug_id=8239140",,Captain1653; patriknw; raboof; chbatey
29055,He-Pin,2020-05-11T11:22:20Z,2022-04-29T23:20:33Z,He-Pin,patriknw,Add Source.fromOption,"Add Source.fromOptinal/Source.fromOption would be helpful. Async one can be implemented with `Source.future(futureOption).toOption` ",,patriknw
28922,jrudolph,2020-04-15T09:10:21Z,2023-08-21T07:19:39Z,johanandren,Captain1653; patriknw; adriaanm,Cleanup jenkins jobs,"Since we will have to move our jenkins instances soon  we should clean up existing jobs.  For akka-http jobs I either removed the task if it was clearly not needed any more. For others that we might still want to look into for reference  I used a `(legacy)` prefix in the name to note that they don't need to be migrated right now. When the main migration is done we should look at the `(legacy)` tasks again and see if anything needs to be salvaged.",,Captain1653; patriknw; adriaanm
28824,He-Pin,2020-03-27T06:50:30Z,2023-09-06T10:34:22Z,johanandren,Captain1653; He-Pin; patriknw; octonato,Add retry on exception and retry on result support.,"With the current retry implementation  it will retry on any exception.  https://github.com/akka/akka/blob/37d87811b5c0622f55e0c07dd0c2e09665cfbff9/akka-actor/src/main/scala/akka/pattern/RetrySupport.scala#L166  A better way is to add support with RetryDirective  and then can implement retry on exceptions or retry on results from it  as `resilience4j-retry` does. ```java RetryConfig config = RetryConfig.custom()   .maxAttempts(2)   .waitDuration(Duration.ofMillis(1000))   .retryOnResult(response -> response.getStatus() == 500)   .retryOnException(e -> e instanceof WebServiceException)   .retryExceptions(IOException.class  TimeoutException.class)   .ignoreExceptions(BunsinessException.class  OtherBunsinessException.class)   .build();  ```",,Captain1653; He-Pin; patriknw; octonato
28756,chbatey,2020-03-18T08:20:48Z,2023-09-07T06:05:18Z,patriknw,Captain1653; patriknw; johanandren,Logger name not always set correctly,"For the following logger in the distributed workers sample we end up with `akka.actor.ActorCell`:  ``` object FrontEnd {    sealed trait Command   case object Tick extends Command   case object Failed extends Command   case object Retry extends Command   case object WorkAccepted extends Command    private def nextWorkId(): String = UUID.randomUUID().toString    def apply(workManager: ActorRef[SubmitWork]): Behavior[Command] = Behaviors.setup { ctx =>     Behaviors.setup { ctx =>       Behaviors.withTimers { timers =>         new FrontEnd(workManager  ctx  timers).idle(0)       }     }   }  }  class FrontEnd private (     workManager: ActorRef[SubmitWork]      ctx: ActorContext[FrontEnd.Command]      timers: TimerScheduler[FrontEnd.Command]) {   import FrontEnd._    def idle(workCounter: Int): Behavior[Command] = {     val nextTick = ThreadLocalRandom.current.nextInt(3  10).seconds     timers.startSingleTimer(""tick""  Tick  nextTick)     Behaviors.receiveMessage {       case Tick =>         busy(workCounter + 1  Work(nextWorkId()  workCounter))       case _ =>         Behaviors.unhandled     }   }    def busy(workCounter: Int  workInProgress: Work): Behavior[Command] = {     def sendWork(work: Work): Unit = {       implicit val timeout: Timeout = Timeout(5.seconds)       ctx.ask[SubmitWork  WorkManager.Ack](workManager  replyTo => SubmitWork(work  replyTo)) {         case Success(_) => WorkAccepted         case Failure(_) => Failed       }     }      sendWork(workInProgress)      Behaviors.receiveMessage {       case Failed =>         ctx.log.info(""Work {} not accepted  retry after a while""  workInProgress.workId)         timers.startSingleTimer(""retry""  Retry  3.seconds)         Behaviors.same       case WorkAccepted =>         ctx.log.info(""Got ack for workId {}""  workInProgress.workId)         idle(workCounter)       case Retry =>         ctx.log.info(""Retrying work {}""  workInProgress.workId)         sendWork(workInProgress)         Behaviors.same       case Tick =>         Behaviors.unhandled     }   }  } ``` ",,Captain1653; patriknw; johanandren
28641,ignasi35,2020-02-24T16:22:01Z,2022-06-10T06:53:46Z,johanandren,Captain1653; raboof; ignasi35; johanandren,Merge language-specific operator docs,"Some operators only make sense in Java or Scala as each implementation has a variant that's specific to the programming language. Take for example scaladsl's `apply` vs javadsl's `from()`.  Other examples of these language-specific operators are:   - [ ] `Source.future` vs `Source.completionStage`  - [ ] `Source.futureSource` vs `Source.completionStageSource`  - [ ] (others?)  We could merge the language-specific pages into a single one similar to what's been done in the [docs for `apply` and `from](https://doc.akka.io/docs/akka/current/stream/operators/Source/from.html).  Refs #25468",,Captain1653; raboof; ignasi35; johanandren
28583,phiSgr,2020-02-09T06:32:52Z,2023-03-11T20:49:37Z,phiSgr,phiSgr; patriknw; johanandren,Broadcast does not parallelize using the snippet from documentation,"https://doc.akka.io/docs/akka/current/stream/operators/Broadcast.html The documentation added in https://github.com/akka/akka/pull/28091 suggested a way to parallelize processing in the `broadcast-async` snippet.  The method suggested is to add `Flow[A].async` between the `Broadcast` operator and the sinks.  I tried that but the processing is still sequential. Reproducer and write-up in this [repo](https://github.com/phiSgr/akka-streams-broadcast).",,phiSgr; patriknw; johanandren
28436,otto-dev,2020-01-02T09:58:36Z,2023-09-15T14:00:10Z,johanandren,Captain1653; patriknw; mghildiy,Docs: Relationship between ActorContext and Behavior in Typed,"I think the following explanation (see link) by @johanandren regarding the relationship between `Behaviors` and `ActorContexts` would make a fine addition to the docs - if nowhere else  at least in the `Learning Akka Typed from Classic` section.  https://discuss.lightbend.com/t/in-akka-typed-what-constitutes-an-actor/5684/2",akka-docs/src/main/paradox/typed/from-classic.md,Captain1653
28327,artur-jablonski,2019-12-06T20:59:13Z,2023-03-27T08:12:13Z,johanandren,He-Pin; patriknw; artur-jablonski; jypma,BroadcastHub doesn't wait for first materialization of Source,"This is what _Akka Streams_ documentation states about `Source` materialized from `BroadcastHub` `Sink` ([link][1]):  > The resulting Source can be materialized any number of times  each materialization effectively attaching a new subscriber. If there are no subscribers attached to this hub then it will not drop any elements but instead backpressure the upstream producer until subscribers arrive.  Therefore I would expect that this:  ```java  Source<String  NotUsed> bcast =             Source.from(Arrays.asList(""1""  ""2""  ""3""))                   .log(""before broadcasting"")                   .runWith(BroadcastHub.of(String.class)  materializer);   bcast.log(""after broadcasting"")       .runWith(Sink.ignore()  materializer); ```  would effectively backpressure the upstream of the `BroadcastHub` `Sink` until the `bcast` `Source` is materialized at least once  but it is not the case. If I run the above  the output is:  ``` [before broadcasting] Element: 1 [before broadcasting] Element: 2 [before broadcasting] Element: 3 [before broadcasting] Upstream finished. [after broadcasting] Upstream finished. ```  which is contrary to the documentation  as the elements are effectively dropped and never broadcasted. If I limit the buffer of the `Broadcast` `Sink` like this:  ```         Source<String  NotUsed> bcast =             Source.from(Arrays.asList(""1""  ""2""  ""3""))                   .log(""before broadcasting"")                   .runWith(BroadcastHub.of(String.class  2)  materializer); //buffer smaller than number of events  ```  then all the elements are broadcasted:  ``` [before broadcasting] Element: 1 [before broadcasting] Element: 2 [after broadcasting] Element: 1 [after broadcasting] Element: 2 [before broadcasting] Element: 3 [before broadcasting] Upstream finished. [after broadcasting] Element: 3 [after broadcasting] Upstream finished. ```  The way I see it it's either a bug or the documentation is misleading?  originally posted at SO:   https://stackoverflow.com/questions/58974630/broadcasthub-doesnt-wait-for-first-materialization-of-source    [1]: https://doc.akka.io/docs/akka/current/stream/stream-dynamic.html",,He-Pin; patriknw; artur-jablonski; jypma
28304,raboof,2019-12-04T14:43:38Z,2022-11-18T13:46:58Z,patriknw,briantopping; cschneider; lefou; atooni; patriknw; barthorre; raboof,Remove OSGi support,"Our OSGi support makes the build quite a bit more complex and has caused us problems with releases in the past. While there's a couple of projects known to use OSGi  none of the core team has OSGi experience  so we would like to move it out of the main project for 2.6.2. This would include both the artifact metadata (sbt-osgi bundling) and the akka-osgi subproject.  @lefou @atooni @briantopping @oheger @Falmarri you have all contributed to OSGi support in some form or other in the past  would any of you be interested in exploring how to maintain OSGi support for Akka outside of the main Akka project?",,briantopping; cschneider; lefou; atooni; patriknw; barthorre; raboof
28040,giftig,2019-10-18T15:50:52Z,2023-09-05T08:30:02Z,johanandren,johanandren,Mislabel in a flow image in the substreams doc page,"The image `akka-docs/src/main/paradox/images/stream-substream-flatMapMerge.png`:  ![](https://doc.akka.io/docs/akka/images/stream-substream-flatMapMerge.png)  ...labels the stage `flatFlattenMerge` instead of `flatMapMerge`.  I'm not sure how you're generating / editing those images or I would have raised a PR to fix it myself. I searched the project for that phrase but didn't find it so it doesn't look like you have an editable format of those images committed; if you're simply editing the PNGs directly to make changes to them I'm happy to fix the label and raise a PR  though.",akka-docs/src/main/paradox/images/stream-substream-flatMapMerge.png,Captain1653
28024,dcullender-cb,2019-10-17T11:34:57Z,2023-09-05T07:04:36Z,johanandren,Captain1653; johanandren,java.util.NoSuchElementException: head of empty stream,"Hi Akka Team   Thanks for all the great work you do.  We are using akka 2.5.25 and once in a while we see the below exception message. It does not seem to cause any issues but thought I would raise it in any case.  We are using akka grpc with a streaming server API which may be causing this.  Thanks Daniel  ``` java.util.NoSuchElementException: head of empty stream         at akka.stream.scaladsl.Sink$.$anonfun$head$3(Sink.scala:180)         at scala.Option.getOrElse(Option.scala:138)         at akka.stream.scaladsl.Sink$.$anonfun$head$2(Sink.scala:180)         at scala.util.Success.$anonfun$map$1(Try.scala:255)         at scala.util.Success.map(Try.scala:213)         at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)         at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)         at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)         at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)         at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)         at akka.dispatch.BatchingExecutor$Batch.run(BatchingExecutor.scala:73)         at akka.dispatch.ExecutionContexts$sameThreadExecutionContext$.unbatchedExecute(Future.scala:85)         at akka.dispatch.BatchingExecutor.execute(BatchingExecutor.scala:122)         at akka.dispatch.BatchingExecutor.execute$(BatchingExecutor.scala:116)         at akka.dispatch.ExecutionContexts$sameThreadExecutionContext$.execute(Future.scala:84)         at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)         at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)         at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)         at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)         at scala.concurrent.Promise.trySuccess(Promise.scala:94)         at scala.concurrent.Promise.trySuccess$(Promise.scala:94)         at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)         at akka.stream.impl.HeadOptionStage$$anon$2.onUpstreamFinish(Sinks.scala:273)         at akka.stream.impl.fusing.GraphInterpreter.processEvent(GraphInterpreter.scala:506)         at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:376)         at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:606)         at akka.stream.impl.fusing.GraphInterpreterShell.init(ActorGraphInterpreter.scala:576)         at akka.stream.impl.fusing.ActorGraphInterpreter.tryInit(ActorGraphInterpreter.scala:682)         at akka.stream.impl.fusing.ActorGraphInterpreter.preStart(ActorGraphInterpreter.scala:731)         at akka.actor.Actor.aroundPreStart(Actor.scala:550)         at akka.actor.Actor.aroundPreStart$(Actor.scala:550)         at akka.stream.impl.fusing.ActorGraphInterpreter.aroundPreStart(ActorGraphInterpreter.scala:671)         at akka.actor.ActorCell.create(ActorCell.scala:676)         at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:547)         at akka.actor.ActorCell.systemInvoke(ActorCell.scala:569)         at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:293)         at akka.dispatch.Mailbox.run(Mailbox.scala:228)         at akka.dispatch.Mailbox.exec(Mailbox.scala:241)         at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)         at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)         at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)         at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ``` ",,Captain1653; johanandren
27960,ennru,2019-10-10T08:11:54Z,2023-09-18T10:16:13Z,johanandren,,Promote `RetryFlow` API to stable,"The `RetryFlow` added with https://github.com/akka/akka/pull/27742 is marked as ""API may change"". It should be promoted to the stable API at some point.",akka-stream/src/main/scala/akka/stream/Attributes.scala; akka-stream/src/main/scala/akka/stream/javadsl/RetryFlow.scala; akka-stream/src/main/scala/akka/stream/scaladsl/RetryFlow.scala; akka-stream/src/main/scala/akka/stream/snapshot/MaterializerState.scala,johanandren
27683,jroper,2019-09-11T06:23:08Z,2022-11-10T12:33:45Z,patriknw,helena; patriknw; jroper,CRDT expiry,"We have a sample app for a highly available shopping cart using Akka ddata. You could never use it in the real world though  because no real world e-commerce platform would consider being limited to 100000 (the maximum number of top level CRDTs we recommend) shopping carts over the life of their system as acceptable.  A simple solution to this is to support expiry of inactive CRDTs. This would involve maintaining a timestamp of when a CRDT was last accessed  either updated or read. The timestamp would need to be sent for each CRDT in the gossip status message  and nodes would update their timestamps when they received a more recent timestamp for a CRDT. Once the timestamp becomes older than the expiry interval  the node can discard the CRDT.  As far as I can see  this should be simple to implement. Another variant would be that expiry was based on last write (not last read)  this would alleviate the need to include timestamps in the status message  instead the timestamp would be sent with the CRDT/delta  and included in hashing. Not sure how useful just basing it on writes will be in practice though.  I think this would be useful for all session data CRDT use cases  and more generally  use cases where non durable CRDTs are used (if it's not the end of the world to lose the data in a complete cluster crash  then the data most likely either has an inherent limited period of usefulness  or can be read from some durable store if not found).",akka-cluster-typed/src/main/scala/akka/cluster/ddata/typed/internal/ReplicatorBehavior.scala; akka-cluster-typed/src/main/scala/akka/cluster/ddata/typed/javadsl/Replicator.scala; akka-cluster-typed/src/main/scala/akka/cluster/ddata/typed/scaladsl/Replicator.scala; akka-cluster-typed/src/main/scala/akka/cluster/ddata/typed/scaladsl/ReplicatorMessageAdapter.scala; akka-distributed-data/src/main/java/akka/cluster/ddata/protobuf/msg/ReplicatedDataMessages.java; akka-distributed-data/src/main/java/akka/cluster/ddata/protobuf/msg/ReplicatorMessages.java; akka-distributed-data/src/main/mima-filters/2.7.0.backwards.excludes/27683-crdt-expiry.excludes; akka-distributed-data/src/main/protobuf/ReplicatorMessages.proto; akka-distributed-data/src/main/resources/reference.conf; akka-distributed-data/src/main/scala/akka/cluster/ddata/DurableStore.scala; akka-distributed-data/src/main/scala/akka/cluster/ddata/Replicator.scala; akka-distributed-data/src/main/scala/akka/cluster/ddata/protobuf/ReplicatorMessageSerializer.scala; akka-distributed-data/src/multi-jvm/scala/akka/cluster/ddata/DurableDataSpec.scala; akka-distributed-data/src/multi-jvm/scala/akka/cluster/ddata/ExpirySpec.scala; akka-distributed-data/src/test/scala/akka/cluster/ddata/ReplicatorSettingsSpec.scala; akka-distributed-data/src/test/scala/akka/cluster/ddata/protobuf/ReplicatorMessageSerializerSpec.scala; akka-docs/src/main/paradox/typed/distributed-data.md,patriknw
27452,helena,2019-08-02T12:54:08Z,2025-01-07T06:23:02Z,patriknw,TylerJewell; patriknw,Consider adding a docs samples page like akka.io/alpakka-samples,"After 2.6  See https://akka.io/alpakka-samples Samples are being published from: https://github.com/akka/alpakka-samples The repo itself is similar to https://github.com/akka/akka-samples  but alpakka-samples have paradox docs in addition.",,TylerJewell; patriknw
27363,jroper,2019-07-17T05:37:01Z,2023-09-04T14:47:13Z,patriknw,Captain1653; patriknw,Custom equals/hashCode for GSet/ORSet/ORMap,"If using classes where you don't control the actual class implementation (such as generated classes  like the recommended approach of using protobufs)  and you want a custom `equals`/`hashCode` for `GSet`  `ORSet`  `ORMap`  the only way to implement it currently is to define a custom class  and therefore a custom serializer.  One use case for custom `equals`/`hashCode` is if the value contains an embedded serialized value  using an encoding that is not stable (ie  two equal values don't necessarily serialize to identical bytes  json and protobuf are both examples of this  since fields can be in any order). In such a case  equality may be based on a user defined key  from which `equals`/`hashCode` are implemented (with the assumption that if two keys are equal  then the serialized values associated with them must be semantically equal).  To support this  I guess the `equals`/`hashCode` implementations would have to be defined as part of the distributed data key.",,Captain1653; patriknw
27347,He-Pin,2019-07-12T12:08:31Z,2022-06-06T12:52:15Z,johanandren,Captain1653; johanandren,Doc: No Signature of Java's stream operators,"Signature ![image](https://user-images.githubusercontent.com/501740/61127058-bce0f600-a4e0-11e9-8f8a-699c94e6b11d.png) ",,Captain1653; johanandren
27330,patriknw,2019-07-11T10:16:18Z,2022-09-16T06:34:40Z,patriknw,,Enable serializer bindings in 2.5.x that were added in Akka 2.6.0,"A few new serializers were added in 2.6.0-M5: * BooleanSerializer * 4 new messages for Cluster Sharding queries in ClusterShardingMessageSerializer * ThrowableNotSerializableException in MiscMessageSerializer * TimeoutException in MiscMessageSerializer  Those were backported in TBD for release in 2.5.24  without enabling them for toBinary serialization.  It's not strictly necessary to enable binding for these in 2.5.x  but using this ticket for tracking in case we want to do it in some 2.5.x > 2.5.24.",akka-actor-tests/src/test/scala/akka/serialization/PrimitivesSerializationSpec.scala; akka-actor/src/main/resources/reference.conf; akka-actor/src/main/scala/akka/serialization/PrimitiveSerializers.scala; akka-cluster-sharding/src/main/java/akka/cluster/sharding/protobuf/msg/ClusterShardingMessages.java; akka-cluster-sharding/src/main/protobuf/ClusterShardingMessages.proto; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/ShardRegion.scala; akka-cluster-sharding/src/main/scala/akka/cluster/sharding/protobuf/ClusterShardingMessageSerializer.scala; akka-cluster-sharding/src/test/scala/akka/cluster/sharding/protobuf/ClusterShardingMessageSerializerSpec.scala; akka-remote/src/main/java/akka/remote/ArteryControlFormats.java; akka-remote/src/main/java/akka/remote/ContainerFormats.java; akka-remote/src/main/java/akka/remote/SystemMessageFormats.java; akka-remote/src/main/java/akka/remote/WireFormats.java; akka-remote/src/main/protobuf/ContainerFormats.proto; akka-remote/src/main/resources/reference.conf; akka-remote/src/main/scala/akka/remote/serialization/MiscMessageSerializer.scala; akka-remote/src/main/scala/akka/remote/serialization/ThrowableNotSerializableException.scala; akka-remote/src/test/java/akka/remote/ProtobufProtocol.java; akka-remote/src/test/scala/akka/remote/serialization/MiscMessageSerializerSpec.scala,patriknw
27163,otto-dev,2019-06-17T23:06:58Z,2023-03-27T08:12:41Z,johanandren,fredfp; francisdb; froth; patriknw; otto-dev; johanandren; He-Pin,BroadcastHub swallows initial elements for new consumers,"This issue is in regard to Akka Streams.  **How to reproduce**: - Attach a source to a BroadcastHub  and materialise the hub - Attach consumers to the hub - Start emitting elements through the BroadcastHub  **Expected behaviour**: - All consumers should receive all emitted elements  **Actual behaviour**: - Some consumers may only receive some  or none of the emitted elements (indeterministic). Some or all initial elements may be swallowed.  The following test fails (most of the time) ```   ""BroadcastHub"" should ""broadcast all elements to all consumers"" in {     val blockingFlow = Source.queue(1  OverflowStrategy.fail) // used to block the source until we say so     val (queue  broadcast) = blockingFlow         .concat(Source(1 to 10)) // emit this after blockingFlow completes         .toMat(BroadcastHub.sink)(Keep.both)         .run()     val resultOne = broadcast.runWith(Sink.seq) // nothing happening yet     val resultTwo = broadcast.runWith(Sink.seq)      queue.complete() // only now is the source emptied      Await.result(resultOne  1.second) should be(1 to 10) // fails     Await.result(resultTwo  1.second) should be(1 to 10) // fails   } ```  Clearly this is a consequence of concurrency  but in some use-cases it's important to be able to guarantee deterministic behaviour  i.e. that all consumers receive all elements.",,fredfp; francisdb; froth; patriknw; otto-dev; johanandren; He-Pin
26876,gabriel-ntuc,2019-05-07T03:27:24Z,2022-04-29T08:56:27Z,johanandren,patriknw; asureshraja; gabriel-ntuc; johanandren; He-Pin,Filter for Java optional,"A common use case that I have found requires some boilerplate right now is ""unwrapping"" Java optionals. There doesn't seem to be a concise way to both filter out and unwrap Java optionals.  Assuming that we have some arbitrary source of optional elements such as: ```java Source<Optional<Integer>  NotUsed> numbers = Source.range(1  10)   .map(x -> Optional.of(x).filter(n -> n % 2 == 0)) ```  Currently the alternatives are:  **filter + get**  ```java numbers   .filter(Optional::isPresent)   .map(Optional::get) ```  **collect** ```java numbers   .collect(new PFBuilder<Optional<Integer>  Integer>()     .matchUnchecked(         Optional.class          (FI.TypedPredicate<Optional<?>>) Optional::isPresent          (FI.Apply<Optional<Integer>  Integer>) Optional::get     )     .build()); ```  **flatMapConcat (≥ JDK 9 only)** ```java numbers   .flatMapConcat(x -> StreamConverters.fromJavaStream(x::stream)) ```  The latter is the shortest way of doing it but besides the limitation on JDK version it is also incredibly inefficient  benchmarking it with 10 million elements resulted in 50x longer running time compared to the other two alternatives  I am not too familiar with Akka stream internals but I am guessing that this will materialize a stream for every element.    It seems to me like such a common use case that it could warrant its own operator something like `filterOptional` or similar that could be added to the Java DSL would reduce a lot of unnecessary boilerplate. ",,patriknw; asureshraja; gabriel-ntuc; johanandren; He-Pin
26573,derolf,2019-03-19T17:09:37Z,2023-09-02T09:06:19Z,derolf,Captain1653; johanandren,Outlet routing component for GraphDSL,"I'd like to propose a component for GraphDSL with the following semantics.  We define a routable packet that contains a payload and a target outlet number.  `case class RouteTo1[A](payload: A)` `case class RouteTo2[B](payload: B)` `...`  Now  we would like to have a `Switch[A  B]` with: `in` : consumes message of type `RouteTo1[A]` and `RouteTo2[B]` `out1` : emits the `payload` of `RouteTo1[A]` packages `out2` : emits the `payload` of `RouteTo2[B]` packages `...`",,Captain1653; johanandren
26367,pierangeloc,2019-02-12T09:19:43Z,2023-09-04T07:21:30Z,johanandren,Captain1653; johanandren,wireTap behaves differently with Sink.seq and Sink.actorRef,"I'm using akka-stream 2.5.16  Scala 2.11.   I see a strange behavior of `wireTap` in my tests. I'm connecting to a wiretap first a `Sink.seq` and then I replace the Sink with a `Sink.actorRef`. I would expect the actor to receive the same messages that are in the `Future[Seq]` materialized by the first Sink  but that is not the case  as the actor receives just one `Done`.  ```scala case object Tick     def f(n: Int): ErrorOrTick = if (n % 2 == 0) Right(Tick) else Left(""Boom”)  ""this test passes"" in {       val src: Source[ErrorOrTick  NotUsed] = Source.fromIterator(() => Stream.from(0).iterator).take(8).map(f)       val wiretapSink: Sink[ErrorOrTick  Future[immutable.Seq[String]]] = Flow[ErrorOrTick].collect {case Left(e) => e}.toMat(Sink.seq)(Keep.right)        val (wiretap  sink): (Future[immutable.Seq[String]]  Future[immutable.Seq[ErrorOrTick]]) = src.wireTapMat(wiretapSink)(Keep.right).toMat(Sink.seq)(Keep.both).run       Await.result(wiretap  2.seconds).toList shouldEqual List(""Boom""  ""Boom""  ""Boom""  ""Boom"")       Await.result(sink  2.seconds).toList shouldEqual List(Right(Tick)  Left(""Boom"")  Right(Tick)  Left(""Boom"")  Right(Tick)  Left(""Boom"")  Right(Tick)  Left(""Boom""))     }   ""this test fails"" in {       val probeSink = TestProbe()        val src: Source[ErrorOrTick  NotUsed] = Source.fromIterator(() => Stream.from(0).iterator).take(8).map(f)       val wiretapSink: Sink[ErrorOrTick  NotUsed] = Flow[ErrorOrTick].collect  {case Left(e) => e}.to(Sink.actorRef(probeSink.ref  Done))        val (wiretap  sink): (NotUsed  Future[immutable.Seq[ErrorOrTick]]) = src.wireTapMat(wiretapSink)(Keep.right).toMat(Sink.seq)(Keep.both).run       Await.result(sink  2.seconds).toList shouldEqual List(Right(Tick)  Left(""Boom"")  Right(Tick)  Left(""Boom"")  Right(Tick)  Left(""Boom"")  Right(Tick)  Left(""Boom""))        probeSink.expectMsgAllOf(5.seconds  ""Boom""  ""Boom""  ""Boom""  ""Boom""  Done)     } ``` ",,Captain1653; johanandren
26290,epot,2019-01-27T19:06:20Z,2023-09-04T08:35:48Z,johanandren,Captain1653; epot; patriknw; johanandren,Nodes stuck leaving akka cluster and new nodes cannot fully join,"We have an Akka cluster of ~1000 nodes with ~10 different roles. Version used: `2.5.17`. We started to have an issue for the past few days. It started when a dozen nodes try to leave the cluster because they were shut down. We did not notice the issue first  but those nodes never really left the cluster and are stuck in `leaving` state. Now  each node that is restarted has the issue: it never disappears from the cluster  and if we try to restart Akka on the same node  it fails to join  getting some `Received InitJoinAck message from` a seed node but are never up.  If we start Akka on new nodes (with addresses the cluster never saw) then they are weakly up but never up. We also lost Akka cluster singletons on a few role and they never get reassigned even if we spin up new machines.  It really looks likes the cluster leadership is broken somehow  but we can't find any logs giving some insights into this. We would really prefer to restart completely the cluster. An important process run on seed nodes so we are also reluctant to restart them (as we are not sure we are not going to lose the singleton ion this role). It seems the cluster leader runs on another role  so we could try to restart it.   I tried looking into the opened issues  but it does not seem to be a known issue  not sure if it rings a bell to anyone?",,Captain1653; epot; patriknw; johanandren
26195,chbatey,2019-01-03T14:38:52Z,2023-09-01T07:49:10Z,patriknw,Captain1653; patriknw; He-Pin; 2m; TimMoore,Factory version of Source `fromFutureSource`,When using `Source.fromFutureSource` a single Future is re-used for every materialisation. A common usecase for this is doing an async action to initialise a Source e.g. hitting a database to get some initial state. A version that takes a `() => Future[Source]` would be more useful in these cases that would behave more like a `Task` than a `Future`,,Captain1653; patriknw; He-Pin; 2m; TimMoore
26111,He-Pin,2018-12-12T13:05:50Z,2023-08-31T18:58:10Z,He-Pin,Captain1653; He-Pin; patriknw; johanandren,Feature request(Java API): Add CompletionStages helper as an alias with akka.dispatch.Futures,"Currently  Akka has `akka.dispatch.Futures` for Java API but none for `CompletionStage`  even there is `CompletableFuture#allOf` and `CompletableFuture#anyOf` but there are no more rich operators.  eg: ![image](https://user-images.githubusercontent.com/501740/49871423-30d6f500-fe51-11e8-9028-b9a8c549b6ab.png)  I opened this issue up because today I saw one of my workmate at HemaFresh is using `akka.dispatch.Futures` from Java. For what we have in our TQL implementation  we do have so many helpers to work with `CompletableStage`. ![image](https://user-images.githubusercontent.com/501740/49871545-80b5bc00-fe51-11e8-842b-3cd025381a81.png)  eg: ```java   /**    * 根据一个 {@link CompletableFuture} 的 {@link Iterable}  并应用一个折叠函数，从而异步产生一个值。    * 需要注意的是，这里对函数的应用是同步执行的。    *    * @param futures 需要进行异步折叠的所有 {@link CompletableFuture}.    * @param zero    初始值；    * @param acc     用于将值合并到一起的函数;    * @return 返回一个 {@link CompletableFuture}，其中包含了折叠后的值。    */   public static <T  U> CompletableFuture<U> fold(     final Iterable<? extends CompletableFuture<? extends T>> futures      final U zero      final BiFunction<? super U  ? super T  ? extends U> acc)  ```  I think Akka could provide something like this to helper Java developer work with `CompletionStage` more directly but not with the `akka.dispatch.Futures`",,Captain1653; He-Pin; patriknw; johanandren
26072,He-Pin,2018-12-06T19:26:41Z,2023-08-21T07:19:25Z,johanandren,mghildiy; Captain1653; patriknw; johanandren; kun-song; He-Pin,Java example with @lombok?,"```java @Data @AllArgsConstructor @Builder public class AgooPushedEvent implements MetricsEvent {   private final MsgSingleDTO msgSingleDTO;   private final AgooParamDTO agooParamDTO;   private final ClientPlatformEnum clientPlatformEnum;   private final MessageSendDTO messageSendDTO;   private final boolean sendSuccess; } ``` Something like this could make the code snips shorter? or at least recommend it? even I am not a fun of Lombok its self but it does help when programming with plain old Java immutable objects.",,mghildiy; Captain1653; patriknw; johanandren; kun-song; He-Pin
25839,raboof,2018-10-30T16:02:47Z,2022-05-04T12:36:17Z,johanandren,,zipLatest: eager close option,"The zipLatest stage (https://doc.akka.io/docs/akka/snapshot/stream/operators/Source-or-Flow/zipLatest.html) currently completes when any of the upstream streams complete.  This can make sense  but in other cases it can be more useful to keep repeating the last element of any closed stream  and only complete the stage it when all incoming streams have completed.  It might make sense to add a parameter for this.",,johanandren
25823,andersstorhaug,2018-10-24T01:31:08Z,2022-04-28T07:06:09Z,patriknw,He-Pin; johanandren; arpanchaudhury,`MergePrioritized` never fully uses allocated buffers?,"<!--  We use the issue tracker for bugs and feature requests. For general questions and discussion please use https://discuss.akka.io or https://gitter.im/akka/akka instead.  Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka HTTP: https://github.com/akka/akka-http/issues   - Alpakka:   https://github.com/akka/alpakka/issues   - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your issue precisely  and if possible provide a reproducer snippet (this helps resolve issues much quicker).  Thanks  happy hakking! -->  Out of curiosity I was trying to understand how `MergePrioritized` was implemented and I noticed that its buffers appear to contain at most one element -- the inlet for the respective priority/source.  However it looks like the buffers are sized [based on priority](https://github.com/akka/akka/blob/master/akka-stream/src/main/scala/akka/stream/scaladsl/Graph.scala#L319):  ```scala private val allBuffers = Vector.tabulate(priorities.size)(i ⇒ FixedSizeBuffer[Inlet[T]](priorities(i))) ```  Is there an optimization to be made around this?",,He-Pin; johanandren; arpanchaudhury
25701,carlosrogue,2018-09-29T11:58:46Z,2023-08-30T08:56:02Z,johanandren,Captain1653; carlosrogue,Fix fallback DNS name server resolution using reflection in DnsSettings,"From Akka Team [tweet](https://twitter.com/akkateam/status/1045624340786630662) to 2.5.17 release [announcement](https://akka.io/blog/news/2018/09/27/akka-2.5.17-released) to 2.5.17 [milestone](https://github.com/akka/akka/milestone/133?closed=1) to this issue #25635 and to this pull request #25636  while checking `DnsSettings`  I found this:  https://github.com/akka/akka/blob/d7c463e033a17a0f7c06997ee768d406c1359c33/akka-actor/src/main/scala/akka/io/dns/DnsSettings.scala#L120",,Captain1653; carlosrogue
25628,sampleblood,2018-09-16T11:41:20Z,2023-05-26T14:49:07Z,johanandren,johanandren,BroadcastHub source break down,"@Inject  `public TickerProcessor(Config configuration) {`         `super(configuration);`         `final Config config = configuration.getConfig(""web-socket"");`         `ActorMaterializer mat = ActorMaterializer.create(context());`        ` Source<Ticker  SourceQueueWithComplete<Ticker>> sourceQueueWithCompleteSource =                 Source.queue(config.getInt(""queue-buffer-size"")  OverflowStrategy.dropHead());`        ` Pair<SourceQueueWithComplete<Ticker>  Source<Ticker  NotUsed>> sinkSourcePair = sourceQueueWithCompleteSource.log(""tickerQueue"")                 .toMat(BroadcastHub.of(Ticker.class  config.getInt(""broadcast-buffer-size""))  Keep.both()).run(mat);`        `inputQueue = sinkSourcePair.first();`         `source = sinkSourcePair.second();`        ` logSource();`     `}`  // use to debug  this will stop in random time  relate to this issue `     private void logSource() {         if (logger.isInfoEnabled()) {             source.runForeach(p -> logger.info(""logSource: volume: {}""  p.tickerData.data.tickers.get(0).get(2))  ActorMaterializer.create(context()));         }     } `  this is an actor in play framework  init stream in constructor  inputQueue offer element every one second  source consumed by many other actors. everything works well at the beginning   but after sometime   may be one day or two  the source just stop without any exception.  inputQueue offer runs normal   but source stop to emitting any new element.  when start a new source from broadcastHub  source will emit exact 21 old elements in sudden and then stop. please help me check that   thank you guys ",,johanandren
25623,dembol,2018-09-14T16:00:48Z,2022-05-02T08:32:42Z,jrudolph,jrudolph; dembol; patriknw; johanandren; He-Pin,High memory consumption using Grouped operator in Akka Streams,"I’ve noticed a serious problem with high memory consumption while using streams terminated by SinkRef and `grouped` operator somewhere in a stream topology. The `grouped` operator is backed by a VectorBuilder which is cleared when `onPush` or `onUpstreamFinish` callbacks are executed. Unfortunately clearing the vector in Scala 2.12 means allocating new root node but still keeping hard references to the obsolete nodes on the higher levels of a tree which cannot be Garbage Collected. I see that some additional cleaning has been added in Scala 2.13 which will eliminate the problem in the future -  https://github.com/scala/scala/commit/845b0f0ffc59392b3dd59979f89d4f101e598236#diff-59f3462485b74027de4fd5e9febcc81bR627  The situation can be very dangerous when somebody wants to use `grouped` operator with high number of grouped elements  connect it to the sink produced by `StreamRefs.sourceRef()` and send materialized `SourceRef` over the network. Why it’s so dangerous? `SourceRefImpl` and `SinkRefImpl` start watching their partners what causes sending a WATCH SystemMessage with watchee and watcher remote paths. Those paths are deserialized by `SystemMessageSerializer.deserializeSystemMessage` which in turn calls `RemoteActorRefProvider.resolveActorRef` which uses `ActorRefResolveThreadLocalCache` backed by `LruBoundedCache`. If we have `grouped` stage with lots of heavy elements we may observe OutOfMemoryErrors in short time if we materialize many such streams.  Here are screenshots from profiler:  ![telemetry](https://user-images.githubusercontent.com/1668056/45560536-b1cc2380-b845-11e8-93bc-0aec639a4669.png)  ![heap_walker](https://user-images.githubusercontent.com/1668056/45561114-3d927f80-b847-11e8-89c1-b60085133bbf.png)  The quick fix is to use modified `grouped` operator using a List instead of a Vector (https://gist.github.com/dembol/b69d205ca35af7ec19453e66affbb10c) or use `grouped` operator with less than 32 elements.",,jrudolph; dembol; patriknw; johanandren; He-Pin
25535,khaneun,2018-08-28T02:17:42Z,2023-08-28T07:29:33Z,patriknw,Captain1653; helena; patriknw; khaneun,Can't remove garbage cluster members,"I've operating with 18 nodes of cluster for 2 years. A faw weeks ago  after ocurring troubles on some nodes (kinds of network problem... )   Cluster can not remove a lot of garbage members. and they have anomaly states like  [DOWN seen=false]  ``` [INFO ] [akka-cluster-name-akka.actor.default-dispatcher-4] Cluster(akka://akka-cluster-name)  Cluster Node [akka.tcp://akka-cluster-name@10.1.120.10:9501]  - Leader can currently not perform its duties  reachability status:  [akka.tcp://akka-cluster-name@20.10.3.120:22930 -> akka.tcp://akka-cluster-name@20.10.3.120:19525: Unreachable [Unreachable] (477)   akka.tcp://akka-cluster-name@20.10.3.34:9501 -> akka.tcp://akka-cluster-name@20.10.3.120:19525: Unreachable [Unreachable] (282)   akka.tcp://akka-cluster-name@20.10.3.34:18704 -> akka.tcp://akka-cluster-name@20.10.3.120:19525: Unreachable [Unreachable] (4554)   akka.tcp://akka-cluster-name@20.10.3.34:5691 -> akka.tcp://akka-cluster-name@20.10.3.120:19525: Unreachable [Unreachable] (70)   akka.tcp://akka-cluster-name@20.10.3.34:31963 -> akka.tcp://akka-cluster-name@20.10.3.120:19525: Unreachable [Unreachable] (1116)]   member status: [akka.tcp://akka-cluster-name@20.10.3.34:10837 Up seen=true   akka.tcp://akka-cluster-name@20.10.3.120:10407 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:10809 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:11309 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:1139 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:11474 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:11617 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:11884 Down seen=false   ... akka.tcp://akka-cluster-name@20.10.3.120:14330 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:14800 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:14918 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:15066 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:15991 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:16403 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:16454 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:17609 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:18899 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:19098 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:19525 Up seen=false   ... akka.tcp://akka-cluster-name@20.10.3.120:22225 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:22551 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:22930 Up seen=true   akka.tcp://akka-cluster-name@20.10.3.120:23682 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:24269 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:25233 Up seen=true   akka.tcp://akka-cluster-name@20.10.3.120:25270 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:25382 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:25533 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:25764 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:26117 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:2674 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:26766 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:27350 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:27512 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:27677 Down seen=false  akka.tcp://akka-cluster-name@20.10.3.120:27856 Up seen=true   akka.tcp://akka-cluster-name@20.10.3.120:27865 Up seen=true   akka.tcp://akka-cluster-name@20.10.3.120:28321 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:28522 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:28900 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:29193 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:29240 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:30104 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:30418 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:30577 Down seen=false   akka.tcp://akka-cluster-name@20.10.3.120:30679 Down seen=false   ...  ```  and ocurr the amounts of the warning log every sec.   ``` [2018-08-27 09:59:03.786] [WARN ] [akka-cluster-name-akka.actor.default-dispatcher-4] akka.remote.ReliableDeliverySupervisor Association with remote system [akka.tcp://akka-cluster-name@20.10.3.120:22551] has failed  address is now gated for [5000] ms. Reason: [Association failed with [akka.tcp://akka-cluster-name@20.10.3.120:22551]] Caused by: [Connection refused: /20.10.3.120:22551] [2018-08-27 09:59:04.097] [WARN ] [akka-cluster-name-akka.actor.default-dispatcher-3] akka.remote.ReliableDeliverySupervisor Association with remote system [akka.tcp://akka-cluster-name@20.10.3.120:19098] has failed  address is now gated for [5000] ms. Reason: [Association failed with [akka.tcp://akka-cluster-name@20.10.3.120:19098]] Caused by: [Connection refused: /20.10.3.120:19098] [2018-08-27 09:59:04.787] [WARN ] [akka-cluster-name-akka.actor.default-dispatcher-15] akka.remote.ReliableDeliverySupervisor Association with remote system [akka.tcp://akka-cluster-name@20.10.3.120:17609] has failed  address is now gated for [5000] ms. Reason: [Association failed with [akka.tcp://akka-cluster-name@20.10.3.120:17609]] Caused by: [Connection refused: /20.10.3.120:17609] [2018-08-27 09:59:05.097] [WARN ] [akka-cluster-name-akka.actor.default-dispatcher-5] akka.remote.ReliableDeliverySupervisor Association with remote system [akka.tcp://akka-cluster-name@20.10.3.120:13738] has failed  address is now gated for [5000] ms. Reason: [Association failed with [akka.tcp://akka-cluster-name@20.10.3.120:13738]] Caused by: [Connection refused: /20.10.3.120:13738] [2018-08-27 09:59:05.456] [WARN ] [akka-cluster-name-akka.actor.default-dispatcher-15] akka.remote.ReliableDeliverySupervisor Association with remote system [akka.tcp://akka-cluster-name@20.10.3.120:20162] has failed  address is now gated for [5000] ms. Reason: [Association failed with [akka.tcp://akka-cluster-name@20.10.3.120:20162]] Caused by: [Connection refused: /20.10.3.120:20162]  ... ```  How can I remove those anomaly members? or any ideas? please help me!  #18474 https://github.com/akka/akka/issues/18474    ",,Captain1653; helena; patriknw; khaneun
25441,raboof,2018-08-06T17:30:00Z,2023-08-28T07:12:26Z,johanandren,Captain1653; johanandren,Make clearer recommendation in the 'shared leveldb' documentation section,"The 'shared leveldb' section (https://doc.akka.io/docs/akka/current/scala/persistence.html#shared-leveldb-journal) does mention it is not a production option and is replaced by another mechanism  but those are not very actionable recommendations at this point (e.g. pointing to the very generic https://akka.io/community).  It might be nice to give a little more specific guidance here.",,Captain1653; johanandren
25418,lksoe,2018-07-31T18:48:47Z,2023-08-30T08:57:12Z,johanandren,jrudolph; Captain1653; johanandren,Association fails when restarting two nodes at the same time in a cluster,"In our current setup  we have two nodes that are part of a cluster that are initially working as expected. Node1 is the initial seed node and Node2 is the other seed node.   In rare occasions  when we restart Node1 and then subsequently restart Node2  we see that association in Node1 does not occur (not logged) even though Node2 reports an association. This causes Node2 to report that it cannot connect to seed Node1.  Logs from Node1: ``` Jul 31 17:09:50 host1 mySystem: [INFO] [07/31/2018 17:09:50.305] [main] [akka.remote.Remoting] Starting remoting Jul 31 17:09:50 host1 mySystem: [INFO] [07/31/2018 17:09:50.486] [main] [akka.remote.Remoting] Remoting started; listening on addresses :[akka.ssl.tcp://mySystem@host1:9610] Jul 31 17:09:50 host1 mySystem: [INFO] [07/31/2018 17:09:50.489] [main] [akka.remote.Remoting] Remoting now listens on addresses: [akka.ssl.tcp://mySystem@host1:9610] Jul 31 17:09:50 host1 mySystem: [INFO] [07/31/2018 17:09:50.520] [main] [akka.cluster.Cluster(akka://mySystem)] Cluster Node [akka.ssl.tcp://mySystem@host1:9610] - Starting up... Jul 31 17:09:50 host1 mySystem: [INFO] [07/31/2018 17:09:50.572] [main] [akka.cluster.Cluster(akka://mySystem)] Cluster Node [akka.ssl.tcp://mySystem@host1:9610] - Registered cluster JMX MBean [akka:type=Cluster] Jul 31 17:09:50 host1 mySystem: [INFO] [07/31/2018 17:09:50.572] [main] [akka.cluster.Cluster(akka://mySystem)] Cluster Node [akka.ssl.tcp://mySystem@host1:9610] - Started up successfully Jul 31 17:09:50 host1 mySystem: [DEBUG] [07/31/2018 17:09:50.946] [mySystem-akka.remote.default-remote-dispatcher-6] [NettyTransport(akka://mySystem)] SSL random number generator set to: AES128CounterSecureRNG Jul 31 17:09:53 host1 mySystem: [DEBUG] [07/31/2018 17:09:53.917] [New I/O worker #1] [NettyTransport(akka://mySystem)] Remote connection to [host2/host2ipaddress:9610] was disconnected because of [id: 0x6f3131e8  /host1ipaddress:41380 :> host2/host2ipaddress:9610] DISCONNECTED Jul 31 17:09:53 host1 mySystem: [WARN] [07/31/2018 17:09:53.920] [New I/O worker #1] [NettyTransport(akka://mySystem)] Remote connection to [host2/host2ipaddress:9610] failed with javax.net.ssl.SSLException: Received close_notify during handshake Jul 31 17:09:55 host1 mySystem: [DEBUG] [07/31/2018 17:09:55.616] [mySystem-akka.actor.default-dispatcher-18] [akka.ssl.tcp://mySystem@host1:9610/system/cluster/core/daemon/firstSeedNodeProcess-1] Couldn't join other seed nodes  will join myself. seed-nodes=[akka.ssl.tcp://mySystem@host1:9610  akka.ssl.tcp://mySystem@host2:9610] Jul 31 17:09:55 host1 mySystem: [INFO] [07/31/2018 17:09:55.626] [mySystem-akka.actor.default-dispatcher-20] [akka.cluster.Cluster(akka://mySystem)] Cluster Node [akka.ssl.tcp://mySystem@host1:9610] - Node [akka.ssl.tcp://mySystem@host1:9610] is JOINING  roles [mySystem-websockets  dc-default] Jul 31 17:09:55 host1 mySystem: [INFO] [07/31/2018 17:09:55.636] [mySystem-akka.actor.default-dispatcher-20] [akka.cluster.Cluster(akka://mySystem)] Cluster Node [akka.ssl.tcp://mySystem@host1:9610] - Leader is moving node [akka.ssl.tcp://mySystem@host1:9610] to [Up] Jul 31 17:10:05 host1 mySystem: [INFO] [07/31/2018 17:10:05.709] [mySystem-akka.remote.default-remote-dispatcher-6] [akka.ssl.tcp://mySystem@host1:9610/system/transports/akkaprotocolmanager.ssl.tcp0/akkaProtocol-ssl.tcp%3A%2F%2FmySystem%40host2%3A9610-1] No response from remote for outbound association. Associate timed out after [15000 ms]. Jul 31 17:10:05 host1 mySystem: [DEBUG] [07/31/2018 17:10:05.712] [mySystem-akka.remote.default-remote-dispatcher-5] [akka.ssl.tcp://mySystem@host1:9610/system/endpointManager/reliableEndpointWriter-akka.ssl.tcp%3A%2F%2FmySystem%40host2%3A9610-0/endpointWriter] AssociationError [akka.ssl.tcp://mySystem@host1:9610] -> [akka.ssl.tcp://mySystem@host2:9610]: Error [Association failed with [akka.ssl.tcp://mySystem@host2:9610]] [ Jul 31 17:10:05 host1 mySystem: akka.remote.EndpointAssociationException: Association failed with [akka.ssl.tcp://mySystem@host2:9610] Jul 31 17:10:05 host1 mySystem: Caused by: java.util.concurrent.TimeoutException: No response from remote for outbound association. Associate timed out after [15000 ms]. Jul 31 17:10:05 host1 mySystem: at akka.remote.transport.ProtocolStateActor$$anonfun$2.applyOrElse(AkkaProtocolTransport.scala:366) Jul 31 17:10:05 host1 mySystem: at akka.remote.transport.ProtocolStateActor$$anonfun$2.applyOrElse(AkkaProtocolTransport.scala:340) Jul 31 17:10:05 host1 mySystem: at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) Jul 31 17:10:05 host1 mySystem: at akka.actor.FSM$class.processEvent(FSM.scala:665) Jul 31 17:10:05 host1 mySystem: at akka.remote.transport.ProtocolStateActor.processEvent(AkkaProtocolTransport.scala:285) Jul 31 17:10:05 host1 mySystem: at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:659) Jul 31 17:10:05 host1 mySystem: at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:631) Jul 31 17:10:05 host1 mySystem: at akka.actor.Actor$class.aroundReceive(Actor.scala:517) Jul 31 17:10:05 host1 mySystem: at akka.remote.transport.ProtocolStateActor.aroundReceive(AkkaProtocolTransport.scala:285) Jul 31 17:10:05 host1 mySystem: at akka.actor.ActorCell.receiveMessage(ActorCell.scala:590) Jul 31 17:10:05 host1 mySystem: at akka.actor.ActorCell.invoke(ActorCell.scala:559) Jul 31 17:10:05 host1 mySystem: at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257) Jul 31 17:10:05 host1 mySystem: at akka.dispatch.Mailbox.run(Mailbox.scala:224) Jul 31 17:10:05 host1 mySystem: at akka.dispatch.Mailbox.exec(Mailbox.scala:234) Jul 31 17:10:05 host1 mySystem: at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) Jul 31 17:10:05 host1 mySystem: at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) Jul 31 17:10:05 host1 mySystem: at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) Jul 31 17:10:05 host1 mySystem: at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) Jul 31 17:10:05 host1 mySystem: ] Jul 31 17:10:05 host1 mySystem: [WARN] [07/31/2018 17:10:05.715] [mySystem-akka.remote.default-remote-dispatcher-6] [akka.ssl.tcp://mySystem@host1:9610/system/endpointManager/reliableEndpointWriter-akka.ssl.tcp%3A%2F%2FmySystem%40host2%3A9610-0] Association with remote system [akka.ssl.tcp://mySystem@host2:9610] has failed  address is now gated for [5000] ms. Reason: [Association failed with [akka.ssl.tcp://mySystem@host2:9610]] Caused by: [No response from remote for outbound association. Associate timed out after [15000 ms].] Jul 31 17:10:05 host1 mySystem: [INFO] [07/31/2018 17:10:05.718] [mySystem-akka.actor.default-dispatcher-14] [akka://mySystem/deadLetters] Message [akka.cluster.InternalClusterAction$InitJoin] from Actor[akka://mySystem/system/cluster/core/daemon/firstSeedNodeProcess-1#1473082516] to Actor[akka://mySystem/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'. Jul 31 17:10:05 host1 mySystem: [INFO] [07/31/2018 17:10:05.718] [mySystem-akka.actor.default-dispatcher-14] [akka://mySystem/deadLetters] Message [akka.cluster.InternalClusterAction$InitJoin] from Actor[akka://mySystem/system/cluster/core/daemon/firstSeedNodeProcess-1#1473082516] to Actor[akka://mySystem/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'. Jul 31 17:10:05 host1 mySystem: [INFO] [07/31/2018 17:10:05.718] [mySystem-akka.actor.default-dispatcher-14] [akka://mySystem/deadLetters] Message [akka.cluster.InternalClusterAction$InitJoin] from Actor[akka://mySystem/system/cluster/core/daemon/firstSeedNodeProcess-1#1473082516] to Actor[akka://mySystem/deadLetters] was not delivered. [3] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'. Jul 31 17:10:05 host1 mySystem: [INFO] [07/31/2018 17:10:05.718] [mySystem-akka.actor.default-dispatcher-14] [akka://mySystem/deadLetters] Message [akka.cluster.InternalClusterAction$InitJoin] from Actor[akka://mySystem/system/cluster/core/daemon/firstSeedNodeProcess-1#1473082516] to Actor[akka://mySystem/deadLetters] was not delivered. [4] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'. Jul 31 17:10:05 host1 mySystem: [INFO] [07/31/2018 17:10:05.718] [mySystem-akka.actor.default-dispatcher-14] [akka://mySystem/deadLetters] Message [akka.cluster.InternalClusterAction$InitJoin] from Actor[akka://mySystem/system/cluster/core/daemon/firstSeedNodeProcess-1#1473082516] to Actor[akka://mySystem/deadLetters] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'. Jul 31 17:10:05 host1 mySystem: [DEBUG] [07/31/2018 17:10:05.719] [mySystem-akka.remote.default-remote-dispatcher-5] [akka.ssl.tcp://mySystem@host1:9610/system/endpointManager/reliableEndpointWriter-akka.ssl.tcp%3A%2F%2FmySystem%40host2%3A9610-0/endpointWriter] Disassociated [akka.ssl.tcp://mySystem@host1:9610] -> [akka.ssl.tcp://mySystem@host2:9610] ```  Logs from Node 2: ``` Jul 31 17:09:53 host2 mySystem: [INFO] [07/31/2018 17:09:53.990] [main] [akka.remote.Remoting] Starting remoting Jul 31 17:09:54 host2 mySystem: [INFO] [07/31/2018 17:09:54.189] [main] [akka.remote.Remoting] Remoting started; listening on addresses :[akka.ssl.tcp://mySystem@host2:9610] Jul 31 17:09:54 host2 mySystem: [INFO] [07/31/2018 17:09:54.191] [main] [akka.remote.Remoting] Remoting now listens on addresses: [akka.ssl.tcp://mySystem@host2:9610] Jul 31 17:09:54 host2 mySystem: [INFO] [07/31/2018 17:09:54.221] [main] [akka.cluster.Cluster(akka://mySystem)] Cluster Node [akka.ssl.tcp://mySystem@host2:9610] - Starting up... Jul 31 17:09:54 host2 mySystem: [INFO] [07/31/2018 17:09:54.281] [main] [akka.cluster.Cluster(akka://mySystem)] Cluster Node [akka.ssl.tcp://mySystem@host2:9610] - Registered cluster JMX MBean [akka:type=Cluster] Jul 31 17:09:54 host2 mySystem: [INFO] [07/31/2018 17:09:54.281] [main] [akka.cluster.Cluster(akka://mySystem)] Cluster Node [akka.ssl.tcp://mySystem@host2:9610] - Started up successfully Jul 31 17:09:54 host2 mySystem: [DEBUG] [07/31/2018 17:09:54.686] [mySystem-akka.remote.default-remote-dispatcher-6] [NettyTransport(akka://mySystem)] SSL random number generator set to: AES128CounterSecureRNG Jul 31 17:09:59 host2 mySystem: [DEBUG] [07/31/2018 17:09:59.845] [mySystem-akka.remote.default-remote-dispatcher-5] [akka.ssl.tcp://mySystem@host2:9610/system/endpointManager/reliableEndpointWriter-akka.ssl.tcp%3A%2F%2FmySystem%40host1%3A9610-0/endpointWriter] Associated [akka.ssl.tcp://mySystem@host2:9610] -> [akka.ssl.tcp://mySystem@host1:9610] Jul 31 17:09:59 host2 mySystem: [DEBUG] [07/31/2018 17:09:59.857] [mySystem-akka.remote.default-remote-dispatcher-5] [akka.serialization.Serialization(akka://mySystem)] Using serializer [akka.cluster.protobuf.ClusterMessageSerializer] for message [akka.cluster.InternalClusterAction$InitJoin] Jul 31 17:09:59 host2 mySystem: [DEBUG] [07/31/2018 17:09:59.886] [mySystem-akka.remote.default-remote-dispatcher-5] [akka.ssl.tcp://mySystem@host2:9610/system/endpointManager/reliableEndpointWriter-akka.ssl.tcp%3A%2F%2FmySystem%40host1%3A9610-0/endpointWriter] Drained buffer with maxWriteCount: 50  fullBackoffCount: 1  smallBackoffCount: 0  noBackoffCount: 0   adaptiveBackoff: 1000 Jul 31 17:10:04 host2 mySystem: [WARN] [07/31/2018 17:10:04.405] [mySystem-akka.actor.default-dispatcher-2] [akka.ssl.tcp://mySystem@host2:9610/system/cluster/core/daemon/joinSeedNodeProcess-1] Couldn't join seed nodes after [2] attempts  will try again. seed-nodes=[akka.ssl.tcp://mySystem@host1:9610] Jul 31 17:10:09 host2 mySystem: [WARN] [07/31/2018 17:10:09.423] [mySystem-akka.actor.default-dispatcher-2] [akka.ssl.tcp://mySystem@host2:9610/system/cluster/core/daemon/joinSeedNodeProcess-1] Couldn't join seed nodes after [3] attempts  will try again. seed-nodes=[akka.ssl.tcp://mySystem@host1:9610] Jul 31 17:10:14 host2 mySystem: [WARN] [07/31/2018 17:10:14.443] [mySystem-akka.actor.default-dispatcher-19] [akka.ssl.tcp://mySystem@host2:9610/system/cluster/core/daemon/joinSeedNodeProcess-1] Couldn't join seed nodes after [4] attempts  will try again. seed-nodes=[akka.ssl.tcp://mySystem@host1:9610] Jul 31 17:10:19 host2 mySystem: [WARN] [07/31/2018 17:10:19.463] [mySystem-akka.actor.default-dispatcher-2] [akka.ssl.tcp://mySystem@host2:9610/system/cluster/core/daemon/joinSeedNodeProcess-1] Couldn't join seed nodes after [5] attempts  will try again. seed-nodes=[akka.ssl.tcp://mySystem@host1:9610] Jul 31 17:10:24 host2 mySystem: [WARN] [07/31/2018 17:10:24.483] [mySystem-akka.actor.default-dispatcher-18] [akka.ssl.tcp://mySystem@host2:9610/system/cluster/core/daemon/joinSeedNodeProcess-1] Couldn't join seed nodes after [6] attempts  will try again. seed-nodes=[akka.ssl.tcp://mySystem@host1:9610] Jul 31 17:10:29 host2 mySystem: [WARN] [07/31/2018 17:10:29.503] [mySystem-akka.actor.default-dispatcher-2] [akka.ssl.tcp://mySystem@host2:9610/system/cluster/core/daemon/joinSeedNodeProcess-1] Couldn't join seed nodes after [7] attempts  will try again. seed-nodes=[akka.ssl.tcp://mySystem@host1:9610] ```",,jrudolph; Captain1653; johanandren
25327,atooni,2018-07-09T14:16:57Z,2022-11-18T13:48:00Z,patriknw,patriknw; atooni; raboof,OSGi headers missing for akka typed,"Hello    we are using Akka within an OSGi based application and wnated to experiment with akka typed to see whether it could help us for furture releases.  It seems the akka-actor-typed OSGi headers are missing from the manifest.   Best regards  Andreas",,patriknw; atooni; raboof
25251,ktoso,2018-06-19T16:15:01Z,2023-08-28T08:14:13Z,johanandren,Captain1653; johanandren,Typed Actors: Can we emulate Union Types via wrapping?,"Just taking note of this interesting idea... I think we may  at the cost of allocations and more wrapping  emulate union types by wrapping into explicit `UnionN` types and providing an behavior which delegates to ""right target"" based on type checking... The behavior that people would implement / use would need receiveMessage's for each of the types it demultiplexes.  Have not fully explored the idea but seems doable. Java API would require explicit wrapping in the Union  ```Scala     class A     class B      class Nein {       val canA: Behaviors.Receive[A] = Behaviors.receiveMessage[A] { msg ⇒         ???       }        canA.receiveSignal {         case (context  PostStop) ⇒           println(""I'm dead now..."")           Behaviors.same       }        val canB: Behaviors.Receive[B] = Behaviors.receiveMessage[B] { msg ⇒        }        val context: akka.actor.typed.scaladsl.ActorContext[Any] = ???        final class Union2[T1  T2](b1: T1  b2: T2) {         def has1 = b1 ne null         def has2 = b2 ne null       }       object Union2 {         implicit def mk1[T  O](t: T): Union2[T  O] = Union2(t  null)         implicit def mk2[T  O](t: T): Union2[O  T] = Union2(null  t)       }        def anyOf[T1  T2](b1: Behavior[T1]  b2: Behavior[T2]): Behavior[Union2[T1  T2]] = {         // if T1  send to b1  if T2  send to b2         // signals... to both in order maybe?         ???       }         // can't do this nowadays:       // val all: Behavior[???] = canA orElse canB // nope       val all: Behavior[Union2[A  B]] = anyOf(canA  canB)       val allRef: ActorRef[Union2[A  B]] = context.spawn(all  ""fake-union"")        val a: A = ???       val b: B = ???        allRef ! a // implicitly packed as Union2[A  B]       allRef ! b // implicitly packed as Union2[A  B]  ```",,Captain1653; johanandren
25147,raboof,2018-05-25T12:40:25Z,2023-08-27T08:49:58Z,johanandren,Captain1653; johanandren; ktoso,all-contributors overview,It might be cool to acknowledge all kinds of contributors with something like https://www.npmjs.com/package/all-contributors-cli - though the table generated there is not super pretty. Perhaps could be a cool contribution :smile: ?,,Captain1653; johanandren; ktoso
25073,dispalt,2018-05-09T06:03:43Z,2023-11-12T00:36:42Z,dispalt,jiminhsieh; patriknw; BassirouRabo; dispalt,StreamRefsProtocol inherit from Serializable?,"I am running into a multiple serializer issue with `StreamsRef` using the vanilla `chill-akka` settings  and I was looking through other protocols (artery  cluster  etc) and they all seem to inherit from `Serializable`.  Is this potentially the source of the issue?  The error:  ``` Multiple serializers found for [akka.stream.impl.streamref.StreamRefsProtocol$SequencedOnNext]  choosing first of: [com.twitter.chill.akka.AkkaSerializer  akka.stream.serialization.StreamRefSerializer] ```",,jiminhsieh; patriknw; BassirouRabo; dispalt
25069,hseeberger,2018-05-08T12:53:49Z,2023-08-30T08:58:04Z,johanandren,Captain1653; johanandren,Allow for different overflow strategies for `BroadcastHub.sink`,Currently the upstream source is implicitly backpressured once the buffer is full. It would be useful to have different overflow strategies  e.g. failing the slow consumer(s).,,Captain1653; johanandren
24951,markusthoemmes,2018-04-23T11:54:46Z,2023-04-17T11:11:02Z,johanandren,ktoso; patriknw; markusthoemmes; johanandren; He-Pin,Provide a flow which finishes the stream after not seeing an event for some time.,"There is a multitude of time-aware stages in akka-streams. For this specific use-case there are:  * `takeWhile(time)`: Close the stream after consuming elements for `time`. * `idleTimeout(time)`: **Fails** the stream if there is more than `time` between two elements.  My specific use-case is as follows: I have a stream of roughly in-order data. Multiple producers produce to a topic. The data needs to be grouped by their timestamp (based on a given time-frame granularity).  Since I cannot know when the last element of a specific timeframe will arrive (one producer might emit less elements than others and thus could be stuck behind many messages from another producer) I'd like to keep my stream open until no new element arrives for `time`. It should close as usual and emit the aggregate I computed.  It's basically the same flow as `idleTimeout` but without failing the stream. Do you think something like this is worthwhile having in general? If yes: Shall we  add a new or add a parameter to all the `Timeout` flows stating if they should error or not?",,ktoso; patriknw; markusthoemmes; johanandren; He-Pin
24912,kkolman,2018-04-16T17:26:24Z,2023-08-25T08:44:46Z,johanandren,Captain1653; kkolman,Java PatternCS#gracefulStop not clear enough in java documentation,"Akka's docs are unclear regarding `gracefulStop` usage in Java. GracefulStop example in https://doc.akka.io/docs/akka/2.5/actors.html does not declare `gracefulStop` import.  BFU (like me) might be confused where does the gracefulStop comes from (is it Pattern  is it PatternCS ?):  ``` try {   CompletionStage<Boolean> stopped =     gracefulStop(actorRef  java.time.Duration.ofSeconds(5)  Manager.SHUTDOWN);   stopped.toCompletableFuture().get(6  TimeUnit.SECONDS);   // the actor has been stopped } catch (AskTimeoutException e) {   // the actor wasn't stopped within 5 seconds } ```` ",,Captain1653; kkolman
24901,He-Pin,2018-04-13T18:33:45Z,2023-08-25T08:44:31Z,johanandren,ktoso; Captain1653; richardimaoka; patriknw; He-Pin; raboof,should metion `akka.scheduler.tick-duration` 's default value is 10ms.,"<!--  Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka-HTTP: https://github.com/akka/akka-http/issues   - Alpakka:   https://github.com/akka/alpakka/issues   - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your issue precisely  and if possible provide a reproducer snippet (this helps resolve issues much quicker).  For general questions and discussion please use https://groups.google.com/group/akka-user/ or https://gitter.im/akka/akka instead.  Thanks  happy hakking! --> ",,ktoso; Captain1653; richardimaoka; patriknw; He-Pin; raboof
24879,He-Pin,2018-04-11T09:06:50Z,2023-08-28T12:56:04Z,johanandren,Captain1653; He-Pin; johanandren,RateLimiter patterns,There are needs for RateLimiter pattern support lives in `akka.pattern.Patterns`,,Captain1653; He-Pin; johanandren
24869,ccronemberger,2018-04-09T17:00:34Z,2023-08-27T08:54:22Z,johanandren,Captain1653; chbatey; johanandren,missing Java example for jmm.md,"In this page:  https://github.com/johanandren/akka/blob/master/akka-docs/src/main/paradox/general/jmm.md  I did not find the Java sample code.  Regards       Constantino",,Captain1653; chbatey; johanandren
24835,ktoso,2018-04-03T03:11:44Z,2023-08-27T08:54:02Z,johanandren,Captain1653; patriknw; johanandren,Maybe add Materializer#terminate,"ActorMaterializer has a `shutdown: Unit` but not a `terminate` that would be more in line with the Future returning terminate in Akka Actor.  Should we make them more consistent? This only exists nowadays:  ```   /**    * Shuts down this materializer and all the stages that have been materialized through this materializer. After    * having shut down  this materializer cannot be used again. Any attempt to materialize stages after having    * shut down will result in an IllegalStateException being thrown at materialization time.    */   def shutdown(): Unit  ```  Noticed when making an afterAll and suprised it did not return a Future",,Captain1653; patriknw; johanandren
24756,hekmekk,2018-03-19T14:24:51Z,2023-08-27T08:49:17Z,johanandren,Camsteack; ktoso; Captain1653; hekmekk; johanandren,Missing example on how to use `TestFSMRef` from java,"There is no documentation on how to use [TestFSMRef](https://doc.akka.io/api/akka/current/akka/testkit/TestFSMRef.html) from java. Specifically there is no hint available on how to satisfy the parameter `implicit ev: T <:< FSM[S  D]`. ",,Camsteack; ktoso; Captain1653; hekmekk; johanandren
24751,raboof,2018-03-19T10:24:14Z,2023-08-23T08:07:33Z,johanandren,Captain1653; raboof; johanandren,404 links in our documentation,"The link to 2.5.11 at the bottom of https://doc.akka.io/docs/akka/2.4.20/scala/cluster-usage.html does not work.  Probably good to review how those links get generated  and see if there's any other 404's that show up a lot in our logs.",,Captain1653; raboof; johanandren
24465,patriknw,2018-02-01T06:41:28Z,2023-08-23T19:19:42Z,johanandren,Captain1653; barcahead; patriknw,missing serializer for GetShardRegionStats,When using `ClusterShardingStats` the coordinator sends `GetShardRegionStats` to the remote regions. It's currently falling back to java serialization.,,Captain1653; barcahead; patriknw
24394,omj,2018-01-23T13:20:23Z,2023-08-23T19:19:59Z,johanandren,Captain1653; johanandren,Persistence query with multiple persistence plugins,"<!--  Please report issues regarding specific projects in their respective issue trackers  e.g.:  - Akka-HTTP: https://github.com/akka/akka-http/issues   - Alpakka:   https://github.com/akka/alpakka/issues   - Akka Persistence Cassandra Plugin: https://github.com/akka/akka-persistence-cassandra/issues  - ...  Please explain your issue precisely  and if possible provide a reproducer snippet (this helps resolve issues much quicker).  For general questions and discussion please use https://groups.google.com/group/akka-user/ or https://gitter.im/akka/akka instead.  Thanks  happy hakking! -->  I use akka persistence with leveldb (multiple plugins configuration)  ``` akka {   persistence {     module1.journal {       class = ""akka.persistence.journal.leveldb.LeveldbJournal""       native = on       fsync = on       dir = ""target/persistence/module1-journal""       checksum = off       compaction-intervals = {         ""*"" = 250       }     }      module2.journal {       class = ""akka.persistence.journal.leveldb.LeveldbJournal""       native = on       fsync = on       dir = ""target/persistence/module2-journal""       checksum = off       compaction-intervals = {         ""*"" = 250       }     }   } } ```  When I try to use persistence query ``` import system.dispatcher import akka.persistence.query.PersistenceQuery import akka.persistence.query.journal.leveldb.scaladsl.LeveldbReadJournal  implicit val materializer = ActorMaterializer() implicit val timeout = Timeout(20.seconds)  val queries = PersistenceQuery(system).readJournalFor[LeveldbReadJournal]( ""akka.persistence.module1.journal"")  val src: Source[String  NotUsed] = queries.currentPersistenceIds() ``` I get   > Unable to create read journal plugin instance for path [akka.persistence.module1.journal]  class [akka.persistence.journal.leveldb.LeveldbJournal]!  [info] java.lang.IllegalArgumentException: Unable to create read journal plugin instance for path [akka.persistence.module1.journal]  class [akka.persistence.journal.leveldb.LeveldbJournal]! [info] 	at akka.persistence.query.PersistenceQuery$$anonfun$akka$persistence$query$PersistenceQuery$$createPlugin$4.applyOrElse(PersistenceQuery.scala:96) [info] 	at akka.persistence.query.PersistenceQuery$$anonfun$akka$persistence$query$PersistenceQuery$$createPlugin$4.applyOrElse(PersistenceQuery.scala:93) [info] 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34) [info] 	at scala.util.Failure.recoverWith(Try.scala:232) [info] 	at akka.persistence.query.PersistenceQuery.akka$persistence$query$PersistenceQuery$$createPlugin(PersistenceQuery.scala:93) [info] 	at akka.persistence.query.PersistenceQuery$$anon$1.createExtension(PersistenceQuery.scala:64) [info] 	at akka.persistence.query.PersistenceQuery$$anon$1.createExtension(PersistenceQuery.scala:62) [info] 	at akka.actor.ActorSystemImpl.registerExtension(ActorSystem.scala:880) [info] 	at akka.actor.ExtensionId.apply(Extension.scala:78) [info] 	at akka.actor.ExtensionId.apply$(Extension.scala:77) [info] 	at akka.persistence.query.PersistenceQuery$$anon$1.apply(PersistenceQuery.scala:62) [info] 	at akka.persistence.query.PersistenceQuery.readJournalPluginFor(PersistenceQuery.scala:60) [info] 	at akka.persistence.query.PersistenceQuery.readJournalFor(PersistenceQuery.scala:46) [info] 	at mypackage.MyActor$$anonfun$receive$1.applyOrElse(MyActor.scala:52) [info] 	at akka.actor.Actor.aroundReceive(Actor.scala:517) [info] 	at akka.actor.Actor.aroundReceive$(Actor.scala:515) [info] 	at mypackage.MyActor.aroundReceive(Reindexer.scala:24) [info] 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527) [info] 	at akka.actor.ActorCell.invoke(ActorCell.scala:496) [info] 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257) [info] 	at akka.dispatch.Mailbox.run(Mailbox.scala:224) [info] 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234) [info] 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [info] 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [info] 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [info] 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [info] Caused by: akka.actor.ActorInitializationException: You cannot create an instance of [akka.persistence.journal.leveldb.LeveldbJournal] explicitly using the constructor (new). You have to use one of the 'actorOf' factory methods to create a new actor. See the documentation. [info] 	at akka.actor.ActorInitializationException$.apply(Actor.scala:194) [info] 	at akka.actor.Actor.$init$(Actor.scala:472) [info] 	at akka.persistence.journal.leveldb.LeveldbJournal.<init>(LeveldbJournal.scala:23) [info] 	at akka.persistence.journal.leveldb.LeveldbJournal.<init>(LeveldbJournal.scala:26) [info] 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) [info] 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) [info] 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) [info] 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) [info] 	at akka.actor.ReflectiveDynamicAccess.$anonfun$createInstanceFor$1(ReflectiveDynamicAccess.scala:32) [info] 	at scala.util.Try$.apply(Try.scala:209) [info] 	at akka.actor.ReflectiveDynamicAccess.createInstanceFor(ReflectiveDynamicAccess.scala:27) [info] 	at akka.persistence.query.PersistenceQuery.akka$persistence$query$PersistenceQuery$$instantiate$1(PersistenceQuery.scala:83) [info] 	at akka.persistence.query.PersistenceQuery$$anonfun$akka$persistence$query$PersistenceQuery$$createPlugin$3.applyOrElse(PersistenceQuery.scala:92) [info] 	at akka.persistence.query.PersistenceQuery$$anonfun$akka$persistence$query$PersistenceQuery$$createPlugin$3.applyOrElse(PersistenceQuery.scala:92) [info] 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34) [info] 	at scala.util.Failure.recoverWith(Try.scala:232) [info] 	at akka.persistence.query.PersistenceQuery.akka$persistence$query$PersistenceQuery$$createPlugin(PersistenceQuery.scala:92)  Only when I add default configuration ``` akka {   persistence {     journal { // bugfix for persistence query       plugin = ""akka.persistence.journal.leveldb""        leveldb {         dir = ""target/persistence/module1-journal""       }     }   } } ``` and use default persistence identifier ``` val queries = PersistenceQuery(system).readJournalFor[LeveldbReadJournal](LeveldbReadJournal.Identifier) ``` it starts working (I can see events from module1-journal).   BTW  LeveldbReadJournal.Identifier resolves to ""akka.persistence.query.journal.leveldb"" which I can't find in reference.conf  So what is the correct way to configure leveldb persistence query for use with multiple plugins?  (In my case I simultaneously read events from persistence query and write new events to same persistence plugin and my workaround fails because in result I have 3 configured plugins and two of them point to same database. And because plugin locks database for exclusive access I got ""IO error: lock .../module1-journal/LOCK: already held by process"")",,Captain1653; johanandren
24369,tonicsoft,2018-01-19T20:20:19Z,2023-02-06T13:38:55Z,johanandren,kstokoz; ktoso; johanandren; tonicsoft,Hard to merge Sources in sorted order  except 2 sources of same type,"Use case: merging multiple Sources of different types  sorting by some user specified criteria (e.g. a timestamp)  Suggested Java API:      Source<String  NotUsed> stringSource = Source.from(asList(""1""  ""12""  ""123""));     Source<Integer  NotUsed> intSource = Source.from(asList(1  2  3));          // sort strings and integers by number of characters  or the integer itself     Source<Object  NotUsed> merged = MergeSorted.builder(Integer::compare)             .add(stringSource  String::length)             .add(intSource  Function.identity())             .build();     // outputs ""1""  1  ""12""  2  ""123""  3  To implement this I was faced with two choices:  1. put each stream element in a wrapper object  and use existing mergeSorted functionality  then unwrap 2. implement a custom graph stage which of course is not trivial  I implemented both and neither was very pleasant.   In case you are interested in the production use case  it involved combining many (>5) sources of different types of business events  and producing a single stream ordered by timestamps. It was not possible to make each type extend a common interface such as ""HasTimestamp"".  Use case 2: sort >2 streams of the same type:      Source<Integer  NotUsed> source1;     Source<Integer  NotUsed> source2;     Source<Integer  NotUsed> source3;      Source<Integer  NotUsed> merged = MergeSorted.builder()             .add(source1)             .add(source2)             .add(source3)             .build();",,kstokoz; ktoso; johanandren; tonicsoft
23951,jrudolph,2017-11-09T13:34:04Z,2022-10-31T14:34:19Z,johanandren,jrudolph; ennru; johanandren,Fail materialized future in FileIO.toPath API when IO operation fails,Right now it materializes to a `Future[IOResult]`. Contrary to expectations  it will not return a failed future when the operation fails but it will return an `IOResult` with a failed status field. It should also be configurable what should happen with files that haven't been completely written.,akka-stream-tests/src/test/scala/akka/stream/io/FileSinkSpec.scala; akka-stream-tests/src/test/scala/akka/stream/io/OutputStreamSinkSpec.scala; akka-stream/src/main/scala/akka/stream/IOResult.scala; akka-stream/src/main/scala/akka/stream/impl/io/FileSubscriber.scala; akka-stream/src/main/scala/akka/stream/impl/io/OutputStreamSubscriber.scala,2m
23086,atiqsayyed,2017-06-03T10:05:46Z,2022-06-02T19:38:33Z,johanandren,Captain1653; johanandren,Merged the document from akka-docs scala/stream/stream-composition and java/stream/stream-composition,,,Captain1653; johanandren
22849,patriknw,2017-05-05T06:47:36Z,2022-04-26T14:02:31Z,patriknw,He-Pin,performance improvements for typed javadsl message matchers,The behavior and receive builders can be optimized  for example: * use array in built behavior * match on exact message class would be efficient with HashMap lookup instead of traversals (might only be able to use this when there are only exact message class matchers  but that should be a very common case) * but note that if only a few matchers then array traversal can be better than HashMap lookup  but the good thing is that we can decide implementation at `build()` time,,He-Pin
22730,filosganga,2017-04-17T15:35:52Z,2022-09-13T13:23:19Z,johanandren,ktoso; filosganga; patriknw; johanandren; He-Pin; weihsiu,Missing ResourceFlatMapConcat stage,"Hi  I need to apply a transformation to a `Flow[I O]` that involves opening a resource and release it when the stream is closed. Something similar to fs2 `bracket`:  At the moment I cannot find any way to do that without implementing a custom `GraphStage`.  Would be very good to have a stage that can be used like this: ```scala Flow[T].resourceFlatMapConcat(   () => new Resource /* Acquire the resource */     resource => t => /* Use resource and current element */ Source.single(int)    _.release() /* Release the resource*/) ```  I am not sure if the acquire and release resource should be asynchronous.   On top of this stage I guess will be possible to define `resourceMap` and `resourceMapAsync`. I am not sure if a `resourceFlatMapMerge` stage will make any sense.  Is there any way to implement it at the moment? The only similar stage I have seen is the `resourceUnfold`. You can use in this way:  ```scala Flow[T].flatMapConcat { t =>    Source.resourceUnfold(...) } ```  But as far as I have understood  in this case the resource is created and released for each element of the flow  while I want it to be created when the Flow is materialized and released when it completes (successfully or not).  Another alternative seems using the `statefulMapConcat` where you can acuire the resource at materialization time  but there is no callback to release it.  I am happy to contribute if this stage makes any sense. ",,ktoso; filosganga; patriknw; johanandren; He-Pin; weihsiu
21899,johanandren,2016-11-28T13:55:00Z,2022-11-18T13:49:55Z,patriknw,patriknw; helena,Unused private package for each module,"We somehow generate a Private-Package for each module with a package name based on the modules group-id:  ``` [warn] bnd: Unused Private-Package instructions  no such package(s) on the class path: [com.typesafe.akka.distributed.data.experimental.*] ```  This can be seen for each module in the nightly builds: https://jenkins.akka.io:8498/job/akka-publish-nightly/574/consoleFull  We should get rid of this.",project/OSGi.scala,richardimaoka
21889,patriknw,2016-11-23T17:05:57Z,2023-08-22T06:12:52Z,patriknw,,clarify that java serialization is needed for remote deployment,"e.g.  akka.actor.serialization-bindings {     ""akka.remote.RemoteScope"" = java }  For that specific class we might be able to add a serializer  but I think there are other things in remote deployment that will not be easy to serialize.",,patriknw
21708,trbngr,2016-10-21T09:01:21Z,2023-03-07T08:56:14Z,johanandren,jrudolph; ktoso; trbngr; farico; richardimaoka; patriknw; johanandren,TLSActor causes `IllegalArgumentException` with non-LDH ASCII hostnames.,When making a request using akka-http to this url: `https://open_nsfw.gitlab.io/`. The following exception is thrown.  ``` Caused by: java.lang.IllegalArgumentException: Contains non-LDH ASCII characters     at java.net.IDN.toASCIIInternal(IDN.java:296)     at java.net.IDN.toASCII(IDN.java:122)     at javax.net.ssl.SNIHostName.<init>(SNIHostName.java:99)     at akka.stream.impl.io.TLSActor$$anonfun$applySNI$1$$anonfun$apply$3.apply(TLSActor.scala:497)     at akka.stream.impl.io.TLSActor$$anonfun$applySNI$1$$anonfun$apply$3.apply(TLSActor.scala:482)     at scala.Option$WithFilter.map(Option.scala:207)     at akka.stream.impl.io.TLSActor$$anonfun$applySNI$1.apply(TLSActor.scala:482)     at akka.stream.impl.io.TLSActor$$anonfun$applySNI$1.apply(TLSActor.scala:481)     at scala.Option.flatMap(Option.scala:171)     at akka.stream.impl.io.TLSActor.applySNI(TLSActor.scala:481)     at akka.stream.impl.io.TLSActor.applySessionParameters(TLSActor.scala:177)     at akka.stream.impl.io.TLSActor.<init>(TLSActor.scala:164)     at akka.stream.impl.io.TLSActor$$anonfun$props$1.apply(TLSActor.scala:37)     at akka.stream.impl.io.TLSActor$$anonfun$props$1.apply(TLSActor.scala:37)     at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87)     at akka.actor.Props.newActor(Props.scala:213)     at akka.actor.ActorCell.newActor(ActorCell.scala:562)     at akka.actor.ActorCell.create(ActorCell.scala:588)     ... 9 more ```  It seems like changing [TLSActor](https://github.com/akka/akka/blob/4a7cd147313404eb8137e56163e54f06c23640d0/akka-stream/src/main/scala/akka/stream/impl/io/TLSActor.scala#L497) here to  `clone.setServerNames(Collections.singletonList(new SNIHostName(hostname.getBytes)))` works around the issue.  Are there any other issues this change would raise? ,,jrudolph; ktoso; trbngr; farico; richardimaoka; patriknw; johanandren
21669,jrudolph,2016-10-13T14:23:26Z,2023-08-22T06:13:30Z,patriknw,,Provide support (and/or documentation) for TLS certificate pinning with (old) akka-remote,Idea is to provide a mapping from target hosts to certificates as a stricter alternative to just checking against a CA. - can be implemented by providing a SSLContext with a custom TrustManager - needs support for supplying an SSLContext - should provide an example how to configure it ,,patriknw
21389,patriknw,2016-09-07T06:22:14Z,2023-11-27T15:24:51Z,patriknw,patriknw; 2m; johanandren; octonato,RemoteDeathWatchSpec: Unknown message DeathWatchNotification,Seeing this with both Artery and old remoting  ``` [WARN] [09/07/2016 08:19:21.401] [other-akka.remote.default-remote-dispatcher-9] [akka.actor.LocalActorRefProvider(akka://other)] Unknown message [DeathWatchNotification(Actor[artery://RemoteDeathWatchSpec@localhost:55822/user] true false)] received by [Actor[akka://other/remote]] ``` ,,patriknw; 2m; johanandren; octonato
20583,johanandren,2016-05-20T17:03:23Z,2022-11-18T13:48:40Z,patriknw,patriknw; johanandren,Prevent OSGi from filtering out classes when releasing,To prevent the big fiasco of missing classes in 2.4.5 from ever happening again we should make the build fail or just not omit classes. ,,patriknw; johanandren
19707,johanandren,2016-02-08T08:49:49Z,2022-05-04T09:37:26Z,johanandren,He-Pin; rkuhn; johanandren,Avoid allocations in Java unfoldAsync,Currently there is three transformations taking place in each unfold invocation: `Future` => `CompletionStage`  `Option` => `Optional` and `Tuple2` => `Pair`. We should be able to avoid this somehow. ,,He-Pin; rkuhn; johanandren
19360,ktoso,2016-01-05T21:10:28Z,2022-09-04T10:26:31Z,johanandren,viktorklang; ktoso; drewhk; johanandren; He-Pin; rkuhn,Cleanup: GraphStage-directly vs. andThen SymbolicStage,"We currently have a mix of styles how we create stages:  ``` scala   def grouped(n: Int): Repr[immutable.Seq[Out]] = andThen(Grouped(n))  // vs.  def groupedWithin(n: Int  d: FiniteDuration): Repr[immutable.Seq[Out]] = {     // ...      via(new GroupedWithin[Out](n  d).withAttributes(name(""groupedWithin"")))   } ```  Use of `Stages.DefaultAttributes` also is not consistent in recent GraphStage impls.  // via @viktorklang  ",,viktorklang; ktoso; drewhk; johanandren; He-Pin; rkuhn
19045,viktorklang,2015-11-30T11:23:44Z,2022-09-01T13:11:05Z,patriknw,He-Pin; patriknw; drewhk,Create varargs versions of all fan-in/out fluent combinators in FlowOps,- [x] mergeAll - [x] concatAll - [x] interleaveAll - [x] alsoToAll ,,He-Pin; patriknw; drewhk
18846,PhilAndrew,2015-11-04T05:42:19Z,2022-11-18T13:48:58Z,patriknw,rkuhn; patriknw; briantopping; PhilAndrew,Akka remoting does not work with Akka OSGi unless I copy its reference.conf file,I am trying to use Akka remoting with Akka OSGi. Example project https://github.com/PhilAndrew/sbt-osgi-felix-akka-blueprint-camel/tree/136f8af2a40eea8ce2c8aae066cbb08f94559c19  The example project can be used to test this problem.  This does not work  it says:  ``` print components will not participate in quiesce operations ERROR: Bundle default.sbt.osgi.felix.akka.blueprint.camel [21] Error starting reference:file:/D:/home/projects/sbt-osgi- felix-akka-blueprint-camel/target/scala-2.11/classes/ (org.osgi.framework.BundleException: Activator start error in bund le default.sbt.osgi.felix.akka.blueprint.camel [21].) com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'akka.remote.log-received-messages'         at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152)         at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170)         at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176)         at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176)         at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184)         at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189)         at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214)         at akka.remote.RemoteSettings.<init>(RemoteSettings.scala:24)         at akka.remote.RemoteActorRefProvider.<init>(RemoteActorRefProvider.scala:112)         at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)         at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)         at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)         at java.lang.reflect.Constructor.newInstance(Constructor.java:422)         at akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$2.apply(DynamicAccess.scala:78)         at scala.util.Try$.apply(Try.scala:192)         at akka.actor.ReflectiveDynamicAccess.createInstanceFor(DynamicAccess.scala:73)         at akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$3.apply(DynamicAccess.scala:84)         at akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$3.apply(DynamicAccess.scala:84)         at scala.util.Success.flatMap(Try.scala:231)         at akka.actor.ReflectiveDynamicAccess.createInstanceFor(DynamicAccess.scala:84)         at akka.actor.ActorSystemImpl.liftedTree1$1(ActorSystem.scala:626)         at akka.actor.ActorSystemImpl.<init>(ActorSystem.scala:619)         at akka.actor.ActorSystem$.apply(ActorSystem.scala:143)         at akka.actor.ActorSystem$.apply(ActorSystem.scala:127)         at akka.osgi.OsgiActorSystemFactory.createActorSystem(OsgiActorSystemFactory.scala:33)         at akka.osgi.ActorSystemActivator.start(ActorSystemActivator.scala:42)         at org.apache.felix.framework.util.SecureAction$Actions.run(SecureAction.java:1709)         at java.security.AccessController.doPrivileged(Native Method)         at org.apache.felix.framework.util.SecureAction.startActivator(SecureAction.java:688)         at org.apache.felix.framework.Felix.activateBundle(Felix.java:2220)         at org.apache.felix.framework.Felix.startBundle(Felix.java:2138)         at org.apache.felix.framework.Felix.setActiveStartLevel(Felix.java:1365)         at org.apache.felix.framework.FrameworkStartLevelImpl.run(FrameworkStartLevelImpl.java:308)         at java.lang.Thread.run(Thread.java:745) Terminate batch job (Y/N)? ```  I believe it should work  if I want it to work I have to copy the reference.conf file out of this Akka Remoting jar and put it in resources folder  that is a workaround for the problem  I should not have to do a workaround like this for Akka Remoting in OSGi to work. ,,rkuhn; patriknw; briantopping; PhilAndrew
17451,rkuhn,2015-05-11T15:59:52Z,2022-11-18T13:49:12Z,patriknw,patriknw,sub-projects should fully contain their OSGi and dependency settings,"Currently we import from central places in the `project/` folder  but it would be better to keep this information “local” to each project. We should retain the symbolic names for dependencies  i.e. the `""..."" % ""..."" % ""...""` syntax shall only ever be used in `project/` in order to avoid diverging dependency declarations for the same library (and for a quicker manual overview). ",,patriknw
16617,fkoehler,2015-01-06T15:14:57Z,2022-08-23T11:42:13Z,johanandren,Captain1653; ihostage; patriknw; maciekciolek,CircuitBreaker should provide statistics like Netflix Hystrix does,It would be great if the akka CircuitBreaker would provide some kind of metrics stream like the Netflix Hystrix framework so we forward these to i.e. statsd or write a dashboard like https://github.com/Netflix/Hystrix/tree/master/hystrix-dashboard  I think this would help to get insight into the state of a running system and react to problems. See the hystrix docu for more information. ,,Captain1653; ihostage; patriknw; maciekciolek
16615,patriknw,2015-01-05T10:34:13Z,2023-08-22T06:11:25Z,patriknw,Captain1653; patriknw,Use log-remote-lifecycle-events in ReliableDeliverySupervisor,Currently the supervisionStrategy logs at warning level without checking log-remote-lifecycle-events. See https://groups.google.com/d/msg/akka-user/EmLK1mEMb3U/G5adxGoeIWQJ  I don't know why that is treated differently than other logging in the endpoint writers. Perhaps there is a good reason (and we can close this without action). ,,Captain1653; patriknw
13977,viktorklang,2014-04-04T07:23:25Z,2022-11-18T13:50:08Z,patriknw,patriknw; briantopping,BundleDelegatingClassLoader randomly loads classes from wrong classloader when running Pax Exam tests in native container,imported from https://www.assembla.com/spaces/akka/tickets/3977  The problem occurs when we are running tests using Pax Exam and in the Native Container.  The findTransitiveBundles method returns a list of bundles to use when loading classes specified in the configuration. This list is unordered and when bundle 0 is first in the list the classes will be loaded from the JVM classloader which then causes a ClassCastException. This causes the integration tests to be unstable. One simple solution is to sort this list in a descending order. ,,patriknw; briantopping
13932,patriknw,2014-03-17T10:15:07Z,2023-08-22T06:13:55Z,patriknw,sachag678,Remote deployment not carrying over Props.Mailbox nor Deploy.Mailbox,imported from https://www.assembla.com/spaces/akka/tickets/3932  Originally reported here: https://groups.google.com/d/msg/akka-user/xv-7JhGCub8/Y2LHndLdxyIJ ,,sachag678
12960,drewhk,2013-01-25T15:46:50Z,2023-08-22T06:14:22Z,patriknw,,Mitigate blocking by name lookups when lookup fails,"imported from https://www.assembla.com/spaces/akka/tickets/2960  When the remoting is bombarded with failed name lookups  messages might be dropped or delayed by the blocking on name lookups. Quoting Patrik:  ""I started with writing a test to ensure that things are not exhausted when using broken connections. Unfortunately we have some more work to do. Failing test here: https://github.com/akka/akka/commit/cc1f85b3ba5c8523265dda7c13775fdaad463fbd""  Possible workaround is to Gate addresses where lookup failed. This disables associations to the failed address until the configured time elapses. This does not solve the case however  when each of the failing lookup addresses are different (I don't know how realistic is that case).  Long term solution is to solve name lookups asynchronously  see: #12591 ",,patriknw
